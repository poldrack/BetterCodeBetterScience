

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Data Organization and Management &#8212; Better Code, Better Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'data_management';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Bibliography" href="bibliography.html" />
    <link rel="prev" title="Project structure and management" href="project_organization.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="frontmatter.html">
  
  
  
  
  
  
    <p class="title logo__title">Better Code, Better Science</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="frontmatter.html">
                    Better Code, Better Science
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="essential_tools_and_techniques.html">Essential tools and techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="software_engineering.html">Principles of software engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">Software testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="AI_coding_assistants.html">Coding with AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="project_organization.html">Project structure and management</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Data Organization and Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/poldrack/BetterCodeBetterScience" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/poldrack/BetterCodeBetterScience/issues/new?title=Issue%20on%20page%20%2Fdata_management.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/data_management.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Data Organization and Management</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principles-of-data-management">Principles of data management</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fair-principles">The FAIR Principles</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#findable">Findable</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#accessible">Accessible</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#interoperable">Interoperable</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#reusable">Reusable</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-data-lifecycle">The data lifecycle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#planning-a-study">Planning a study</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-management-plans">Data Management Plans</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collecting-data">Collecting data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#storing-data">Storing data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#file-system-storage">File system storage</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#storage-on-a-pc-laptop-hard-drive">Storage on a PC/laptop hard drive</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#storage-on-a-network-drive">Storage on a network drive</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cloud-drives">Cloud drives</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cloud-object-storage">Cloud object storage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#database-storage">Database storage</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#relational-databases">Relational databases</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#acid">ACID</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#analytic-databases">Analytic databases</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#nosql-databases">NoSQL databases</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#document-stores">Document stores</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-databases">Graph databases</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-databases">Vector databases</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#managing-original-data">Managing original data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#immutable-storage">Immutable storage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backup">Backup</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-access">Data access</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-formats-and-file-types">Data formats and file types</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tabular-data">Tabular data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#long-wide-and-tidy-tabular-data">Long, wide, and tidy tabular data</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#column-headers-are-values-not-variable-names">Column headers are values, not variable names</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-variables-are-stored-in-one-column">Multiple variables are stored in one column</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#variables-are-stored-in-both-rows-and-columns">Variables are stored in both rows and columns</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#single-type-of-observational-unit-spread-across-multiple-tables">Single type of observational unit spread across multiple tables</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tabular-file-formats">Tabular file formats</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#russ-s-first-law-of-tabular-data-management">Russ’s First Law of Tabular Data Management</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multidimensional-array-data">Multidimensional array data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#multidimensional-array-file-formats">Multidimensional array file formats</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#symmetrical-matrices">Symmetrical matrices</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#network-graph-data">Network/graph data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-data-file-formats">Graph data file formats</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specialized-data-formats">Specialized data formats</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-organization-schemes">Data organization schemes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#file-granularity">File granularity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-file-folder-naming-conventions">Data file/folder naming conventions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata">Metadata</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-file-formats">Metadata file formats</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-documentation">Data documentation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-dictionaries">Data dictionaries</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#codebooks">Codebooks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#provenance">Provenance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-of-sensitive-data">Handling of sensitive data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-security">Data security</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deidentification">Deidentification</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#anonymization">Anonymization</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#version-control-for-data">Version control for data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-git-for-data-version-control">Using git for data version control</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-datalad-for-version-control-on-larger-datasets">Using Datalad for version control on larger datasets</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-local-datalad-dataset">Creating a local Datalad dataset</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#modifying-files">Modifying files</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pushing-data-to-a-remote-repository">Pushing data to a remote repository</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#archiving-data">Archiving data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix-an-example-of-database-usage">Appendix: An example of database usage</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-gwas-data-to-a-document-store">Adding GWAS data to a document store</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#annotating-gene-sets">Annotating gene sets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mapping-pathway-information-to-traits">Mapping pathway information to traits</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-graph-database-linking-publications-pathways-to-traits">Generate the graph database linking publications pathways to traits</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#obtaining-literature-related-to-traits">Obtaining literature related to traits</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#add-documents-to-vector-database">Add documents to vector database</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analyzing-and-visualizing-the-results">Analyzing and visualizing the results</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="data-organization-and-management">
<h1><a class="toc-backref" href="#id9">Data Organization and Management</a><a class="headerlink" href="#data-organization-and-management" title="Permalink to this heading">#</a></h1>
<div class="contents topic" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#data-organization-and-management" id="id9">Data Organization and Management</a></p>
<ul>
<li><p><a class="reference internal" href="#principles-of-data-management" id="id10">Principles of data management</a></p>
<ul>
<li><p><a class="reference internal" href="#the-fair-principles" id="id11">The FAIR Principles</a></p>
<ul>
<li><p><a class="reference internal" href="#findable" id="id12">Findable</a></p></li>
<li><p><a class="reference internal" href="#accessible" id="id13">Accessible</a></p></li>
<li><p><a class="reference internal" href="#interoperable" id="id14">Interoperable</a></p></li>
<li><p><a class="reference internal" href="#reusable" id="id15">Reusable</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#the-data-lifecycle" id="id16">The data lifecycle</a></p></li>
<li><p><a class="reference internal" href="#planning-a-study" id="id17">Planning a study</a></p>
<ul>
<li><p><a class="reference internal" href="#data-management-plans" id="id18">Data Management Plans</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#collecting-data" id="id19">Collecting data</a></p></li>
<li><p><a class="reference internal" href="#storing-data" id="id20">Storing data</a></p>
<ul>
<li><p><a class="reference internal" href="#file-system-storage" id="id21">File system storage</a></p>
<ul>
<li><p><a class="reference internal" href="#storage-on-a-pc-laptop-hard-drive" id="id22">Storage on a PC/laptop hard drive</a></p></li>
<li><p><a class="reference internal" href="#storage-on-a-network-drive" id="id23">Storage on a network drive</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#cloud-drives" id="id24">Cloud drives</a></p></li>
<li><p><a class="reference internal" href="#cloud-object-storage" id="id25">Cloud object storage</a></p></li>
<li><p><a class="reference internal" href="#database-storage" id="id26">Database storage</a></p>
<ul>
<li><p><a class="reference internal" href="#relational-databases" id="id27">Relational databases</a></p>
<ul>
<li><p><a class="reference internal" href="#acid" id="id28">ACID</a></p></li>
<li><p><a class="reference internal" href="#analytic-databases" id="id29">Analytic databases</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#nosql-databases" id="id30">NoSQL databases</a></p>
<ul>
<li><p><a class="reference internal" href="#document-stores" id="id31">Document stores</a></p></li>
<li><p><a class="reference internal" href="#graph-databases" id="id32">Graph databases</a></p></li>
<li><p><a class="reference internal" href="#vector-databases" id="id33">Vector databases</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#managing-original-data" id="id34">Managing original data</a></p>
<ul>
<li><p><a class="reference internal" href="#immutable-storage" id="id35">Immutable storage</a></p></li>
<li><p><a class="reference internal" href="#backup" id="id36">Backup</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#data-access" id="id37">Data access</a></p></li>
<li><p><a class="reference internal" href="#data-formats-and-file-types" id="id38">Data formats and file types</a></p>
<ul>
<li><p><a class="reference internal" href="#tabular-data" id="id39">Tabular data</a></p>
<ul>
<li><p><a class="reference internal" href="#long-wide-and-tidy-tabular-data" id="id40">Long, wide, and tidy tabular data</a></p>
<ul>
<li><p><a class="reference internal" href="#column-headers-are-values-not-variable-names" id="id41">Column headers are values, not variable names</a></p></li>
<li><p><a class="reference internal" href="#multiple-variables-are-stored-in-one-column" id="id42">Multiple variables are stored in one column</a></p></li>
<li><p><a class="reference internal" href="#variables-are-stored-in-both-rows-and-columns" id="id43">Variables are stored in both rows and columns</a></p></li>
<li><p><a class="reference internal" href="#single-type-of-observational-unit-spread-across-multiple-tables" id="id44">Single type of observational unit spread across multiple tables</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#tabular-file-formats" id="id45">Tabular file formats</a></p></li>
<li><p><a class="reference internal" href="#russ-s-first-law-of-tabular-data-management" id="id46">Russ’s First Law of Tabular Data Management</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#multidimensional-array-data" id="id47">Multidimensional array data</a></p>
<ul>
<li><p><a class="reference internal" href="#multidimensional-array-file-formats" id="id48">Multidimensional array file formats</a></p></li>
<li><p><a class="reference internal" href="#symmetrical-matrices" id="id49">Symmetrical matrices</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#network-graph-data" id="id50">Network/graph data</a></p>
<ul>
<li><p><a class="reference internal" href="#graph-data-file-formats" id="id51">Graph data file formats</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#specialized-data-formats" id="id52">Specialized data formats</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#data-organization-schemes" id="id53">Data organization schemes</a></p>
<ul>
<li><p><a class="reference internal" href="#file-granularity" id="id54">File granularity</a></p></li>
<li><p><a class="reference internal" href="#data-file-folder-naming-conventions" id="id55">Data file/folder naming conventions</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#metadata" id="id56">Metadata</a></p>
<ul>
<li><p><a class="reference internal" href="#metadata-file-formats" id="id57">Metadata file formats</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#data-documentation" id="id58">Data documentation</a></p>
<ul>
<li><p><a class="reference internal" href="#data-dictionaries" id="id59">Data dictionaries</a></p></li>
<li><p><a class="reference internal" href="#codebooks" id="id60">Codebooks</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#provenance" id="id61">Provenance</a></p></li>
<li><p><a class="reference internal" href="#handling-of-sensitive-data" id="id62">Handling of sensitive data</a></p>
<ul>
<li><p><a class="reference internal" href="#data-security" id="id63">Data security</a></p></li>
<li><p><a class="reference internal" href="#deidentification" id="id64">Deidentification</a></p></li>
<li><p><a class="reference internal" href="#anonymization" id="id65">Anonymization</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#version-control-for-data" id="id66">Version control for data</a></p>
<ul>
<li><p><a class="reference internal" href="#using-git-for-data-version-control" id="id67">Using git for data version control</a></p></li>
<li><p><a class="reference internal" href="#using-datalad-for-version-control-on-larger-datasets" id="id68">Using Datalad for version control on larger datasets</a></p>
<ul>
<li><p><a class="reference internal" href="#creating-a-local-datalad-dataset" id="id69">Creating a local Datalad dataset</a></p></li>
<li><p><a class="reference internal" href="#modifying-files" id="id70">Modifying files</a></p></li>
<li><p><a class="reference internal" href="#pushing-data-to-a-remote-repository" id="id71">Pushing data to a remote repository</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#archiving-data" id="id72">Archiving data</a></p></li>
<li><p><a class="reference internal" href="#appendix-an-example-of-database-usage" id="id73">Appendix: An example of database usage</a></p>
<ul>
<li><p><a class="reference internal" href="#adding-gwas-data-to-a-document-store" id="id74">Adding GWAS data to a document store</a></p></li>
<li><p><a class="reference internal" href="#annotating-gene-sets" id="id75">Annotating gene sets</a></p></li>
<li><p><a class="reference internal" href="#mapping-pathway-information-to-traits" id="id76">Mapping pathway information to traits</a></p></li>
<li><p><a class="reference internal" href="#generate-the-graph-database-linking-publications-pathways-to-traits" id="id77">Generate the graph database linking publications pathways to traits</a></p></li>
<li><p><a class="reference internal" href="#obtaining-literature-related-to-traits" id="id78">Obtaining literature related to traits</a></p></li>
<li><p><a class="reference internal" href="#add-documents-to-vector-database" id="id79">Add documents to vector database</a></p></li>
<li><p><a class="reference internal" href="#analyzing-and-visualizing-the-results" id="id80">Analyzing and visualizing the results</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<p>Research data are like the water of science: When they stop flowing and dry up, everything withers and ultimately dies.  In this chapter we discuss the principles and practices for good research data management and organization.</p>
<section id="principles-of-data-management">
<h2><a class="toc-backref" href="#id10">Principles of data management</a><a class="headerlink" href="#principles-of-data-management" title="Permalink to this heading">#</a></h2>
<p>Research data vary in value, and in some cases can be highly valuable.  For example, the Large Hadron Collider at CERN, which was responsible for the data supporting the discovery of the Higgs Boson in 2012, has annual computing costs alone estimated at <a class="reference external" href="https://en.as.com/latest_news/how-much-money-did-cerns-large-hadron-collider-cost-to-build-and-who-paid-for-it-n/">about $286 Million</a>, such that the loss of the resulting data from those computations would have enormous costs. And in some cases where unique events are detected, such as the LIGO gravitational wave detector or telescope images of cosmic events, the data cannot be recreated if they are lost, making them immensely valuable.  For this reason, scientific agencies have long focused on developing frameworks for research data management. In the US, the National Institute of Standards and Technology (NIST) has developed a <a class="reference external" href="https://www.nist.gov/programs-projects/research-data-framework-rdaf">Research Data Framework</a> that provides researchers with a detailed set of best practices for research data management.</p>
<section id="the-fair-principles">
<h3><a class="toc-backref" href="#id11">The FAIR Principles</a><a class="headerlink" href="#the-fair-principles" title="Permalink to this heading">#</a></h3>
<p>The FAIR Principles <span id="id1">[<a class="reference internal" href="bibliography.html#id6" title="Mark D Wilkinson, Michel Dumontier, I Jsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, Jan-Willem Boiten, Luiz Bonino da Silva Santos, Philip E Bourne, Jildau Bouwman, Anthony J Brookes, Tim Clark, Mercè Crosas, Ingrid Dillo, Olivier Dumon, Scott Edmunds, Chris T Evelo, Richard Finkers, Alejandra Gonzalez-Beltran, Alasdair J G Gray, Paul Groth, Carole Goble, Jeffrey S Grethe, Jaap Heringa, Peter A C 't Hoen, Rob Hooft, Tobias Kuhn, Ruben Kok, Joost Kok, Scott J Lusher, Maryann E Martone, Albert Mons, Abel L Packer, Bengt Persson, Philippe Rocca-Serra, Marco Roos, Rene van Schaik, Susanna-Assunta Sansone, Erik Schultes, Thierry Sengstag, Ted Slater, George Strawn, Morris A Swertz, Mark Thompson, Johan van der Lei, Erik van Mulligen, Jan Velterop, Andra Waagmeester, Peter Wittenburg, Katherine Wolstencroft, Jun Zhao, and Barend Mons. The fair guiding principles for scientific data management and stewardship. Sci Data, 3:160018, Mar 2016. doi:10.1038/sdata.2016.18.">Wilkinson <em>et al.</em>, 2016</a>]</span> are a set of guiding principles for the effective sharing of research objects, including but not limited to research data.  The FAIR acronym refers to four features of research objects that are essential to effective sharing:</p>
<section id="findable">
<h4><a class="toc-backref" href="#id12">Findable</a><a class="headerlink" href="#findable" title="Permalink to this heading">#</a></h4>
<p>Data are findable if they could be reasonably found by another researcher, usually via the standard web searches or database queries.  Making data findable involves:</p>
<ul class="simple">
<li><p>Associating them with a persistent identifier (such as a digital object identifier, or DOI)</p></li>
<li><p>Placing them in a repository that is searchable</p></li>
<li><p>Including sufficient machine-readable metadata to allow a successful search</p></li>
</ul>
</section>
<section id="accessible">
<h4><a class="toc-backref" href="#id13">Accessible</a><a class="headerlink" href="#accessible" title="Permalink to this heading">#</a></h4>
<p>Data are accessible if they can be accessed via clear procedures once they have been found. Making data accessible involves:</p>
<ul class="simple">
<li><p>Providing access by standard protocols (such as HTTP) or common transfer mechanisms (such as Globus).</p></li>
<li><p>Providing access to the metadata, even if the raw data are not available</p></li>
<li><p>Providing clear information regarding any limits on access and requirements for data access, if the data are not openly available</p></li>
</ul>
<p>Note that “accessible” doesn’t necessarily imply “open”; in many cases, access to the data themselves may require additional data usage agreements between institutions.  Accessibility in the FAIR sense simply requires that there is a clear process by which the data can be accessed.</p>
</section>
<section id="interoperable">
<h4><a class="toc-backref" href="#id14">Interoperable</a><a class="headerlink" href="#interoperable" title="Permalink to this heading">#</a></h4>
<p>Data are interoperable if they can be integrated with other data or processed automatically after they have been accessed.  Making data interoperable primarily involves:</p>
<ul class="simple">
<li><p>making the data accessible via standard file formats</p></li>
<li><p>making the metadata available using standard vocabularies or ontologies</p></li>
</ul>
</section>
<section id="reusable">
<h4><a class="toc-backref" href="#id15">Reusable</a><a class="headerlink" href="#reusable" title="Permalink to this heading">#</a></h4>
<p>Data are reusable if the requirements for reuse are clearly specified.  Making data reusable involves:</p>
<ul class="simple">
<li><p>Providing a clear usage agreement (or “license”<a class="footnote-reference brackets" href="#id8" id="id2">1</a>) for the data</p></li>
<li><p>Providing a clear and comprehensive description of the provenance of the data</p></li>
</ul>
<p>The FAIR principles are relatively abstract, in the sense that they don’t provide specific guidance about what FAIR means in any particular domain.  However, there are numerous resources that can help implement these principles, such as <a class="reference external" href="https://rdmkit.elixir-europe.org/">RDMKit</a> and the <a class="reference external" href="https://faircookbook.elixir-europe.org/content/home.html">FAIR Cookbook</a>, both generated by the European ELIXIR organization.</p>
</section>
</section>
</section>
<section id="the-data-lifecycle">
<h2><a class="toc-backref" href="#id16">The data lifecycle</a><a class="headerlink" href="#the-data-lifecycle" title="Permalink to this heading">#</a></h2>
<p>An important concept in research data management is the <em>data lifecycle</em>, which describes the role of data management in each of the different stages of a research project.  Figure <a class="reference internal" href="#lifecycle-fig"><span class="std std-numref">Figure 8</span></a> shows an example of how the <a class="reference external" href="https://rdmkit.elixir-europe.org/data_life_cycle">RDMkit project</a> outlines the stages of the data lifecycle:</p>
<figure class="align-default" id="lifecycle-fig">
<a class="reference internal image-reference" href="_images/data_lifecycle_rdmkit.png"><img alt="RDMkit Data Lifecycle" src="_images/data_lifecycle_rdmkit.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 8 </span><span class="caption-text">A depiction of the data management lifecycle, from the <a class="reference external" href="https://rdmkit.elixir-europe.org/data_life_cycle">RDMkit project by ELIXIR</a>, CC-BY-4.0.</span><a class="headerlink" href="#lifecycle-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>This figure highlights the fact that data management should be part of the discussion at each stage in a project.  In this chapter we will discuss several of the stages in the data lifecycle in detail, though we leave in-depth discussion of data processing and analysis workflows to a later chapter.</p>
</section>
<section id="planning-a-study">
<h2><a class="toc-backref" href="#id17">Planning a study</a><a class="headerlink" href="#planning-a-study" title="Permalink to this heading">#</a></h2>
<p>It is essential to think about data management from the inception of a study, in order to ensure that early decisions don’t lead to pain down the road.  Here are some examples of problems that might arise:</p>
<ul class="simple">
<li><p>If data quality control measures are not put in place at the beginning of the study, then problems with the data might not be discovered until it’s too late.</p></li>
<li><p>If important metadata are not stored, then it might be impossible to properly analyze the data later on.</p></li>
<li><p>If procedures for data versioning and provenance are not in place from the beginning, one can end up with confusion about which data files are appropriate for analysis and how the different data files were generated.</p></li>
<li><p>If the data are not properly documented, then it might not be possible to understand the meaning of specific variables in the dataset later on.</p></li>
</ul>
<p>These are just a few of the problems that can arise, making it important to have a plan for data management at the onset of a research study.</p>
<section id="data-management-plans">
<h3><a class="toc-backref" href="#id18">Data Management Plans</a><a class="headerlink" href="#data-management-plans" title="Permalink to this heading">#</a></h3>
<p>Research funding agencies are increasingly requiring data management plans (DMPs) for grant submissions.  In the US, both the National Science Foundation (NSF) and National Institutes of Health (NIH) require a DMP to accompany grant proposals, and the European Research Council (ERC) requires that funded projects submit a DMP within their first six months.  Creating a data management plan in advance of a project can be very helpful, as it helps encourage the early integration of methods that can help make data management and sharing easier as the project matures.  We will not go into detail regarding these plans, which will vary in their requirements depending on the funding agency. However, there are online tools available to assist with generation of a DMP:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://dmptool.org/">DMPtool</a> - for US funding agencies</p></li>
<li><p><a class="reference external" href="https://ds-wizard.org/">Data Stewardship Wizard</a> - for European funding agencies</p></li>
</ul>
<p>I recommend always creating a data management plan at the start of a project, even if it’s not required by your institution or funding agency.</p>
</section>
</section>
<section id="collecting-data">
<h2><a class="toc-backref" href="#id19">Collecting data</a><a class="headerlink" href="#collecting-data" title="Permalink to this heading">#</a></h2>
<p>Once data collection starts, it is essential to ensure that the data are properly saved and readable.  One should never assume that the code responsible for saving the data has actually worked properly; instead, the data should be separately loaded and checked to make sure that the data are being correctly stored and are properly readable. One good practice is to develop a checklist for new studies to ensure that the data are being collected properly; the details of such a checklist will depend on the specific area of study, but an example from our lab can be found <a class="reference internal" href="#"><span class="xref myst">here</span></a>.</p>
</section>
<section id="storing-data">
<h2><a class="toc-backref" href="#id20">Storing data</a><a class="headerlink" href="#storing-data" title="Permalink to this heading">#</a></h2>
<p>There are several different ways that one can store research data, which vary in their ease of use, speed, reliability, and resilience.  One major distinction is between the use of file systems (either physical or cloud systems) or database systems.</p>
<p>Before discussing different options, it is useful to lay out the important considerations regarding different data storage solutions.  These are the dimensions across which different options will vary:</p>
<ul class="simple">
<li><p><em>Ease of use</em>: How much extra work is required for the user to implement the storage solution?</p></li>
<li><p><em>Collaboration</em>: Do multiple researchers need to access the data? Do they need to be able to modify the dataset concurrently?</p></li>
<li><p><em>Storage capacity</em>: Is the solution sufficient to store the relevant amount of data for the study?  Is it scalable over time?</p></li>
<li><p><em>Performance</em>: Is the solution fast enough to enable the required processing and analysis steps?</p></li>
<li><p><em>Accessibility</em>: Is the storage system accessible to the system where the compute will be performed (e.g. local computer, HPC cluster, cloud system)?</p></li>
<li><p><em>Security</em>: Does the system meet the security and compliance requirements for the particular dataset? Does it allow appropriate access control?</p></li>
<li><p><em>Redundancy</em>: Is the system robust to disasters, ranging from the failure of one hard drive to a catastrophic flood or fire?  Does it provide the required backup capability?</p></li>
<li><p><em>Cost</em>: Does the cost of the solution fit within the researcher’s budget?  Are there hidden costs that must be taken into account?</p></li>
<li><p><em>Longevity</em>: Will the data remain available in the long term?</p></li>
</ul>
<p>It’s also important to point out that most projects end up using multiple storage solutions for different portions of the data lifecycle.</p>
<section id="file-system-storage">
<h3><a class="toc-backref" href="#id21">File system storage</a><a class="headerlink" href="#file-system-storage" title="Permalink to this heading">#</a></h3>
<p>A file system is an organized system for naming and locating computer files on a storage system such as a hard disk.  Readers of this book will undoubtedly be familiar with the file systems present on Mac, Windows, or UNIX/Linux systems, which represent a hierarchical <em>tree</em> of folders and files. Here is an example of the file tree for the source code folder in the book project:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>tree<span class="w"> </span>-L<span class="w"> </span><span class="m">2</span><span class="w"> </span>src
src
└──<span class="w"> </span>BetterCodeBetterScience
<span class="w">    </span>├──<span class="w"> </span>__init__.py
<span class="w">    </span>├──<span class="w"> </span>__pycache__
<span class="w">    </span>├──<span class="w"> </span>bug_driven_testing.py
<span class="w">    </span>├──<span class="w"> </span>claudecode
<span class="w">    </span>├──<span class="w"> </span>constants.py
<span class="w">    </span>├──<span class="w"> </span>data_management.ipynb
<span class="w">    </span>├──<span class="w"> </span>distance.py
<span class="w">    </span>├──<span class="w"> </span>distance_testing
<span class="w">    </span>├──<span class="w"> </span>docker-example
<span class="w">    </span>├──<span class="w"> </span>escape_velocity.py
<span class="w">    </span>├──<span class="w"> </span>formatting_example.py
<span class="w">    </span>├──<span class="w"> </span>formatting_example_ai.py
<span class="w">    </span>├──<span class="w"> </span>formatting_example_ruff.py
<span class="w">    </span>├──<span class="w"> </span>incontext_learning_example.ipynb
<span class="w">    </span>├──<span class="w"> </span>language_model_api_prompting.ipynb
<span class="w">    </span>├──<span class="w"> </span>llm_utils.py
<span class="w">    </span>├──<span class="w"> </span>modify_data.py
<span class="w">    </span>├──<span class="w"> </span>my_linear_regression.py
<span class="w">    </span>├──<span class="w"> </span>simple_testing.py
<span class="w">    </span>├──<span class="w"> </span>simpleScaler.py
<span class="w">    </span>├──<span class="w"> </span>test_independence.py
<span class="w">    </span>└──<span class="w"> </span>textmining
</pre></div>
</div>
<p>We often use spatial metaphors to describe file systems; we say that a file is “inside” a folder, or that we are going to “move” a file from one folder to another.  Working effectively and efficiently with data stored on a file system will be enhanced by a solid knowledge of the various tools that one can use to interact with a file system.  In the examples throughout the book I will focus on <em>POSIX</em>-compliant operating systems like MacOS and Linux, but most of the same concepts also apply to other file systems such as Windows.</p>
<section id="storage-on-a-pc-laptop-hard-drive">
<h4><a class="toc-backref" href="#id22">Storage on a PC/laptop hard drive</a><a class="headerlink" href="#storage-on-a-pc-laptop-hard-drive" title="Permalink to this heading">#</a></h4>
<p>The simplest way to store data is on a hard drive on a researcher’s personal computer workstation or laptop.  While this is easy and relatively cheap for smaller datasets, it is also fraught for numerous reasons:</p>
<ul class="simple">
<li><p>It is risky, as the failure of the hard drive or loss of the system to damage or theft can result in total loss of the data.</p></li>
<li><p>Depending on whether or not the system is encrypted, theft may expose the data in ways that violate confidentiality.</p></li>
<li><p>Most PC/laptop systems do not have automatic backup systems, so they are less likely to have a viable backup for recovery if a problem occurs.</p></li>
<li><p>It is difficult or impossible to allow collaborators to access the data</p></li>
<li><p>For many research domains, the size of the data (often in terabytes) will quickly outstrip the capacity of local hard drives.</p></li>
</ul>
<p>For these reasons, I generally recommend to researchers in my lab that they should never rely solely on their own computer as the storage solution for research data.</p>
</section>
<section id="storage-on-a-network-drive">
<h4><a class="toc-backref" href="#id23">Storage on a network drive</a><a class="headerlink" href="#storage-on-a-network-drive" title="Permalink to this heading">#</a></h4>
<p>Research data is often stored on network drives.  These can vary from a network-attached storage system dedicated to one or more users within a research group, to large-scale network drives managed by an institutional computing center.  One common feature of network storage is the use of redundant drive systems, such as RAID (Redundant Array of Independent Disks). These systems combine multiple individual hard drives in ways that provide some degree of redundancy, such that the system can withstand the loss of one or more individual disks (depending on the setup) with no data loss.  However, it is critically important to remember that while RAID does provide some degree of fault-tolerance, it <em>does not</em> provide the disaster recovery benefits of a true backup.</p>
<p>Many researchers run and manage their own RAID systems for their group’s use, either attached to a single workstation or to a network.  This can be a cost-effective solution for large data storage, especially in situations where institutional data storage resources are not available.  However, I think that the apparent robustness of RAID systems can provide a false sense of security to their users.  Take the most common RAID setup for redundant storage, RAID 5, in which the system is robust to the failure of one of its hard drives.  When a drive fails, the system enters a “degraded” mode, often providing a notice to the user such as a flashing red light or beeping sounds.  If this failure goes unnoticed, or the system administrator puts off fixing it, the failure of a second drive during degraded mode or during the rebuilding of the array after replacing the first failed drive (which can often take many hours) can lead to complete data loss.  Similarly, if the rebuilding of the array fails (for example, due to power loss during the rebuild or an unrecoverable error in reading from the other drives), this can compromise the data. Safe use of RAID arrays requires consistent attention (including email notifications of failure if possible) and a strong backup strategy.</p>
<p>Most research institutions now offer large network-attached storage systems for research data, often connected directly to high-performance computing systems.  We have used systems like these for our research data for more than 15 years, and I personally would never go back to running my group’s own RAID system (which we did for years beforehand).  Foremost, the system administration and hardware management resources of an institutional computing center will almost always outstrip those of most research groups.  These large systems will have monitoring and repair procedures in place to ensure against data loss, and in the 15 years that we have used these systems (at Stanford and the University of Texas), we have never experienced data loss due to hardware failure.  However, they are still liable to potential disasters.  These systems are also highly performant, providing parallel access to the data through high-speed interconnections with the compute system.</p>
<p>Backing up one’s data from a large network drive is a great idea in theory, but in our experience it has often been either impossible or too costly, given the many terabytes of research data that we store on the systems.  Given the relatively low likelihood of failure, we have adopted a more risk-tolerant strategy to big data storage:</p>
<ul class="simple">
<li><p>Original data and any data that cannot be reasonably recreated from original data are stored on at least two independent systems (such as the network drive and a cloud storage system)</p></li>
<li><p>Software code is stored on a separate partition that is backed up by the computing center, as well as being pushed to Github.</p></li>
</ul>
<p>In this way, we have redundant copies of the code and original data that could be used to recreate the processed data if necessary.  This is a risky strategy, but the more risk-averse alternative of continuously backing up our entire 250TB partition would be cost-prohibitive.</p>
</section>
</section>
<section id="cloud-drives">
<h3><a class="toc-backref" href="#id24">Cloud drives</a><a class="headerlink" href="#cloud-drives" title="Permalink to this heading">#</a></h3>
<p>Cloud drives, such as Dropbox or Google Drive, have become very popular for storage and sharing of data.  I personally keep all of my code and documents synced to Dropbox from my laptop, and the file recovery capabilities of Dropbox have saved me from myself more than once after accidentally deleting the wrong files.  I also regularly share files with other researchers using the Dropbox file sharing features.  Because of the potential impact of loss of my laptop, I also keep a “hot spare” laptop that is constantly kept in sync with my primary laptop via Dropbox.  Thus, cloud drives are essential for my own research and productivity workflow. However, cloud drives on their own are unlikely to be a primary solution for data storage with large datasets, for several reasons including:</p>
<ul class="simple">
<li><p>Their cost increases dramatically as the datasets move into the terabyte range.</p></li>
<li><p>You can’t bring the compute to the data using these systems - you have to bring the data to the compute.  This means that the data need to be fully downloaded to each synced system, resulting in a large number of copies of the dataset.</p></li>
<li><p>These systems also are not optimized for large files, and network speed may result in long synchronization times.</p></li>
</ul>
<p>In addition, many institutions have specific restrictions regarding the use of specific cloud drives, especially with regard to private or protected information.</p>
</section>
<section id="cloud-object-storage">
<h3><a class="toc-backref" href="#id25">Cloud object storage</a><a class="headerlink" href="#cloud-object-storage" title="Permalink to this heading">#</a></h3>
<p>An increasingly common storage option, especially for very large datasets, is the use of cloud-based <em>object stores</em>, such as Amazon’s Simple Storage Service (S3) or Google Cloud Storage.  In some ways object storage is similar to a standard file system, in that it allows the storage of arbitrary types of files, which can be retrieved using a key that functions like a file path on a file system.  However, there are also important differences between object storage and file systems. Most importantly, cloud object stores are accessed via web API calls rather than by operations on a local storage system.  Cloud object stores have several features that can make them very attractive for research data storage:</p>
<ul class="simple">
<li><p>They offer scalability in terms of data size that is limited only by one’s budget</p></li>
<li><p>They provide robustness through redundant storage across multiple systems</p></li>
<li><p>They are often much less expensive than standard file system (“block”) storage</p></li>
</ul>
<p>These systems are most effective when they are accessed directly using computing resources hosted by the same cloud provider.  If they are located within the same datacenter, then the network connectivity can be substantially faster.  It rarely makes sense to access data directly on a cloud object store from a local computing system, both because of the potentially high cost of reading and writing data from these systems and because of the relatively long latency and low bandwidth of connections between a local system and a cloud provider.</p>
</section>
<section id="database-storage">
<h3><a class="toc-backref" href="#id26">Database storage</a><a class="headerlink" href="#database-storage" title="Permalink to this heading">#</a></h3>
<p>In some areas of science, such as genomics, it is common to store data using <em>database systems</em> rather than files on a filesystem. A database system is a software system that stores data records and allows the user to query the records based on specific features and to add, modify, or delete records.  A database system can run locally on one’s own computer, or can be accessed remotely via the Internet; most cloud computing providers provide database systems that can be hosted virtually, providing access to storage space that is limited only by one’s budget.</p>
<p>There are many potential benefits to the use of database storage that will be outlined below. However, one important factor in the choice of database versus flat file storage is what software tools will be used to analyze the data.  If the analyses are primarily being performed using custom code in Python or R, then it is relatively easy to either retrieve information from a database or load data from a flat file.  However, in some fields (including the field of neuroimaging where I work) it is common to use software packages that are built to process flat files, which strongly drives researchers in the field towards that approach.</p>
<p>I will first briefly outline several of the most common forms of database systems, and then show an example that employs each of them.</p>
<section id="relational-databases">
<h4><a class="toc-backref" href="#id27">Relational databases</a><a class="headerlink" href="#relational-databases" title="Permalink to this heading">#</a></h4>
<p>The best known form of database is the <em>relational database</em>, which organizes tabular data into a set of tables with well-defined relationships between them.  They also enable queries using a query language, of which Structured Query Language (SQL) is a well-known example.  For me, SQL has always been one of those things that I use just infrequently enough that I never actually learn it.  Fortunately, LLMs are very good at translating natural language into SQL queries, lowering the barrier of entry for researchers who want to try out database storage.</p>
<section id="acid">
<h5><a class="toc-backref" href="#id28">ACID</a><a class="headerlink" href="#acid" title="Permalink to this heading">#</a></h5>
<p>One important feature of a relational databases is that they generally implement features to ensure data integrity and reliability.  These are often referred to as the <em>ACID</em> properties:</p>
<ul class="simple">
<li><p><em>Atomicity</em>: Transactions are atomic, meaning that they either succeed or they don’t: there are no partial transactions.  If a transaction fails then the database remains in the state it was in prior to the failed transaction.</p></li>
<li><p><em>Consistency</em>: A transaction is required to leave the database in a valid state.  Any transaction that attempts to violate any constraints or rules (such as the requirement that every measurement includes a valid device key) will be rejected.</p></li>
<li><p><em>Isolation</em>: Individual transactions do not interfere with one another, such that they would never see any partial changes due to another transaction.  Thus, one can submit many transactions at once and be sure that they will each be processed correctly without interference from others.</p></li>
<li><p><em>Durability</em>:  Transactions are durable, such that once they are written they will be permanent despite failures such as power outages or system crashes (as long as the server is not damaged).</p></li>
</ul>
<p>The adherence of relational database systems to these principles helps ensure the integrity of scientific data, in comparison to the use of flat files which do not necessarily achieve these goals.</p>
</section>
<section id="analytic-databases">
<h5><a class="toc-backref" href="#id29">Analytic databases</a><a class="headerlink" href="#analytic-databases" title="Permalink to this heading">#</a></h5>
<p>There is a particular kind of relational database known as an <em>analytic database</em> that is specialized for operations that work across many rows in the database, rather than the focus on individual records in a standard relational database.  One widely-used analytic database in the Python ecosystem is <a class="reference external" href="https://duckdb.org/">DuckDB</a>, which supports very fast operations on large datasets, and integrates well with Pandas and other tools. Unlike traditional relational database systems, it doesn’t require any specialized server setup.</p>
</section>
</section>
<section id="nosql-databases">
<h4><a class="toc-backref" href="#id30">NoSQL databases</a><a class="headerlink" href="#nosql-databases" title="Permalink to this heading">#</a></h4>
<p>While relational databases were the only game in town for many years, there are now a number of other kinds of database, collectively referred to as <em>NoSQL</em> databases because they use non-relational data models (like documents, graphs, or key-value pairs) rather than the tables with fixed schemas that define a standard relational database.  Each of these can be very useful for specific problems that match the database’s strengths. Some, but not all, NoSQL databases are ACID compliant.  It’s important to ensure that one has the right safeguards in place when using a non-compliant database system.</p>
<p>Here I provide a brief overview of several popular forms of NoSQL databases; see the Appendix to this chapter for a full-stack example that combines several of these.</p>
<section id="document-stores">
<h5><a class="toc-backref" href="#id31">Document stores</a><a class="headerlink" href="#document-stores" title="Permalink to this heading">#</a></h5>
<p>A <em>document store</em> is basically what it sounds like: a system into which one can dump documents and then query them. I think of this as in some ways the opposite of a SQL database.  In the SQL database, most of the work comes in designing the database schema, which will determine up front how the data are represented; after that, querying is fairly straightforward.  In a document store, one can insert documents with varying structure into the database without the need for a predefined schema. The hard work in a document store comes in figuring out how to structure queries and indexes effectively, especially when the structure of the data varies.  For most of the tasks where I have used databases I have chosen document stores over relational databases because of the flexibility that they offer.</p>
</section>
<section id="graph-databases">
<h5><a class="toc-backref" href="#id32">Graph databases</a><a class="headerlink" href="#graph-databases" title="Permalink to this heading">#</a></h5>
<p>A graph database is built to efficiently store and query graph-structured data.  These are data where the primary features of interest for querying are the relationships between entities, rather than the entities themselves. Scientific examples could include social network relationships, protein-protein interactions, or connections between neurons or brain areas.  Graph databases are particularly good at finding multi-step relationships within the graph, which are much more difficult to find using a relational database or document store.  A commonly used graph database is Neo4j, which has its own query language called <em>Cypher</em> that is specifically designed for queries on graph structure.</p>
</section>
<section id="vector-databases">
<h5><a class="toc-backref" href="#id33">Vector databases</a><a class="headerlink" href="#vector-databases" title="Permalink to this heading">#</a></h5>
<p>A relatively recent entry into the database field is the <em>vector database</em>, which is optimized for finding similar numerical vectors.  These have become essential in the context of AI, because they can be used to quickly find similar items that are embedded in a vector space, typically using neural networks.  These items can include text documents, images, molecular structures, or any other kind of data that can be embedded in a vector space.  Vector databases differ in that can return ranked similarity ratings in addition to a discrete set of matches, and thus they are best for performing analyses that involve similarity-based search.</p>
</section>
</section>
</section>
</section>
<section id="managing-original-data">
<h2><a class="toc-backref" href="#id34">Managing original data</a><a class="headerlink" href="#managing-original-data" title="Permalink to this heading">#</a></h2>
<p>By <em>original</em> data I mean data that were obtained by the researcher from another source, such as from a recording device or by manual recording.  These are the data that, if lost, would constitute an irretrievable loss of the scientific record. As such, these data should be protected in a way that is different from <em>derivative</em> data that are obtained via processing of the original data.</p>
<section id="immutable-storage">
<h3><a class="toc-backref" href="#id35">Immutable storage</a><a class="headerlink" href="#immutable-storage" title="Permalink to this heading">#</a></h3>
<p>It is important to ensure that the original data are not modified, either accidentally or intentionally.  This can be achieved by setting the permissions on the files as read-only, though it is important to note that a user with superuser privileges could still make changes to the data.  For this reason, it is also important to store information that allows the validation of each file as matching its original.  This can be easily achieved by computing a <em>checksum</em> for each file and storing it separately. A checksum is a mathematical function of the file contents, which changes if any of the data in the file are changed and thus can serve as a “fingerprint” for the file contents:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>➤  echo &quot;file contents&quot; &gt; file1.txt
➤  echo &quot;file content&quot; &gt; file2.txt
➤  diff file1.txt file2.txt
1c1
&lt; file contents
---
&gt; file content

➤  md5sum file1.txt
081404b3d2ae5bf599add15b7445ac07  file1.txt
➤  md5sum file2.txt                                                       1 ↵
186e4cee4e00635b35be4236193f33fb  file2.txt
</pre></div>
</div>
<p>There are various types of checksums, such as MD5 (used in the example above) or SHA-1, any of which should be suitable for validating file identity.  However, the different methods produce different checksums so it’s important to document which method was used to create them.</p>
</section>
<section id="backup">
<h3><a class="toc-backref" href="#id36">Backup</a><a class="headerlink" href="#backup" title="Permalink to this heading">#</a></h3>
<p>Disasters can occur that can render data irretrievable, from a major flood or earthquake to a cup of coffee spilled onto a laptop.  It is essential to maintain a backup of the original data for disaster recovery purposes.  This backup should be located on a system that is geographically separate from the main storage, such as a cloud server.</p>
<p>Many researchers store their data using RAID systems (which stands for “redundant array of independent disks”), which can provide some degree of resilience against disk failure.  Depending on the RAID configuration, these systems can survive the failure of one or more individual disks without data loss. However, storage on a RAID system is not a suitable replacement for backup, as these systems can still fail (e.g. due to a fire or flood that damages multiple disks).</p>
</section>
</section>
<section id="data-access">
<h2><a class="toc-backref" href="#id37">Data access</a><a class="headerlink" href="#data-access" title="Permalink to this heading">#</a></h2>
<p>Access to research data within a research group should operate by the <em>Principle of Least Privilege</em>, which is a general approach to computer security that states that any user should have only enough privileges to perform their intended actions, and no more. While this is most relevant to multi-user systems, it is often relevant even to systems with only a single user. With regard to data access, this principle has two important implications.  First, any particular dataset should be accessible only to users who have permission and need to use those data. Second, if data are meant to be accessed by a user but not modified by that user, then the user should have read-only access to the data.</p>
<p>Even when a user may have a need to modify data, it often makes sense to set the data as read-only, so that any modifications require an explicit permissions change before the modifications can be made. This can help prevent accidental changes or data deletion, even on a single-user system.</p>
</section>
<section id="data-formats-and-file-types">
<h2><a class="toc-backref" href="#id38">Data formats and file types</a><a class="headerlink" href="#data-formats-and-file-types" title="Permalink to this heading">#</a></h2>
<p>There is a wide range of different data formats and file types used across science.  Here I will cover some of the most widely used formats and file types, realizing that there are many areas of science that use highly specialized formats/file types that I can’t cover in depth here.</p>
<section id="tabular-data">
<h3><a class="toc-backref" href="#id39">Tabular data</a><a class="headerlink" href="#tabular-data" title="Permalink to this heading">#</a></h3>
<p>Tabular data are loosely defined as data stored in rows and columns, as in a spreadsheet.   A <em>data frame</em> is a particular representation of tabular data, in which each column in the dataset has a label and each row has an <em>index</em> value that refers to that row.  The packages supporting data frames (such as <code class="docutils literal notranslate"><span class="pre">pandas</span></code> in Python) generally provide a set of operations that can be performed on the data frame, such as filtering, sorting, merging, or pivoting.</p>
<section id="long-wide-and-tidy-tabular-data">
<h4><a class="toc-backref" href="#id40">Long, wide, and tidy tabular data</a><a class="headerlink" href="#long-wide-and-tidy-tabular-data" title="Permalink to this heading">#</a></h4>
<p>There are multiple ways to organize data within a tabular dataset, reflecting what each column and row refer to.  This distinction is often referred to as <em>long</em> versus <em>wide</em> data, though in reality there is really a spectrum of organization between these extremes. <em>Wide data</em> generally refers to data where each row refers to a single observational unit (such as a one site, person, or planet), and each column refers to different variables measured for that unit. For example, let’s say that we had measurements of height, weight, and blood pressure from three individuals.  A wide representation of these data would have one row per individual, with an identifier column identifying the individual and separate columns for each of the measurements:</p>
<div class="pst-scrollable-table-container"><table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-right head"><p>id</p></th>
<th class="text-right head"><p>height</p></th>
<th class="text-right head"><p>weight</p></th>
<th class="text-right head"><p>blood_pressure</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-right"><p>1</p></td>
<td class="text-right"><p>170</p></td>
<td class="text-right"><p>70</p></td>
<td class="text-right"><p>120</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>2</p></td>
<td class="text-right"><p>180</p></td>
<td class="text-right"><p>80</p></td>
<td class="text-right"><p>130</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>3</p></td>
<td class="text-right"><p>175</p></td>
<td class="text-right"><p>75</p></td>
<td class="text-right"><p>125</p></td>
</tr>
</tbody>
</table>
</div>
<p><em>Long data</em> generally refers to data where different variables measured for a unit are spread across rows.  In this case, there are separate columns that specifies the variable being measured, the value of the variable for that unit, and the identity of the unit being measured.</p>
<div class="pst-scrollable-table-container"><table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-right head"><p>id</p></th>
<th class="text-left head"><p>measurement</p></th>
<th class="text-right head"><p>value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-right"><p>1</p></td>
<td class="text-left"><p>height</p></td>
<td class="text-right"><p>170</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>2</p></td>
<td class="text-left"><p>height</p></td>
<td class="text-right"><p>180</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>3</p></td>
<td class="text-left"><p>height</p></td>
<td class="text-right"><p>175</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>1</p></td>
<td class="text-left"><p>weight</p></td>
<td class="text-right"><p>70</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>2</p></td>
<td class="text-left"><p>weight</p></td>
<td class="text-right"><p>80</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>3</p></td>
<td class="text-left"><p>weight</p></td>
<td class="text-right"><p>75</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>1</p></td>
<td class="text-left"><p>blood_pressure</p></td>
<td class="text-right"><p>120</p></td>
</tr>
<tr class="row-odd"><td class="text-right"><p>2</p></td>
<td class="text-left"><p>blood_pressure</p></td>
<td class="text-right"><p>130</p></td>
</tr>
<tr class="row-even"><td class="text-right"><p>3</p></td>
<td class="text-left"><p>blood_pressure</p></td>
<td class="text-right"><p>125</p></td>
</tr>
</tbody>
</table>
</div>
<p>A related concept is the notion of <em>tidy data</em>, popularized by Hadley Wickham who is leader in the <em>R</em> language community.  While it is often associated with long data, the concept of tidy data actually refers to the meaning of the data rather than its shape.  Tidy data has three features, as specified by <span id="id3">[<a class="reference internal" href="bibliography.html#id4" title="Hadley Wickham. Tidy data. Journal of Statistical Software, 59(10):1–23, 2014. URL: https://www.jstatsoft.org/index.php/jss/article/view/v059i10, doi:10.18637/jss.v059.i10.">Wickham, 2014</a>]</span>:</p>
<ul class="simple">
<li><p>each variable is a column</p></li>
<li><p>each observation is a row</p></li>
<li><p>each type of observational unit is a table.</p></li>
</ul>
<p>It’s easiest to understand these concepts by looking at some examples of datasets that <em>are not</em> tidy, following the examples laid out by <span id="id4">[<a class="reference internal" href="bibliography.html#id4" title="Hadley Wickham. Tidy data. Journal of Statistical Software, 59(10):1–23, 2014. URL: https://www.jstatsoft.org/index.php/jss/article/view/v059i10, doi:10.18637/jss.v059.i10.">Wickham, 2014</a>]</span></p>
<section id="column-headers-are-values-not-variable-names">
<h5><a class="toc-backref" href="#id41">Column headers are values, not variable names</a><a class="headerlink" href="#column-headers-are-values-not-variable-names" title="Permalink to this heading">#</a></h5>
<p>Sometimes data are spread across columns where each column refers to a different value of the variable.  For example, the following table shows cancer pathology data from three hospitals, with different columns quantifying the number of samples falling into each of four different tumor stages:</p>
<div class="pst-scrollable-table-container"><table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-left head"><p>site</p></th>
<th class="text-right head"><p>Stage1</p></th>
<th class="text-right head"><p>Stage2</p></th>
<th class="text-right head"><p>Stage3</p></th>
<th class="text-right head"><p>Stage4</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>46</p></td>
<td class="text-right"><p>27</p></td>
<td class="text-right"><p>38</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>37</p></td>
<td class="text-right"><p>48</p></td>
<td class="text-right"><p>31</p></td>
<td class="text-right"><p>27</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>25</p></td>
<td class="text-right"><p>37</p></td>
<td class="text-right"><p>33</p></td>
<td class="text-right"><p>23</p></td>
</tr>
</tbody>
</table>
</div>
<p>There are really three different variables represented in this table: Site, Stage, and frequency.  What we really want is to have three columns, representing those three variables.  We can achieve this using the <code class="docutils literal notranslate"><span class="pre">melt</span></code> function from <code class="docutils literal notranslate"><span class="pre">pandas</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df_tidy</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;site&quot;</span><span class="p">],</span> 
    <span class="n">var_name</span><span class="o">=</span><span class="s2">&quot;Stage&quot;</span><span class="p">,</span> <span class="n">value_name</span><span class="o">=</span><span class="s2">&quot;Frequency&quot;</span><span class="p">)</span>
<span class="c1"># make stage an integer</span>
<span class="n">df_tidy</span><span class="o">.</span><span class="n">Stage</span> <span class="o">=</span> <span class="n">df_tidy</span><span class="o">.</span><span class="n">Stage</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;Stage&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_tidy</span><span class="o">.</span><span class="n">to_markdown</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
<div class="pst-scrollable-table-container"><table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-left head"><p>site</p></th>
<th class="text-right head"><p>Stage</p></th>
<th class="text-right head"><p>Frequency</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>46</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>37</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>25</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>27</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>48</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>37</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-right"><p>38</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-right"><p>31</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-right"><p>33</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>27</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>23</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="multiple-variables-are-stored-in-one-column">
<h5><a class="toc-backref" href="#id42">Multiple variables are stored in one column</a><a class="headerlink" href="#multiple-variables-are-stored-in-one-column" title="Permalink to this heading">#</a></h5>
<p>This pattern takes the previous one a step further, by defining columns based on the values of more than one variable.  For example, let’s say that there data for both lung and prostate cancer:</p>
<div class="pst-scrollable-table-container"><table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-left head"><p>site</p></th>
<th class="text-right head"><p>Stg1Lng</p></th>
<th class="text-right head"><p>Stg2Lng</p></th>
<th class="text-right head"><p>Stg3Lng</p></th>
<th class="text-right head"><p>Stg4Lng</p></th>
<th class="text-right head"><p>Stg1Prs</p></th>
<th class="text-right head"><p>Stg2Prs</p></th>
<th class="text-right head"><p>Stg3Prs</p></th>
<th class="text-right head"><p>Stg4Prs</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>44</p></td>
<td class="text-right"><p>32</p></td>
<td class="text-right"><p>21</p></td>
<td class="text-right"><p>28</p></td>
<td class="text-right"><p>48</p></td>
<td class="text-right"><p>24</p></td>
<td class="text-right"><p>44</p></td>
<td class="text-right"><p>34</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>22</p></td>
<td class="text-right"><p>30</p></td>
<td class="text-right"><p>22</p></td>
<td class="text-right"><p>45</p></td>
<td class="text-right"><p>26</p></td>
<td class="text-right"><p>49</p></td>
<td class="text-right"><p>31</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>48</p></td>
<td class="text-right"><p>40</p></td>
<td class="text-right"><p>26</p></td>
<td class="text-right"><p>33</p></td>
<td class="text-right"><p>46</p></td>
<td class="text-right"><p>33</p></td>
<td class="text-right"><p>24</p></td>
<td class="text-right"><p>25</p></td>
</tr>
</tbody>
</table>
</div>
<p>In this example, each value column represents a combination of stage and type of cancer.  We can tidy this by first melting the data frame, and then splitting the combined column names into separate variables for Stage and Cancer type:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># tidy this, first by melting</span>
<span class="n">df_tidy</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;site&quot;</span><span class="p">],</span> 
    <span class="n">var_name</span><span class="o">=</span><span class="s2">&quot;Stage_Cancer&quot;</span><span class="p">,</span> <span class="n">value_name</span><span class="o">=</span><span class="s2">&quot;Freq&quot;</span><span class="p">)</span>
<span class="c1"># then split Stage_Cancer into two columns</span>
<span class="n">df_tidy</span><span class="p">[[</span><span class="s2">&quot;Stage&quot;</span><span class="p">,</span> <span class="s2">&quot;Cancer&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">df_tidy</span><span class="o">.</span><span class="n">Stage_Cancer</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Stg(\d)(\w</span><span class="si">{3}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="k">del</span> <span class="n">df_tidy</span><span class="p">[</span><span class="s2">&quot;Stage_Cancer&quot;</span><span class="p">]</span>
<span class="c1"># make Stage an integer</span>
<span class="n">df_tidy</span><span class="o">.</span><span class="n">Stage</span> <span class="o">=</span> <span class="n">df_tidy</span><span class="o">.</span><span class="n">Stage</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="c1"># reorder columns</span>
<span class="n">df_tidy</span> <span class="o">=</span> <span class="n">df_tidy</span><span class="p">[[</span><span class="s2">&quot;site&quot;</span><span class="p">,</span> <span class="s2">&quot;Stage&quot;</span><span class="p">,</span> <span class="s2">&quot;Cancer&quot;</span><span class="p">,</span> <span class="s2">&quot;Freq&quot;</span><span class="p">]]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_tidy</span><span class="o">.</span><span class="n">to_markdown</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
<div class="pst-scrollable-table-container"><table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-left head"><p>site</p></th>
<th class="text-right head"><p>Stage</p></th>
<th class="text-left head"><p>Cancer</p></th>
<th class="text-right head"><p>Freq</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>44</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>22</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>48</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>30</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>40</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>21</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>22</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>26</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>28</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>45</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>33</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>48</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>26</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>46</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>24</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>49</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>33</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>44</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>31</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>24</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H1</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>34</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H2</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H3</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>25</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="variables-are-stored-in-both-rows-and-columns">
<h5><a class="toc-backref" href="#id43">Variables are stored in both rows and columns</a><a class="headerlink" href="#variables-are-stored-in-both-rows-and-columns" title="Permalink to this heading">#</a></h5>
<p>We could also have some variables denoted by their own column with others split across columns:</p>
<div class="pst-scrollable-table-container"><table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-left head"><p>site</p></th>
<th class="text-left head"><p>Cancer</p></th>
<th class="text-right head"><p>Stage1</p></th>
<th class="text-right head"><p>Stage2</p></th>
<th class="text-right head"><p>Stage3</p></th>
<th class="text-right head"><p>Stage4</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>H1</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>44</p></td>
<td class="text-right"><p>32</p></td>
<td class="text-right"><p>21</p></td>
<td class="text-right"><p>28</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H1</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>48</p></td>
<td class="text-right"><p>24</p></td>
<td class="text-right"><p>44</p></td>
<td class="text-right"><p>34</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H2</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>22</p></td>
<td class="text-right"><p>30</p></td>
<td class="text-right"><p>22</p></td>
<td class="text-right"><p>45</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H2</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>26</p></td>
<td class="text-right"><p>49</p></td>
<td class="text-right"><p>31</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H3</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>48</p></td>
<td class="text-right"><p>40</p></td>
<td class="text-right"><p>26</p></td>
<td class="text-right"><p>33</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H3</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>46</p></td>
<td class="text-right"><p>33</p></td>
<td class="text-right"><p>24</p></td>
<td class="text-right"><p>25</p></td>
</tr>
</tbody>
</table>
</div>
<p>Here we can melt the data frame to collect the Stage columns:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># gather to make it tidy</span>
<span class="n">df_both_tidy</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">df_both</span><span class="p">,</span> <span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;site&quot;</span><span class="p">,</span> <span class="s2">&quot;Cancer&quot;</span><span class="p">],</span> 
    <span class="n">var_name</span><span class="o">=</span><span class="s2">&quot;Stage&quot;</span><span class="p">,</span> <span class="n">value_name</span><span class="o">=</span><span class="s2">&quot;Frequency&quot;</span><span class="p">)</span>
<span class="c1"># make Stage an integer</span>
<span class="n">df_both_tidy</span><span class="o">.</span><span class="n">Stage</span> <span class="o">=</span> <span class="n">df_both_tidy</span><span class="o">.</span><span class="n">Stage</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;Stage&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_both_tidy</span><span class="o">.</span><span class="n">to_markdown</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
<div class="pst-scrollable-table-container"><table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-left head"><p>site</p></th>
<th class="text-left head"><p>Cancer</p></th>
<th class="text-right head"><p>Stage</p></th>
<th class="text-right head"><p>Frequency</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>H1</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>44</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H1</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>48</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H2</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>22</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H2</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>26</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H3</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>48</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H3</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>46</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H1</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H1</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>24</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H2</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>30</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H2</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>49</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H3</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>40</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H3</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>2</p></td>
<td class="text-right"><p>33</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H1</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-right"><p>21</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H1</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-right"><p>44</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H2</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-right"><p>22</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H2</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-right"><p>31</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H3</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-right"><p>26</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H3</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>3</p></td>
<td class="text-right"><p>24</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H1</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>28</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H1</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>34</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H2</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>45</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H2</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>32</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>H3</p></td>
<td class="text-left"><p>Lng</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>33</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>H3</p></td>
<td class="text-left"><p>Prs</p></td>
<td class="text-right"><p>4</p></td>
<td class="text-right"><p>25</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="single-type-of-observational-unit-spread-across-multiple-tables">
<h5><a class="toc-backref" href="#id44">Single type of observational unit spread across multiple tables</a><a class="headerlink" href="#single-type-of-observational-unit-spread-across-multiple-tables" title="Permalink to this heading">#</a></h5>
<p>Sometimes we might have different data frames for each observation unit, such as a different data frame for each hospital in our example. To fix this we can simple merge the data frames by concatenating them:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df_merged</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">,</span> <span class="n">df3</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="tabular-file-formats">
<h4><a class="toc-backref" href="#id45">Tabular file formats</a><a class="headerlink" href="#tabular-file-formats" title="Permalink to this heading">#</a></h4>
<p>The most common file formats are <em>comma-separated value</em> (CSV) or <em>tab-separated value</em> (TSV) files.  Both of these have the benefit of being represented in plain text, so their contents can be easily examined without any special software.  I generally prefer to use tabs rather than commas as the separator (or <em>delimiter</em>), primarily because they can more easily naturally represent longer pieces of text that may include commas. These can also be represented using CSV, but they require additional processing in order to <em>escape</em> the commas within the text so that they are not interpreted as delimiters.</p>
<p>Text file formats like CSV and TSV are nice for their ease of interpretability, but they are highly inefficient for large data compared to optimized file formats, such as the <em>Parquet</em> format.  To see this in action, I loaded a brain image and saved all of the non-zero data points (857,785 to be exact) to a data frame, which I then saved to CSV and Parquet formats; see <a class="reference internal" href="#src/BetterCodeBetterScience/data_management.ipynb"><span class="xref myst">the management notebook</span></a> for details.  Looking at the resulting files, we can see that the Parquet file is only about 20% the size of the CSV file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>du<span class="w"> </span>-sk<span class="w"> </span>/tmp/brain_tabular.*
<span class="m">19464</span><span class="w">	</span>/tmp/brain_tabular.csv
<span class="m">3804</span><span class="w">	</span>/tmp/brain_tabular.parquet
</pre></div>
</div>
<p>When we look at the amount of time needed to load these files, we see an even stronger edge for the Parquet format. Because the loading times can vary due to other activity on the system, we load each 100 times to get an average load time:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="c1"># time loading of each format</span>
<span class="c1"># load 100 times to get average loading time of each format</span>

<span class="n">nreps</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nreps</span><span class="p">):</span>
    <span class="n">df_csv</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/tmp/brain_tabular.csv&#39;</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">csv_time</span> <span class="o">=</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span><span class="o">/</span><span class="n">nreps</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CSV load time: </span><span class="si">{</span><span class="n">csv_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nreps</span><span class="p">):</span>
    <span class="n">df_parquet</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="s1">&#39;/tmp/brain_tabular.parquet&#39;</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">parquet_time</span> <span class="o">=</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span><span class="o">/</span><span class="n">nreps</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parquet load time: </span><span class="si">{</span><span class="n">parquet_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;ratio </span><span class="si">{</span><span class="n">csv_time</span><span class="o">/</span><span class="n">parquet_time</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CSV</span> <span class="n">load</span> <span class="n">time</span><span class="p">:</span> <span class="mf">0.0719</span> <span class="n">seconds</span>
<span class="n">Parquet</span> <span class="n">load</span> <span class="n">time</span><span class="p">:</span> <span class="mf">0.0082</span> <span class="n">seconds</span>
<span class="n">ratio</span> <span class="mf">8.77</span>
</pre></div>
</div>
<p>Here we see that loading the CSV file takes almost 9 times as long as the Parquet file.  For a single file of this size this is not a meaningful difference in times, but for projects involving many files or much larger files the difference in loading times could become a real game-changer.</p>
</section>
<section id="russ-s-first-law-of-tabular-data-management">
<h4><a class="toc-backref" href="#id46">Russ’s First Law of Tabular Data Management</a><a class="headerlink" href="#russ-s-first-law-of-tabular-data-management" title="Permalink to this heading">#</a></h4>
<blockquote>
<div><p>“Don’t use spreadsheets to manage scientific data.”</p>
</div></blockquote>
<p>Spreadsheet software such as Microsoft Excel is commonly used by researchers for all sorts of data management and processing operations.  Why are spreadsheets problematic?</p>
<ul class="simple">
<li><p>They encourage manual manipulation of the data, which makes the operations non-reproducible by definition.</p></li>
<li><p>Spreadsheet tools will often automatically format data, sometimes changing things in important but unwanted ways.  For example, gene names such as “SEPT2” and “MARCH1” are converted to dates by Microsoft Excel, and some accession numbers (e.g. “2310009E13”) are converted to floating point numbers.  An analysis of published genomics papers <span id="id5">[<a class="reference internal" href="bibliography.html#id7" title="Mark Ziemann, Yotam Eren, and Assam El-Osta. Gene name errors are widespread in the scientific literature. Genome Biol, 17(1):177, Aug 2016. doi:10.1186/s13059-016-1044-7.">Ziemann <em>et al.</em>, 2016</a>]</span> found that roughly twenty percent of supplementary gene lists created using Excel contained errors in gene names due to these conversions.</p></li>
<li><p>It is very easy to make errors when performing operations on a spreadsheet, and these errors can often go unnoticed.  A well known example occurred in the paper  <a class="reference external" href="https://www.nber.org/papers/w15639">“Growth in the time of debt”</a> by the prominent economists Carmen Reinhart and Kenneth Rogoff. This paper claimed to have found that high levels of national debt led to decreased economic growth, and was used as a basis for promoting austerity programs after the 2008 financial crisis.  However, <a class="reference external" href="https://academic.oup.com/cje/article/38/2/257/1714018">researchers subsequently discovered</a> that the authors had made an error in their Excel spreadsheet, excluding data from several countries; when the full data were used, the relationship between growth and debt became much weaker.</p></li>
<li><p>Spreadsheet software can sometimes have limitations that can cause problems.  For example, the use of an outdated Microsoft Excel file format (.xls) <a class="reference external" href="https://www.bbc.com/news/technology-54423988">caused underreporting of COVID-19 cases</a> due to limitations on the number of rows in that file format, and the lack of any warnings when additional rows in the imported data files were ignored.</p></li>
<li><p>Spreadsheets do not easily lend themselves to version control and change tracking, although some spreadsheet tools (such as Google Sheets) do provide the ability to clearly label versions of the data.</p></li>
</ul>
<p>I will occasionally use Microsoft Excel to examine a data file, but I think that spreadsheet tools should <em>almost never</em> be used as part of a scientific data workflow.</p>
</section>
</section>
<section id="multidimensional-array-data">
<h3><a class="toc-backref" href="#id47">Multidimensional array data</a><a class="headerlink" href="#multidimensional-array-data" title="Permalink to this heading">#</a></h3>
<p>Many forms of data are represented as multidimensional arrays.  For example, many forms of microscopy data are represented as either two-dimensional (slice) or three-dimensional (volume) arrays, while dynamic imaging modalities are often represented as three- or four-dimensional data, with the first two or three dimensions representing space and the final dimension reflecting time.  Within Python these are generally processed using <code class="docutils literal notranslate"><span class="pre">numpy</span></code>, which efficiently processes large multidimensional arrays.  As an example, I loaded a four-dimensional brain template, where the first three dimensions are spatial and the final dimension reflects 512 different components that define a probabilistic atlas of the brain.  After loading the data into a <code class="docutils literal notranslate"><span class="pre">numpy</span></code> array, we can see its shape:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>(91, 109, 91, 512)
</pre></div>
</div>
<p>In this case, the first three dimensions are spatial (representing the left/right, front/back, and up/down axes of the brain) and the final dimension represents timepoints.  We can also use the <code class="docutils literal notranslate"><span class="pre">imshow</span></code> function from <code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot</span></code> to view a two-dimensional slice of the image at a particular timepoint:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1"># view z==50 at timepoint 5</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img src="images/difumo_example.png" alt="2d image example" width="500px">
<section id="multidimensional-array-file-formats">
<h4><a class="toc-backref" href="#id48">Multidimensional array file formats</a><a class="headerlink" href="#multidimensional-array-file-formats" title="Permalink to this heading">#</a></h4>
<p>A common file format for array data in Python is the native Numpy format, which is known by its extension, <code class="docutils literal notranslate"><span class="pre">.npy</span></code>.  This file format has a number of benefits for Python users:</p>
<ul class="simple">
<li><p>It is very fast to both read and write files</p></li>
<li><p>It supports <em>memory mapping</em>, which allows portions of the file to be read without loading the entire file</p></li>
<li><p>It has perfect fidelity and maintains exact data types</p></li>
<li><p>It is very easy to use (<code class="docutils literal notranslate"><span class="pre">np.load()</span></code> to load and <code class="docutils literal notranslate"><span class="pre">np.save()</span></code> to save).</p></li>
</ul>
<p>However, the <code class="docutils literal notranslate"><span class="pre">.npy</span></code> format also has a number of drawbacks for scientific data:</p>
<ul class="simple">
<li><p>It is harder for non-Numpy users to work with, requiring specialized libraries to read in languages other than Python.</p></li>
<li><p>It does not compress the data, so files can be much larger than a compressed file format. This can become very important when working with large sparse datasets.</p></li>
<li><p>It doesn’t support storage of metadata alongside the data</p></li>
</ul>
<p>There are several other commonly used standard file formats for array data; we will focus on <em>HDF5</em> and <em>Zarr</em>.  HDF5 is a longstanding format for storage of large datasets, which is supported by nearly all programming languages. It has built-in support for compression, and allows access to specific chunks without loading the entire dataset.  However, may researchers (at least within the Python ecosystem) are moving towards the Zarr format, which stores data in a set of smaller chunk files rather than a single large file as in HDF5.  Zarr has several advantages over HDF5:</p>
<ul class="simple">
<li><p>Zarr is much more efficient for cloud storage, since only the specific chunk file needs to be accessed</p></li>
<li><p>Zarr is simpler than HDF5, and has a more Pythonic interface</p></li>
<li><p>Zarr makes it very easy to add new data to a file, which can be more difficult in HDF5</p></li>
</ul>
<p>Let’s use the data from above as an example. This is a dataset that is highly sparse; after thresholding to remove very small values, only about 0.1% of the values are nonzero.  This means that we should be able to get a high degree of compression for this dataset, given the redundancy of the data.  Let’s first save the data to a .npy file and look at its (uncompressed) size:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>np.save(&#39;/tmp/difumo.npy&#39;, data)
!du -sm /tmp/difumo.npy
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">3526</span><span class="w">	</span>/tmp/difumo.npy
</pre></div>
</div>
<p>That’s about 3.5 gigabytes.  Now let’s save it to HDF5:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>import h5py
with h5py.File(&#39;/tmp/difumo.h5&#39;, &#39;w&#39;) as f:
    f.create_dataset(&#39;difumo&#39;, data=data, compression=&#39;gzip&#39;)
!du -sm /tmp/difumo.h5
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">10</span><span class="w">	</span>/tmp/difumo.h5
</pre></div>
</div>
<p>Due to the compression by HDF5, the data file is about 350 times smaller with HDF5! We can also look at the same with Zarr:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>import zarr
zarr_data = zarr.open(&#39;/tmp/difumo.zarr&#39;, mode=&#39;w&#39;, shape=data.shape, dtype=data.dtype)
zarr_data[:] = data
!du -sm /tmp/difumo.zarr
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="m">5</span><span class="w">	</span>/tmp/difumo.zarr
</pre></div>
</div>
<p>This shows that Zarr obtains even more compression than HDF5, each using its default compression method; note that it might be possible to get better compression using custom compression methods for each.  We can also compare the time needed to load each of the files; because of the relatively longer loading time for these files, we only perform 10 repetitions in this example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nreps</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">for</span> <span class="n">ext</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;npy&#39;</span><span class="p">,</span> <span class="s1">&#39;h5&#39;</span><span class="p">,</span> <span class="s1">&#39;zarr&#39;</span><span class="p">]:</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;/tmp/difumo.</span><span class="si">{</span><span class="n">ext</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="k">if</span> <span class="n">ext</span> <span class="o">==</span> <span class="s1">&#39;npy&#39;</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nreps</span><span class="p">):</span>
            <span class="n">data_loaded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">ext</span> <span class="o">==</span> <span class="s1">&#39;h5&#39;</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nreps</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">data_loaded</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;difumo&#39;</span><span class="p">][:]</span>
    <span class="k">elif</span> <span class="n">ext</span> <span class="o">==</span> <span class="s1">&#39;zarr&#39;</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nreps</span><span class="p">):</span>
            <span class="n">zarr_data</span> <span class="o">=</span> <span class="n">zarr</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
            <span class="n">data_loaded</span> <span class="o">=</span> <span class="n">zarr_data</span><span class="p">[:]</span>
    <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">avg_load_time</span> <span class="o">=</span> <span class="p">(</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">/</span> <span class="n">nreps</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Average loading time for </span><span class="si">{</span><span class="n">ext</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">avg_load_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Average loading time for npy: 0.451627 seconds
Average loading time for h5: 3.138907 seconds
Average loading time for zarr: 0.745648 seconds
</pre></div>
</div>
<p>This shows that Zarr is slightly slower than the native <code class="docutils literal notranslate"><span class="pre">numpy</span></code> file load, but much faster than HDF5.</p>
<p>I would suggest that unless you have a strong need for HDF5 compatibility, that you use Zarr files to store large binary data files such as matrices.</p>
</section>
<section id="symmetrical-matrices">
<h4><a class="toc-backref" href="#id49">Symmetrical matrices</a><a class="headerlink" href="#symmetrical-matrices" title="Permalink to this heading">#</a></h4>
<p>It’s not uncommon to work with symmetrical matrices, such as correlation matrices.  Since the upper triangle and lower triangle of a symmetric matrix are simply transposed versions of one another, there is no need to save both - we can simply save either the upper or lower triangle.  Depending on the application, this may be a useful way to save space and loading time.</p>
</section>
</section>
<section id="network-graph-data">
<h3><a class="toc-backref" href="#id50">Network/graph data</a><a class="headerlink" href="#network-graph-data" title="Permalink to this heading">#</a></h3>
<p>A graph is a representation that includes a set of nodes along with a set of edges that represent connections between those nodes. In some cases these are unweighted (binary), such as whether two individuals are friends on a social network.  In other cases they are weighted, such as number of common friends that two people have on a social network.  Graphs also vary in being either undirected, such that the relationship is bidirectional between the two nodes, or directional, such as the relationship has a direction.  For example, friendship on a social network is an undirected relationship, whereas following on a social network is a directed relationship, since one person can follow the other, vice versa, or both.</p>
<p>One way to represent a graph is through a set of <em>adjacencies</em>, or connections.  Here is an example of a small social network, in which we generate a graph within the <code class="docutils literal notranslate"><span class="pre">networkx</span></code> package using a set of adjacencies:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>

<span class="n">friends</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;Bill&#39;</span><span class="p">,</span> <span class="s1">&#39;Sally&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;Bill&#39;</span><span class="p">,</span> <span class="s1">&#39;Mark&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;Bill&#39;</span><span class="p">,</span> <span class="s1">&#39;Elise&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;Mark&#39;</span><span class="p">,</span> <span class="s1">&#39;Elise&#39;</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;Mark&#39;</span><span class="p">,</span> <span class="s1">&#39;Lisa&#39;</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">(</span><span class="n">friends</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">edges</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>EdgeView([(&#39;Bill&#39;, &#39;Sally&#39;), (&#39;Bill&#39;, &#39;Mark&#39;), (&#39;Bill&#39;, &#39;Elise&#39;), (&#39;Mark&#39;, &#39;Elise&#39;), (&#39;Mark&#39;, &#39;Lisa&#39;)])
</pre></div>
</div>
<p>We can view this as a graph using the plotting functions in <code class="docutils literal notranslate"><span class="pre">networkx</span></code>:</p>
<img src="images/graph_example.png" alt="graph example" width="500px">
<p>Another way to represent a graph is via an <em>adjacency matrix</em>, which numerically represents the relations between nodes in the graph.  We can generate this from the <code class="docutils literal notranslate"><span class="pre">networkx</span></code> graph:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">adj_matrix</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">G</span><span class="p">)</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span>
<span class="n">labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">)</span>
<span class="n">adj_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">adj_matrix</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">adj_df</span><span class="o">.</span><span class="n">to_markdown</span><span class="p">())</span>
</pre></div>
</div>
<div class="pst-scrollable-table-container"><table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-left head"><p></p></th>
<th class="text-right head"><p>Bill</p></th>
<th class="text-right head"><p>Sally</p></th>
<th class="text-right head"><p>Mark</p></th>
<th class="text-right head"><p>Elise</p></th>
<th class="text-right head"><p>Lisa</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Bill</p></td>
<td class="text-right"><p>0</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>0</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Sally</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>0</p></td>
<td class="text-right"><p>0</p></td>
<td class="text-right"><p>0</p></td>
<td class="text-right"><p>0</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Mark</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>0</p></td>
<td class="text-right"><p>0</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>1</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Elise</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>0</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>0</p></td>
<td class="text-right"><p>0</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Lisa</p></td>
<td class="text-right"><p>0</p></td>
<td class="text-right"><p>0</p></td>
<td class="text-right"><p>1</p></td>
<td class="text-right"><p>0</p></td>
<td class="text-right"><p>0</p></td>
</tr>
</tbody>
</table>
</div>
<section id="graph-data-file-formats">
<h4><a class="toc-backref" href="#id51">Graph data file formats</a><a class="headerlink" href="#graph-data-file-formats" title="Permalink to this heading">#</a></h4>
<p>There are a number of different file formats for graph data, used variously across different software packages.  For example, the <code class="docutils literal notranslate"><span class="pre">networkx</span></code> package supports 13 different graph formats!  The decision about which format to use will likely depend on the specific software packages that you plan to use. I have had good luck with both <em>GraphML</em> and <em>Pajek</em> formats.</p>
<p>For large networks that are dense (i.e. networks where most connections are nonzero) or weighted (i.e. the edges have continuous weights) it might make more sense to save the network as an adjacency matrix, making sure to also save the associated node labels.  This allows taking advantage of the efficiency of formats like Zarr, though it will incur the overhead of having to load the adjacency matrix into the graph engine.</p>
</section>
</section>
<section id="specialized-data-formats">
<h3><a class="toc-backref" href="#id52">Specialized data formats</a><a class="headerlink" href="#specialized-data-formats" title="Permalink to this heading">#</a></h3>
<p>Many subfields of science have developed specific file formats for the data in their domain, such as:</p>
<ul class="simple">
<li><p>In genomics, there are multiple formats include <em>FASTQ</em> for raw sequencing reads, <em>BAM</em>/<em>SAM</em> for aligned sequence reads, <em>VCF</em> for variant calls, and <em>BED</em> for genomic coordinates</p></li>
<li><p>In structural biology, <em>PDB</em>/<em>mmCIF</em> for protein structures, and <em>MTZ</em> for X-ray diffraction data</p></li>
<li><p>In chemistry, <em>MOL</em>/<em>SDF</em> for molecular structures</p></li>
<li><p>In astronomy, <em>FITS</em> and <em>ASDF</em> for telescope data</p></li>
<li><p>In neuroscience, <em>NWB</em> and <em>NIfTI</em></p></li>
<li><p>In the earth sciences, there are numerous formats for various types of spatial data</p></li>
</ul>
<p>There is always a tension between using a domain-specific standard versus a general standard; the choice for any particular project will depend heavily on which software packages are being used for data analysis and what data formats they support, as well as the efficiency of the file formats.</p>
</section>
</section>
<section id="data-organization-schemes">
<h2><a class="toc-backref" href="#id53">Data organization schemes</a><a class="headerlink" href="#data-organization-schemes" title="Permalink to this heading">#</a></h2>
<p>It is essential to use a consistent data organization scheme for one’s research data. This is obvious when the data are shared with other researchers, but even if the data will never be shared with anyone else, good organization is essential when one looks back at one’s own data in the future.  Thus, good data organization is a gift to your future self!</p>
<p>In this section we discuss data organization. The most important principle of data organization is that the scheme should be easily understood consistently applied.  If a standard scheme exists in one’s field of research, then I would strongly suggest using that scheme, or at least adapting it to one’s local requirements.  A second important principle is that file and folder names should be machine readable. Increasingly we want to use automated tools to parse large datasets, and a machine-readable organization scheme (as I discuss below) is essential to doing this effectively.</p>
<section id="file-granularity">
<h3><a class="toc-backref" href="#id54">File granularity</a><a class="headerlink" href="#file-granularity" title="Permalink to this heading">#</a></h3>
<p>One common decision that we need to make when managing data is to save data in more smaller files versus fewer larger files.  The right answer to this question depends in part on how we will have to access the data.  If we only need to access a small portion of the data and we can easily determine which file to open to obtain those data, then it probably makes sense to save many small files.  However, if we need to combine data across many small files, then it likely makes sense to save the data as one large file.  For example, in the <a class="reference internal" href="#src/BetterCodeBetterScience/data_management.ipynb"><span class="xref myst">data management notebook</span></a> there is an example where we create a large (10000 x 100000) matrix of random numbers, and save them either to a single file or to a separate file for each row.  When loading these data, the loading of the single file is about 5 times faster than loading the individual files.</p>
<p>Another consideration about the number of files has to do with storage systems that are commonly used on high-performance computing systems.  On these systems, it is common to have separate quotas for total space used (e.g. in terabytes) as well as for the number of <em>inodes</em>, which are structures that store information about files and folders on a UNIX filesystem. Thus, generating many small files (e.g. millions) can sometimes cause problems on these systems. For this reason, we generally err on the side of generating fewer larger files versus more smaller files when working on high-performance computing systems.</p>
</section>
<section id="data-file-folder-naming-conventions">
<h3><a class="toc-backref" href="#id55">Data file/folder naming conventions</a><a class="headerlink" href="#data-file-folder-naming-conventions" title="Permalink to this heading">#</a></h3>
<p>From my standpoint, the most important consideration for naming of files and folders is the ability to automatically parse the file/folder names.  While there are may possible ways to do this, I prefer the approach used in the Brain Imaging Data Structure (BIDS), which our group was involved in developing <span id="id6">[<a class="reference internal" href="bibliography.html#id3" title="Krzysztof J Gorgolewski, Tibor Auer, Vince D Calhoun, R Cameron Craddock, Samir Das, Eugene P Duff, Guillaume Flandin, Satrajit S Ghosh, Tristan Glatard, Yaroslav O Halchenko, Daniel A Handwerker, Michael Hanke, David Keator, Xiangrui Li, Zachary Michael, Camille Maumet, B Nolan Nichols, Thomas E Nichols, John Pellman, Jean-Baptiste Poline, Ariel Rokem, Gunnar Schaefer, Vanessa Sochat, William Triplett, Jessica A Turner, Gaël Varoquaux, and Russell A Poldrack. The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. Sci Data, 3:160044, Jun 2016. doi:10.1038/sdata.2016.44.">Gorgolewski <em>et al.</em>, 2016</a>]</span>.  This is a standard for organizing a wide range of brain imaging data types, but the strategy behind the standard is applicable to almost any scientific data types.  The basic idea is to embed a set of key-value pairs in the name, along with a suffix that defines the data type along with a file type extension for files.  The schema looks like this:</p>
<p><code class="docutils literal notranslate"><span class="pre">&lt;key&gt;-&lt;value&gt;_&lt;key&gt;-&lt;value&gt;_suffix.extension</span></code></p>
<p>This is useful because it is very easy to automatically parse such a file name.  For example, let’s say we have a file called ‘sub-001_sess-1A_desc-Diffusion_fa.nii.gz’.  We can easily parse file names like this as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;sub-001_sess-1A_desc-Diffusion_fa.nii.gz&#39;</span>

<span class="k">def</span> <span class="nf">split_filename</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="n">extension</span> <span class="o">=</span> <span class="s1">&#39;.&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">filename</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">filename</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">key_values</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])}</span>
    <span class="n">key_values</span><span class="p">[</span><span class="s1">&#39;suffix&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">extension</span><span class="p">,</span> <span class="n">key_values</span>

<span class="n">extension</span><span class="p">,</span> <span class="n">key_values</span> <span class="o">=</span> <span class="n">split_filename</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">key_values</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;desc&#39;</span><span class="p">:</span> <span class="s1">&#39;Diffusion&#39;</span><span class="p">,</span> <span class="s1">&#39;sess&#39;</span><span class="p">:</span> <span class="s1">&#39;1A&#39;</span><span class="p">,</span> <span class="s1">&#39;sub&#39;</span><span class="p">:</span> <span class="s1">&#39;001&#39;</span><span class="p">,</span> <span class="s1">&#39;suffix&#39;</span><span class="p">:</span> <span class="s1">&#39;fa&#39;</span><span class="p">}</span>
</pre></div>
</div>
<p>This is very useful because it allows one to easily query a large set of files for particular key-value pairs, and also allows one to easily parse the key-value pairs for a particular file.</p>
<p>It’s worth nothing that using a naming scheme like this requires strict attention to naming hygiene.  In particular, it’s essential to ensure that the delimiter characters (“-” and “_”) don’t accidentally get used within the values.  For example, if one were using an analysis called “IS-RSA”, using this for the description (e.g. “‘sub-001_sess-1A_desc-IS-RSA_corr.zarr”) would cause file parsing to fail.</p>
</section>
</section>
<section id="metadata">
<h2><a class="toc-backref" href="#id56">Metadata</a><a class="headerlink" href="#metadata" title="Permalink to this heading">#</a></h2>
<p><em>Metadata</em> refers to “data about data”, and generally is meant to contain the information that is needed to interpret a dataset.  In principle, someone who obtains a dataset should be able to understand and reuse the data using only the metadata provided alongside the dataset. There are many different types of metadata that might be associated with a study, and it is usually necessary to decide how comprehensive to be in providing detailed metadata.  This will often rely upon the scientific expertise and judgment of the researcher, to determine which particular metadata would be essential for others to usefully interpret and reuse the data.</p>
<p>An important concept in metadata is the <em>ontology</em>. In the context of bioinformatics, an ontology is a structured representation of the entities that exist in a domain (defined by a <em>controlled vocabulary</em>) and the relationships between these entities. One of the best known examples in the Gene Ontology, which represents classes of biological entities including Molecular Functions, Cellular Components, and Biological Processes.  As an example, Figure <a class="reference internal" href="#go-fig"><span class="std std-numref">Figure 9</span></a></p>
<figure class="align-default" id="go-fig">
<a class="reference internal image-reference" href="_images/GO_node_of_ranvier.png"><img alt="Gene Ontology graph for node of Ranvier" src="_images/GO_node_of_ranvier.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 9 </span><span class="caption-text">An example of a Gene Ontology graph for the entity “node of Ranvier”, which is a component of a neuron.  Obtained from <a class="reference external" href="https://www.ebi.ac.uk/QuickGO/GTerm?id=GO:0033268">https://www.ebi.ac.uk/QuickGO/GTerm?id=GO:0033268</a>.</span><a class="headerlink" href="#go-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Ontologies are very useful for specifying metadata, because they allow us to know exactly what a particular entry in the metadata means, and thus allow us to establish link between equivalent entities across datasets.  For example, let’s say that a researcher wants to query a database for datasets related to insulin signaling in pancreatic beta cells in Type II diabetes, and that there are three relevant datasets in the database.  Without an ontology, each of the teams might use different terms to refer to these cells (such as “pancreatic beta cells”, “insulin-producing cells”, and “islet beta cells”), making it difficult to link the datasets. However, if each of the datasets were to include metadata linked to a specific ontology (in this case, the identifier <code class="docutils literal notranslate"><span class="pre">CL:0000169</span></code> from the Cell Ontolog, which refers to “type B pancreatic cell”), then it becomes much easier to find and link these datasets.  There are at present a broad range of ontologies available for nearly every scientific domain; the <a class="reference external" href="https://bioportal.bioontology.org/">BioPortal</a> project provides a tool to search across a wide range of existing ontologies.</p>
<section id="metadata-file-formats">
<h3><a class="toc-backref" href="#id57">Metadata file formats</a><a class="headerlink" href="#metadata-file-formats" title="Permalink to this heading">#</a></h3>
<p>An important feature of metadata is that it needs to be <em>machine-readable</em>, meaning that it is provided in a structured format that be automatically parsed by a computer.  Common formats are Extensible Markup Language (XML) and JavaScript Object Notation (JSON).  JSON is generally simpler and more human-readable, but it doesn’t natively provide the ability to define attributes for particular entries (such as the units of measurement) or link to ontologies.  An extension of JSON known as <em>JSON-LD</em> (JSON for Linked Data) provides support for the latter, by allowing links to controlled vocabularies.</p>
<p>For example, let’s say that I wanted to represent information about an author (myself) in JSON, which I might do like this:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Russell Poldrack&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;affiliation&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Stanford University&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;email&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;russpold@stanford.edu&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Now let’s say that someone else wanted to search across datasets to find researchers from Stanford University. They would have no way of knowing that I used the term “affiliation” as opposed to “organization”, “institiution”, or other terms.  We could instead represent this using JSON-LD, which is more verbose but allows us to link to a vocabulary (in this case <a class="reference external" href="http://schema.org">schema.org</a>) that defines these entities by providing a <code class="docutils literal notranslate"><span class="pre">&#64;context</span></code> tag:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;@context&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;https://schema.org&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;@type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Person&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Russell Poldrack&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;affiliation&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;@type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Organization&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Stanford University&quot;</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;email&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;russpold@stanford.edu&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="data-documentation">
<h2><a class="toc-backref" href="#id58">Data documentation</a><a class="headerlink" href="#data-documentation" title="Permalink to this heading">#</a></h2>
<p>While metadata is generally meant to be used by computers, it is also important to provide human-readable documentation for a dataset, so that other researchers (or one’s own self in the future) can understand and reuse the data successfully.  There are two forms of documentation that can be important to provide.</p>
<section id="data-dictionaries">
<h3><a class="toc-backref" href="#id59">Data dictionaries</a><a class="headerlink" href="#data-dictionaries" title="Permalink to this heading">#</a></h3>
<p>A <em>data dictionary</em> provides information about each of the variables in a dataset. These are meant to be human readable, though it can often be useful to share them in a machine-readable format (such as JSON) so that they can also be used in programmatic ways.  A data dictionary includes information such as:</p>
<ul class="simple">
<li><p>an understandable description of the variable</p></li>
<li><p>the data type (e.g. string, integer, Boolean)</p></li>
<li><p>the allowable range of values</p></li>
</ul>
<p>For example, a study of immune system function in human participants might include the following in its data dictionary:</p>
<div class="pst-scrollable-table-container"><table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Variable Name</p></th>
<th class="head"><p>Data Type</p></th>
<th class="head"><p>Allowable Values</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>age</p></td>
<td><p>Integer</p></td>
<td><p>0-120</p></td>
<td><p>Age of the participant in years</p></td>
</tr>
<tr class="row-odd"><td><p>gender</p></td>
<td><p>String</p></td>
<td><p>M, W, O</p></td>
<td><p>Participant’s self-identified gender</p></td>
</tr>
<tr class="row-even"><td><p>crp</p></td>
<td><p>Numeric</p></td>
<td><p>0.1-50.0, -90, -98, -99</p></td>
<td><p>C-reactive protein level (mg/L)</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="codebooks">
<h3><a class="toc-backref" href="#id60">Codebooks</a><a class="headerlink" href="#codebooks" title="Permalink to this heading">#</a></h3>
<p>A codebook is meant to be a more human-friendly description of the content of the dataset, focusing on how the data were collected and coded. It often includes a detailed description of each variable that is meant to help understand and interpret the data.  For the example above, the codebook might include the following:</p>
<p><em>Variable Information</em></p>
<ul class="simple">
<li><p>Variable name: crp</p></li>
<li><p>Variable label: High-sensitivity C-reactive protein</p></li>
<li><p>Variable definition: A quantitative measure of C-reactive protein in blood serum.</p></li>
</ul>
<p><em>Measurement and Coding</em></p>
<ul class="simple">
<li><p>Data Type: Numeric (Floating Point, 2 decimal places)</p></li>
<li><p>Units of Measurement: mg/L (milligrams per Liter)</p></li>
<li><p>Measurement Method: Immunoturbidimetric assay.</p></li>
<li><p>Instrument: Roche Cobas c702 clinical chemistry analyzer.</p></li>
<li><p>Allowable Range: 0.10 - 50.00</p>
<ul>
<li><p>Note: The lower limit of detection for this assay is 0.10 mg/L.</p></li>
</ul>
</li>
<li><p>Values and Codes:</p>
<ul>
<li><p>[Numerical Value]: A continuous value from 0.10 to 50.00 represents the measured concentration in mg/L.</p></li>
<li><p>-90: Value below the lower limit of detection (&lt; 0.10 mg/L).</p></li>
<li><p>-98: Unusable sample (e.g., sample was hemolyzed, insufficient quantity).</p></li>
<li><p>-99: Missing (e.g., sample not collected, participant refused blood draw).</p></li>
</ul>
</li>
</ul>
<p><em>Collection Protocol and Provenance</em></p>
<ul class="simple">
<li><p>Specimen Type: Serum from a venous blood sample.</p></li>
<li><p>Collection Procedure: Blood was drawn from the antecubital vein into a serum separator tube (SST) after an 8-hour overnight fast. The sample was allowed to clot for 30 minutes, then centrifuged at 1,500 x g for 15 minutes. Serum was aliquoted and stored at -80°C until analysis.</p></li>
<li><p>Date of Creation: 2025-11-15</p></li>
<li><p>Version: 1.0</p></li>
</ul>
<p>It is essential to generate data dictionaries and codebooks upon the generation of the dataset; otherwise important details may be lost.</p>
</section>
</section>
<section id="provenance">
<h2><a class="toc-backref" href="#id61">Provenance</a><a class="headerlink" href="#provenance" title="Permalink to this heading">#</a></h2>
<p><em>Provenance</em> refers to particular metadata regarding the history of processes and inputs that give rise to a particular file.  Tracking of provenance is essential to ensure that one knows exactly how a particular file was created.  This includes:</p>
<ul class="simple">
<li><p>the origin of original data (such as the instrument used to collect it, or date of collection)</p></li>
<li><p>the specific input files that went into creation of the file, for files that are derived data</p></li>
<li><p>the specific versions of any software tools that were used to create the file</p></li>
<li><p>the specific settings used for the software tools</p></li>
</ul>
<p>Tracking of provenance is non-trivial.  The World Wide Web Consortium (W3C) has developed a framework called <a class="reference external" href="https://www.w3.org/TR/2013/NOTE-prov-primer-20130430/">PROV</a> which defines a model for the representation of provenance information.  This framework provides an overview of the many features of provenance that one might want to record for an information that is shared online.  The PROV data models defines three main concepts:</p>
<ul class="simple">
<li><p><em>Entities</em>: things that are produced, such as datasets and publications</p></li>
<li><p><em>Activities</em>: processes that involve using, generating, or modifying entities</p></li>
<li><p><em>Agents</em>: People, organizations, or artifacts (such as computers) that are responsible for activities</p></li>
</ul>
<p>In addition, the model defines a set of relationships between these concepts, as seen in Figure <a class="reference internal" href="#prov-fig"><span class="std std-numref">Figure 10</span></a>:</p>
<figure class="align-default" id="prov-fig">
<a class="reference internal image-reference" href="https://www.w3.org/TR/2013/NOTE-prov-primer-20130430/images/key-concepts.png"><img alt="W3C PROV entities and relations" src="https://www.w3.org/TR/2013/NOTE-prov-primer-20130430/images/key-concepts.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 10 </span><span class="caption-text">A depiction of the PROV data model entities and relations.  Copyright © [2013] <a class="reference external" href="https://www.w3.org/copyright/document-license-2023/">World Wide Web Consortium</a>.</span><a class="headerlink" href="#prov-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>This data model highlights the breadth of information that needs to be represented in order to accurately record provenance.</p>
<p>There are several different ways to track provenance in practice, which vary in their complexity, comprehensiveness, and ease of use.  We will discuss this in much more detail in a later chapter on workflows.</p>
</section>
<section id="handling-of-sensitive-data">
<h2><a class="toc-backref" href="#id62">Handling of sensitive data</a><a class="headerlink" href="#handling-of-sensitive-data" title="Permalink to this heading">#</a></h2>
<p>Researchers in some fields, particularly those who work with data obtained from human subjects, often handle data are <em>sensitive</em>, meaning that they may require a higher degree of security and/or additional procedures to protect the privacy and confidentiality of the research subjects.</p>
<section id="data-security">
<h3><a class="toc-backref" href="#id63">Data security</a><a class="headerlink" href="#data-security" title="Permalink to this heading">#</a></h3>
<p>Sensitive data often require additional protections from potential breach.  The minimum requirement is generally that the data are housed on an encrypted file system and any transfers are made via an encrypted channel, and that access to the system is controlled.  Some datasets include more stringent security measures in their Data Use Agreement.  For example, the Adolescent Brain Cognitive Development (ABCD) study, a widely used dataset on brain and cognitive development, <a class="reference external" href="https://abcdstudy.org/scientists/data-sharing/">requires</a> that any systems used to house or process the data must meet a specific standard for sensitive information known as  <a class="reference external" href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/800-171r3/NIST.SP.800-171r3.html">NIST SP 800-171</a>. This standard comprises 17 “families” of security requirements that a system must meet to be compliant:</p>
<ul class="simple">
<li><p>Access Control</p></li>
<li><p>Maintenance</p></li>
<li><p>Security Assessment and Monitoring</p></li>
<li><p>Awareness and Training</p></li>
<li><p>Media Protection</p></li>
<li><p>System and Communications Protection</p></li>
<li><p>Audit and Accountability</p></li>
<li><p>Personnel Security</p></li>
<li><p>System and Information Integrity</p></li>
<li><p>Configuration Management</p></li>
<li><p>Physical Protection</p></li>
<li><p>Planning</p></li>
<li><p>Identification and Authentication</p></li>
<li><p>Risk Assessment</p></li>
<li><p>System and Services Acquisition</p></li>
<li><p>Incident Response</p></li>
<li><p>Supply Chain Risk Management</p></li>
</ul>
<p>In general this level of security certification will be limited to computer systems run by an organizational IT group rather than by an individual investigator, due to the stringency of the requirements.</p>
</section>
<section id="deidentification">
<h3><a class="toc-backref" href="#id64">Deidentification</a><a class="headerlink" href="#deidentification" title="Permalink to this heading">#</a></h3>
<p>Deidentification generally involves the removal of specific identifying information that could potentially be used to reidentify a human subject.  In the US, this generally relies upon the <em>Safe Harbor</em> provision in the Health Insurance Portability and Accountability Act of 1996 (HIPAA), which <a class="reference external" href="https://www.hhs.gov/hipaa/for-professionals/special-topics/de-identification/index.html">states the following criteria</a> for rendering a dataset deidentified:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(i) The following identifiers of the individual or of relatives, employers, or household members of the individual, are removed:
- (A) Names
- (B) All geographic subdivisions smaller than a state, including street address, city, county, precinct, ZIP code, and their equivalent geocodes, except for the initial three digits of the ZIP code if, according to the current publicly available data from the Bureau of the Census:(1) The geographic unit formed by combining all ZIP codes with the same three initial digits contains more than 20,000 people; and(2) The initial three digits of a ZIP code for all such geographic units containing 20,000 or fewer people is changed to 000
- (C) All elements of dates (except year) for dates that are directly related to an individual, including birth date, admission date, discharge date, death date, and all ages over 89 and all elements of dates (including year) indicative of such age, except that such ages and elements may be aggregated into a single category of age 90 or older
- (D) Telephone numbers
- (E) Fax numbers
- (F) Email addresses
- (G) Social security numbers
- (H) Medical record numbers
- (I) Health plan beneficiary numbers
- (J) Account numbers
- (K) Certificate/license numbers
- (L) Vehicle identifiers and serial numbers, including license plate numbers
- (M) Device identifiers and serial numbers
- (N) Web Universal Resource Locators (URLs)
- (O) Internet Protocol (IP) addresses
- (P) Biometric identifiers, including finger and voice prints
- (Q) Full-face photographs and any comparable images
- (R) Any other unique identifying number, characteristic, or code, except as permitted by paragraph (c) of this section [Paragraph (c) is presented below in the section “Re-identification”]; and

(ii) The covered entity does not have actual knowledge that the information could be used alone or in combination with other information to identify an individual who is a subject of the information.
</pre></div>
</div>
<p>In the US, deidentification of data is generally sufficient to render them non-sensitive, whereas this is generally <em>not</em> the case in European countries covered by the General Data Protection Regulation (GDPR).</p>
</section>
<section id="anonymization">
<h3><a class="toc-backref" href="#id65">Anonymization</a><a class="headerlink" href="#anonymization" title="Permalink to this heading">#</a></h3>
<p>Anonymization refers to the modification of data in a way that can essentially guarantee that the subjects cannot be reidentified. For example, one might modify ages so that they are stated in ranges (such as 20-25 years old) instead of a specific year.  These methods generally change the data in ways that could potentially affect downstream analyses, and thus many researchers shy away from using anonymized data unless absolutely necessary.</p>
<p>One method that is often used for large datasets is known as <em>differential privacy</em>, which involves adding noise to analytic results in a way that can provably prevent reidentification.  For example, this method is <a class="reference external" href="https://www.census.gov/programs-surveys/decennial-census/decade/2020/planning-management/process/disclosure-avoidance/differential-privacy.html">now used</a> by the US Census Bureau to protect individuals. This has the benefit of providing a provable mathematical guarantee of privacy by quantifying the maximum degree of privacy loss given a particular amount of noise added.  However, this method may have adverse effects on the data, such by disparately impacting small sub-populations within a larger dataset <span id="id7">[<a class="reference internal" href="bibliography.html#id2" title="Alexis R Santos-Lozada, Jeffrey T Howard, and Ashton M Verdery. How differential privacy will affect our understanding of health disparities in the united states. Proc Natl Acad Sci U S A, 117(24):13405-13412, Jun 2020. doi:10.1073/pnas.2003714117.">Santos-Lozada <em>et al.</em>, 2020</a>]</span>.</p>
</section>
</section>
<section id="version-control-for-data">
<h2><a class="toc-backref" href="#id66">Version control for data</a><a class="headerlink" href="#version-control-for-data" title="Permalink to this heading">#</a></h2>
<p>In the case of original data we never want to allow any changes, but for derived data we will often end up making changes to our workflows that result in changes in the data.  As an example, let’s say that we are analyzing RNA-sequencing data, and we receive a notice that a bug was found in the specific version of STAR that we had used for sequence alignment.  We would like to be able to track these changes, so that we know which data we are working with at any point in time. In many laboratories, this achieved through file naming, resulting in a menagerie of files with names like “dataset_new_fixed_v2.tsv”.  This can make it difficult to determine exactly which data were used in any analysis. In Chapter 2 we discussed the many reasons why we use version control for code, and many of those also apply to data as well. In the case of data, it is particularly important to be able to track the what, when, and why of any changes to the data, which is exactly the purpose of version control systems.</p>
<section id="using-git-for-data-version-control">
<h3><a class="toc-backref" href="#id67">Using git for data version control</a><a class="headerlink" href="#using-git-for-data-version-control" title="Permalink to this heading">#</a></h3>
<p>When the relevant data are small (e.g. smaller than a few megabytes) and stored in a text format (such as CSV/TSV), one can simply use git to track changes in the data.  (We will discuss in a later chapter why Github is not an optimal platform for sharing data, at least not on its own.).</p>
<p>However, git does not work well for version control on larger datasets using binary data files.  Git is able to efficiently store version information about code because it tracks the specific differences in the code between versions (known as a <em>diff</em>), and only stores the differences.  Thus, if one has a very large code file and changes one line, only that one line difference is stored in the git database.  However, with binary data this strategy is not effective, and git has to store the entire new dataset each time, leading to bloated repositories and very slow performance.</p>
</section>
<section id="using-datalad-for-version-control-on-larger-datasets">
<h3><a class="toc-backref" href="#id68">Using Datalad for version control on larger datasets</a><a class="headerlink" href="#using-datalad-for-version-control-on-larger-datasets" title="Permalink to this heading">#</a></h3>
<p>A solution to this problem is to use a version control tool that is specifically designed for large data.  There are several tools that address this problem; we will focus on <a class="reference external" href="https://www.datalad.org/">Datalad</a>, which is a data management system that functions very similarly to git.  It is based on a tool called <a class="reference external" href="https://git-annex.branchable.com/">git-annex</a>, but provides much greater ease of use for researchers.  (Full disclosure: Our group collaborates with the Datalad group and our grants have supported some of their development work.)</p>
<p>An important note:  Datalad is quite powerful but has a significant learning curve, and takes a bit of time to get accustomed to.  In particular, its use of symbolic links can sometimes confuse new users. Having said that, let’s look at some simple examples.</p>
<section id="creating-a-local-datalad-dataset">
<h4><a class="toc-backref" href="#id69">Creating a local Datalad dataset</a><a class="headerlink" href="#creating-a-local-datalad-dataset" title="Permalink to this heading">#</a></h4>
<p>Let’s say that we want to create a new dataset on our local computer that will be tracked by Datalad.  We first create a new repository:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>datalad<span class="w"> </span>create<span class="w"> </span>my_datalad_repo

create<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>/Users/poldrack/Dropbox/code/BetterCodeBetterScience/my_datalad_repo<span class="w"> </span><span class="o">(</span>dataset<span class="o">)</span>
</pre></div>
</div>
<p>This creates a new directory, called <code class="docutils literal notranslate"><span class="pre">my_datalad_repo</span></code> and sets it up as a Datalad dataset.  We then go into the directory and create a subdirectory called <code class="docutils literal notranslate"><span class="pre">data</span></code>, and then download some data files from another project.  We do this using the <code class="docutils literal notranslate"><span class="pre">datalad</span> <span class="pre">download-url</span></code> function, which will both download the data and save them to the datalad dataset:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span><span class="nb">cd</span><span class="w"> </span>my_datalad_repo
➤<span class="w">  </span>mkdir<span class="w"> </span>data
➤<span class="w">  </span>datalad<span class="w"> </span>download-url<span class="w"> </span>--dataset<span class="w"> </span>.<span class="w"> </span>-O<span class="w"> </span>data/<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>https://raw.githubusercontent.com/IanEisenberg/Self_Regulation_Ontology/refs/heads/master/Data/Complete_02-16-2019/meaningful_variables_clean.csv

<span class="o">[</span>INFO<span class="w">   </span><span class="o">]</span><span class="w"> </span>Downloading<span class="w"> </span><span class="s1">&#39;https://raw.githubusercontent.com/IanEisenberg/Self_Regulation_Ontology/refs/heads/master/Data/Complete_02-16-2019/meaningful_variables_clean.csv&#39;</span><span class="w"> </span>into<span class="w"> </span><span class="s1">&#39;/Users/poldrack/Dropbox/code/BetterCodeBetterScience/my_datalad_repo/data/&#39;</span>
download_url<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>/Users/poldrack/Dropbox/code/BetterCodeBetterScience/my_datalad_repo/data/meaningful_variables_clean.csv<span class="w"> </span><span class="o">(</span>file<span class="o">)</span>
add<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>data/meaningful_variables_clean.csv<span class="w"> </span><span class="o">(</span>file<span class="o">)</span>
save<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>.<span class="w"> </span><span class="o">(</span>dataset<span class="o">)</span>
action<span class="w"> </span>summary:
<span class="w">  </span>add<span class="w"> </span><span class="o">(</span>ok:<span class="w"> </span><span class="m">1</span><span class="o">)</span>
<span class="w">  </span>download_url<span class="w"> </span><span class="o">(</span>ok:<span class="w"> </span><span class="m">1</span><span class="o">)</span>
<span class="w">  </span>save<span class="w"> </span><span class="o">(</span>ok:<span class="w"> </span><span class="m">1</span><span class="o">)</span>

➤<span class="w">  </span>datalad<span class="w"> </span>download-url<span class="w"> </span>--dataset<span class="w"> </span>.<span class="w"> </span>-O<span class="w"> </span>data/<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>https://raw.githubusercontent.com/IanEisenberg/Self_Regulation_Ontology/refs/heads/master/Data/Complete_02-16-2019/demographics.csv

<span class="o">[</span>INFO<span class="w">   </span><span class="o">]</span><span class="w"> </span>Downloading<span class="w"> </span><span class="s1">&#39;https://raw.githubusercontent.com/IanEisenberg/Self_Regulation_Ontology/refs/heads/master/Data/Complete_02-16-2019/demographics.csv&#39;</span><span class="w"> </span>into<span class="w"> </span><span class="s1">&#39;/Users/poldrack/Dropbox/code/BetterCodeBetterScience/my_datalad_repo/data/&#39;</span>
download_url<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>/Users/poldrack/Dropbox/code/BetterCodeBetterScience/my_datalad_repo/data/demographics.csv<span class="w"> </span><span class="o">(</span>file<span class="o">)</span>
add<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>data/demographics.csv<span class="w"> </span><span class="o">(</span>file<span class="o">)</span>
save<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>.<span class="w"> </span><span class="o">(</span>dataset<span class="o">)</span>
action<span class="w"> </span>summary:
<span class="w">  </span>add<span class="w"> </span><span class="o">(</span>ok:<span class="w"> </span><span class="m">1</span><span class="o">)</span>
<span class="w">  </span>download_url<span class="w"> </span><span class="o">(</span>ok:<span class="w"> </span><span class="m">1</span><span class="o">)</span>
<span class="w">  </span>save<span class="w"> </span><span class="o">(</span>ok:<span class="w"> </span><span class="m">1</span><span class="o">)</span>
</pre></div>
</div>
<p>A Datalad dataset is also a <code class="docutils literal notranslate"><span class="pre">git</span></code> repository, which we can see if we use the <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">log</span></code> command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>git<span class="w"> </span>log

commit<span class="w"> </span>a5696c1a32d69dd24781652d04902047c5d3df50<span class="w"> </span><span class="o">(</span>HEAD<span class="w"> </span>-&gt;<span class="w"> </span>main<span class="o">)</span>
Author:<span class="w"> </span>Russell<span class="w"> </span>Poldrack<span class="w"> </span>&lt;poldrack@gmail.com&gt;
Date:<span class="w">   </span>Sun<span class="w"> </span>Nov<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="m">12</span>:13:22<span class="w"> </span><span class="m">2025</span><span class="w"> </span>-0800

<span class="w">    </span><span class="o">[</span>DATALAD<span class="o">]</span><span class="w"> </span>Download<span class="w"> </span>URLs

<span class="w">    </span>URLs:
<span class="w">      </span>https://raw.githubusercontent.com/IanEisenberg/Self_Regulation_Ontology/refs/heads/master/Data/Complete_02-16-2019/demographics.csv

commit<span class="w"> </span>2603a1fb98f00d6cdd029194f010a845d73cdc7c
Author:<span class="w"> </span>Russell<span class="w"> </span>Poldrack<span class="w"> </span>&lt;poldrack@gmail.com&gt;
Date:<span class="w">   </span>Sun<span class="w"> </span>Nov<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="m">12</span>:13:20<span class="w"> </span><span class="m">2025</span><span class="w"> </span>-0800

<span class="w">    </span><span class="o">[</span>DATALAD<span class="o">]</span><span class="w"> </span>Download<span class="w"> </span>URLs

<span class="w">    </span>URLs:
<span class="w">      </span>https://raw.githubusercontent.com/IanEisenberg/Self_Regulation_Ontology/refs/heads/master/Data/Complete_02-16-2019/meaningful_variables_clean.csv

commit<span class="w"> </span>95b9016840e1d35bef0edf3afa06e41fdaaefce4
Author:<span class="w"> </span>Russell<span class="w"> </span>Poldrack<span class="w"> </span>&lt;poldrack@gmail.com&gt;
Date:<span class="w">   </span>Sun<span class="w"> </span>Nov<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="m">12</span>:12:08<span class="w"> </span><span class="m">2025</span><span class="w"> </span>-0800

<span class="w">    </span><span class="o">[</span>DATALAD<span class="o">]</span><span class="w"> </span>new<span class="w"> </span>dataset
</pre></div>
</div>
<p>Here we see the commit messages that were automatically created by Datalad, first for creating the new dataset and then for downloading the URLS.  The <code class="docutils literal notranslate"><span class="pre">datalad</span> <span class="pre">download-url</span></code> function adds the URL to the log, which is useful for provenance tracking.</p>
</section>
<section id="modifying-files">
<h4><a class="toc-backref" href="#id70">Modifying files</a><a class="headerlink" href="#modifying-files" title="Permalink to this heading">#</a></h4>
<p>Now let’s say that we want to make a change to one of the files and save the changes to the dataset.  Files tracked by Datalad are read-only (“locked”) by default.  If we want to edit them, then we need to use <code class="docutils literal notranslate"><span class="pre">datalad</span> <span class="pre">unlock</span></code> to unlock the file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>datalad<span class="w"> </span>unlock<span class="w"> </span>data/demographics.csv

unlock<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>data/demographics.csv<span class="w"> </span><span class="o">(</span>file<span class="o">)</span>
</pre></div>
</div>
<p>We then use a Python script to make the change, which in this case is removing some columns from the dataset:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>python<span class="w"> </span>../src/BetterCodeBetterScience/modify_data.py<span class="w"> </span>data/demographics.csv
</pre></div>
</div>
<p>We can now use <code class="docutils literal notranslate"><span class="pre">datalad</span> <span class="pre">status</span></code> to see that the file has been modified:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>datalad<span class="w"> </span>status
<span class="w"> </span>modified:<span class="w"> </span>data/demographics.csv<span class="w"> </span><span class="o">(</span>file<span class="o">)</span>
</pre></div>
</div>
<p>And we can then save it using <code class="docutils literal notranslate"><span class="pre">datalad</span> <span class="pre">save</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>datalad<span class="w"> </span>save<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;removed Motivation variables from demographics.csv&quot;</span>

add<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>data/demographics.csv<span class="w"> </span><span class="o">(</span>file<span class="o">)</span>
save<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>.<span class="w"> </span><span class="o">(</span>dataset<span class="o">)</span>
action<span class="w"> </span>summary:
<span class="w">  </span>add<span class="w"> </span><span class="o">(</span>ok:<span class="w"> </span><span class="m">1</span><span class="o">)</span>
<span class="w">  </span>save<span class="w"> </span><span class="o">(</span>ok:<span class="w"> </span><span class="m">1</span><span class="o">)</span>
</pre></div>
</div>
<p>Datalad doesn’t have a staging area like <code class="docutils literal notranslate"><span class="pre">git</span></code> does, so there is no need to first add and then commit the file; <code class="docutils literal notranslate"><span class="pre">datalad</span> <span class="pre">save</span></code> is equivalent to adding and then committing the changes. If we then check the status we see that there are no changes waiting to be saved:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>datalad<span class="w"> </span>status

nothing<span class="w"> </span>to<span class="w"> </span>save,<span class="w"> </span>working<span class="w"> </span>tree<span class="w"> </span>clean
</pre></div>
</div>
</section>
<section id="pushing-data-to-a-remote-repository">
<h4><a class="toc-backref" href="#id71">Pushing data to a remote repository</a><a class="headerlink" href="#pushing-data-to-a-remote-repository" title="Permalink to this heading">#</a></h4>
<p>Datalad is a particularly powerful tool for sharing data across systems.  It allows one to push or pull data from a number of different remote storage systems; in this example we will use the <a class="reference external" href="https://osf.io/">Open Science Framework (OSF)</a> as our storage location, because it is particularly easy to use with Datalad.</p>
<p>We first need to install and set up the <code class="docutils literal notranslate"><span class="pre">datalad-osf</span></code> Python package, per <a class="reference external" href="https://docs.datalad.org/projects/osf/en/latest/settingup.html">the Datalad documentation</a>.  We also need to create an account on the OSF site, and obtain a Personal Access Token for login.  We can then use Datalad to authenticate with OSF:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>datalad<span class="w"> </span>osf-credentials<span class="w">                                                </span><span class="m">1</span><span class="w"> </span>↵
You<span class="w"> </span>need<span class="w"> </span>to<span class="w"> </span>authenticate<span class="w"> </span>with<span class="w"> </span><span class="s1">&#39;https://osf.io&#39;</span><span class="w"> </span>credentials.<span class="w"> </span>https://osf.io/settings/tokens<span class="w"> </span>provides<span class="w"> </span>information<span class="w"> </span>on<span class="w"> </span>how<span class="w"> </span>to<span class="w"> </span>gain<span class="w"> </span>access
token:
osf_credentials<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span><span class="o">[</span>authenticated<span class="w"> </span>as<span class="w"> </span>Russell<span class="w"> </span>Poldrack<span class="w"> </span>&lt;poldrack@stanford.edu&gt;<span class="o">]</span>
</pre></div>
</div>
<p>Having authenticated with OSF, we can now create a new OSF project using Datalad:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>datalad<span class="w"> </span>create-sibling-osf<span class="w"> </span>--title<span class="w"> </span>datalad-test-project<span class="w"> </span>-s<span class="w"> </span>osf
create-sibling-osf<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>https://osf.io/htprk/
<span class="o">[</span>INFO<span class="w">   </span><span class="o">]</span><span class="w"> </span>Configure<span class="w"> </span>additional<span class="w"> </span>publication<span class="w"> </span>dependency<span class="w"> </span>on<span class="w"> </span><span class="s2">&quot;osf-storage&quot;</span>
configure-sibling<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>.<span class="w"> </span><span class="o">(</span>sibling<span class="o">)</span>
</pre></div>
</div>
<p>Once the project is created, we can push the contents of our dataset to our OSF project:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>datalad<span class="w"> </span>push<span class="w"> </span>--to<span class="w"> </span>osf
copy<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>data/demographics.csv<span class="w"> </span><span class="o">(</span>file<span class="o">)</span><span class="w"> </span><span class="o">[</span>to<span class="w"> </span>osf-storage...<span class="o">]</span>
copy<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>data/meaningful_variables_clean.csv<span class="w"> </span><span class="o">(</span>file<span class="o">)</span><span class="w"> </span><span class="o">[</span>to<span class="w"> </span>osf-storage...<span class="o">]</span>
publish<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>.<span class="w"> </span><span class="o">(</span>dataset<span class="o">)</span><span class="w"> </span><span class="o">[</span>refs/heads/main-&gt;osf:refs/heads/main<span class="w"> </span><span class="o">[</span>new<span class="w"> </span>branch<span class="o">]]</span>
publish<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>.<span class="w"> </span><span class="o">(</span>dataset<span class="o">)</span><span class="w"> </span><span class="o">[</span>refs/heads/git-annex-&gt;osf:refs/heads/git-annex<span class="w"> </span><span class="o">[</span>new<span class="w"> </span>branch<span class="o">]]</span>
action<span class="w"> </span>summary:
<span class="w">  </span>copy<span class="w"> </span><span class="o">(</span>ok:<span class="w"> </span><span class="m">2</span><span class="o">)</span>
<span class="w">  </span>publish<span class="w"> </span><span class="o">(</span>ok:<span class="w"> </span><span class="m">2</span><span class="o">)</span>
</pre></div>
</div>
<p>These data now exist on OSF, and can be cloned to our local machine using <code class="docutils literal notranslate"><span class="pre">datalad</span> <span class="pre">clone</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>datalad<span class="w"> </span>clone<span class="w"> </span>osf://htprk/
<span class="o">[</span>INFO<span class="w">   </span><span class="o">]</span><span class="w"> </span>Remote<span class="w"> </span>origin<span class="w"> </span>uses<span class="w"> </span>a<span class="w"> </span>protocol<span class="w"> </span>not<span class="w"> </span>supported<span class="w"> </span>by<span class="w"> </span>git-annex<span class="p">;</span><span class="w"> </span>setting<span class="w"> </span>annex-ignore
install<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>/Users/poldrack/Downloads/htprk<span class="w"> </span><span class="o">(</span>dataset<span class="o">)</span>

➤<span class="w">  </span>tree<span class="w"> </span>htprk
htprk
└──<span class="w"> </span>data
<span class="w">    </span>├──<span class="w"> </span>demographics.csv<span class="w"> </span>-&gt;<span class="w"> </span>../.git/annex/objects/f7/Mm/MD5E-s58237--dc5b157fb9937eae2166d73ee943c766.csv/MD5E-s58237--dc5b157fb9937eae2166d73ee943c766.csv
<span class="w">    </span>└──<span class="w"> </span>meaningful_variables_clean.csv<span class="w"> </span>-&gt;<span class="w"> </span>../.git/annex/objects/J5/X6/MD5E-s1248729--e4fbac610f1f5e25e04474e55209ef56.csv/MD5E-s1248729--e4fbac610f1f5e25e04474e55209ef56.csv
</pre></div>
</div>
<p>Notice that the files in the cloned dataset directory are actually symbolic links; the actual file contents are not downloaded when the dataset is cloned. We can see this if we try to look at the size of the datafile:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>wc<span class="w"> </span>data/demographics.csv
wc:<span class="w"> </span>data/demographics.csv:<span class="w"> </span>open:<span class="w"> </span>No<span class="w"> </span>such<span class="w"> </span>file<span class="w"> </span>or<span class="w"> </span>directory
</pre></div>
</div>
<p>To actually download the file contents, we can use <code class="docutils literal notranslate"><span class="pre">datalad</span> <span class="pre">get</span></code>, after which we will see that the file contents are available:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>➤<span class="w">  </span>datalad<span class="w"> </span>get<span class="w"> </span>.<span class="w">                                                          </span><span class="m">1</span><span class="w"> </span>↵
get<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>data/demographics.csv<span class="w"> </span><span class="o">(</span>file<span class="o">)</span><span class="w"> </span><span class="o">[</span>from<span class="w"> </span>web...<span class="o">]</span>
get<span class="o">(</span>ok<span class="o">)</span>:<span class="w"> </span>data/meaningful_variables_clean.csv<span class="w"> </span><span class="o">(</span>file<span class="o">)</span><span class="w"> </span><span class="o">[</span>from<span class="w"> </span>web...<span class="o">]</span>
action<span class="w"> </span>summary:
<span class="w">  </span>get<span class="w"> </span><span class="o">(</span>ok:<span class="w"> </span><span class="m">2</span><span class="o">)</span>

➤<span class="w">  </span>wc<span class="w"> </span>data/demographics.csv
<span class="w">     </span><span class="m">523</span><span class="w">    </span><span class="m">1276</span><span class="w">   </span><span class="m">58237</span><span class="w"> </span>data/demographics.csv
</pre></div>
</div>
<p>One can also push data using Datalad to a range of other remote hosts; see the <a class="reference external" href="https://handbook.datalad.org/en/latest/basics/101-138-sharethirdparty.html">Datalad documentation</a> for more on this.</p>
</section>
</section>
</section>
<section id="archiving-data">
<h2><a class="toc-backref" href="#id72">Archiving data</a><a class="headerlink" href="#archiving-data" title="Permalink to this heading">#</a></h2>
<p>At the end of a project the data may seem like they are no longer needed, but in many cases there are reasons to retain the data beyond the end of the project. Funding agencies often have a required data retention period beyond the end of the grant. For example, the US National Institutes of Health (NIH) requires that records be retained for <a class="reference external" href="https://grants.nih.gov/grants/policy/nihgps/HTML5/section_8/8.4.2_record_retention_and_access.htm">three years</a> beyond the end of the funding.  Some universities also have their own data retention requirements; for example, my institution (Stanford University) also has a <a class="reference external" href="https://doresearch.stanford.edu/policies/research-policy-handbook/conduct-research/retention-and-access-research-data">three-year data retention requirement</a>, whereas Johns Hopkins University has a <a class="reference external" href="https://www.hopkinsmedicine.org/institutional-review-board/guidelines-policies/guidelines/record-retention">five-year retention requirement</a>. In my opinion it is preferable to retain data, at least in archival form, as long as possible. I have received requests to share data more than 15 years after the original study completion, and it was only due to long-term retention of these data that we were able to honor these requests.</p>
<p>Archiving of research data can take several forms:</p>
<ul class="simple">
<li><p>Physical hard drive: Datasets up to several terabytes can be stored on a physical hard drive kept in a secure and safe location.  This is not an optimal storage method, primarily because physical hard drives can fail over time. If one insists on using physical hard drives, then I would suggest placing the data on two different hard drives (preferably different models, to diversify vulnerability to hardware issues), and that those drives are stored in different locations to avoid risk of destruction in a disaster such as a flood or fire.</p></li>
<li><p>Archival storage media: In the past it was common to store data onto media such as writable DVDs or cartridge disks. A major problem with this kind of archiving is the inevitable obsolescence of storage media formats: When was the last time you saw a computer with a DVD reader, much less a Zip drive (which was the common medium when I was a postdoc)?  This method should generally be avoided, except as a redundant backup to another storage form.</p></li>
<li><p>Cloud storage: Increasingly, commercial cloud storage providers such as Dropbox or Google Drive are used as archival storage locations.  However, these providers do not guarantee long-term availability of the data, and to not offer verification that would allow one to ensure that the data haven’t been silently corrupted.  I generally use these tools as an additional redundant store for much of my older data, but I would not want to rely upon them as my sole archival storage.</p></li>
</ul>
<p>As we will discuss in more detail in our later chapter on sharing of research objects, it is generally preferably to archive data in a location that has a long-term preservation policy and verifiability.  This can include institutional repositories (usually run by librarians, who have deep expertise in archiving), general purpose repositories (like OSF or Zenodo), or domain-specific repositories.</p>
</section>
<section id="appendix-an-example-of-database-usage">
<h2><a class="toc-backref" href="#id73">Appendix: An example of database usage</a><a class="headerlink" href="#appendix-an-example-of-database-usage" title="Permalink to this heading">#</a></h2>
<p>Here I will work through an example of a real scientific question using several database systems. I will focus on NoSQL databases, for two reasons:</p>
<p>1: They are less well known amongst scientists compared to relational databases
2: I personally prefer the NoSQL approach in most cases</p>
<p>Note that while many researchers may never use all the different databases used here, I am intentionally presenting a full-stack example to show how they can be combined.</p>
<p>The question that I will ask is as follows: How well can the biological similarity between traits (including diseases as well as other phenotypes) be estimated from the semantic similarity of publications that refer to the trait?  We will use two primary datasets to assess this:</p>
<ul class="simple">
<li><p>A dataset of genome-wise association study (GWAS) results for specific traits obtained from <a class="reference external" href="https://www.ebi.ac.uk/gwas/docs/file-downloads">here</a>.</p></li>
<li><p>Abstracts that refer to each of the traits identified in the GWAS result, obtained from the <a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/">PubMed</a> database.</p></li>
</ul>
<p>I will not present all of the code for each step; this can be found <a class="reference internal" href="#src/BetterCodeBetterScience/database_example_funcs.py"><span class="xref myst">here</span></a> and <a class="reference internal" href="#src/BetterCodeBetterScience/database.py"><span class="xref myst">here</span></a>. Rather, I will show portions that are particularly relevant to the databases being used.</p>
<section id="adding-gwas-data-to-a-document-store">
<h3><a class="toc-backref" href="#id74">Adding GWAS data to a document store</a><a class="headerlink" href="#adding-gwas-data-to-a-document-store" title="Permalink to this heading">#</a></h3>
<p>We start by uploading the GWAS data and adding them to a document store, using <em>MongoDB</em>, which I installed on my local machine.   We start by reading the CSV file containing the data.  Looking at those data, we see that they are not properly <em>normalized</em>. Normalization is a concept that is essential for relational databases but can also be very helpful for document stores.  We won’t go into the details of normalization here (for more, see <a class="reference external" href="https://learn.microsoft.com/en-us/troubleshoot/microsoft-365-apps/access/database-normalization-description">here</a>); rather, we will simply outline the primary requirements of the <em>first normal form</em>, which is the most basic form of normalization.  This requires that:</p>
<ol class="arabic simple">
<li><p>There are no duplicate records</p></li>
<li><p>The columns contain scalar values (and thus do not contain composite values such as sets of values)</p></li>
<li><p>There are not multiple columns that contain the same kind of data</p></li>
</ol>
<p>In this case, looking at the data we see that several columns contain multiple values for genes, due to the fact that some single nucleotide polymorphisms (SNPs) are located in intergenic space and thu can be mapped to multiple genes.  These values separated by commas (e.g. “FADS2, FADS1”).  To normalize this, we can <em>explode</em> the data frame, which involves separating out these values into separate rows, which have otherwise identical contents.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gwas_data</span> <span class="o">=</span> <span class="n">get_exploded_gwas_data</span><span class="p">()</span>
</pre></div>
</div>
<p>We can now import the data from this data frame into a MongoDB collection, mapping each unique trait to the genes that are reported as being associated with it.  First I generated a separate function that sets up a MongoDB collection (see <code class="docutils literal notranslate"><span class="pre">setup_mongo_collection</span></code> <a class="reference internal" href="#src/BetterCodeBetterScience/database.py"><span class="xref myst">here</span></a>).  We can then use that function to set up our gene set collection:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># since the collection names are shared across functions, </span>
<span class="c1"># create global variable with their names</span>
<span class="n">COLLECTION_GENESET</span> <span class="o">=</span> <span class="s1">&#39;geneset_annotations_by_trait&#39;</span>

<span class="k">def</span> <span class="nf">import_genesets_by_trait</span><span class="p">(</span>
    <span class="n">gwas_data_melted</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

    <span class="n">geneset_annotations_by_trait</span> <span class="o">=</span> <span class="n">setup_mongo_collection</span><span class="p">(</span><span class="n">COLLECTION_GENESET</span><span class="p">)</span>
    <span class="c1"># &quot;mapped_trait_uri&quot; is the field that contains the identifier for each trait</span>
    <span class="n">geneset_annotations_by_trait</span><span class="o">.</span><span class="n">create_index</span><span class="p">(</span><span class="s1">&#39;mapped_trait_uri&#39;</span><span class="p">,</span> <span class="n">unique</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># first get a mapping from MAPPED_TRAIT_URI to TRAIT_NAME</span>
    <span class="n">trait_name_mapping</span> <span class="o">=</span> <span class="n">gwas_data_melted</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;MAPPED_TRAIT_URI&#39;</span><span class="p">)[</span>
        <span class="s1">&#39;MAPPED_TRAIT&#39;</span>
    <span class="p">]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>

    <span class="c1"># loop through each unique MAPPED_TRAIT_URI in gwas_data data frame </span>
    <span class="c1"># add all of its gene sets to the mongo collection </span>
    <span class="k">for</span> <span class="n">mapped_trait_uri</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span>
        <span class="n">gwas_data_melted</span><span class="p">[</span><span class="s1">&#39;MAPPED_TRAIT_URI&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
    <span class="p">):</span>
        <span class="n">gene_sets</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">gwas_data_melted</span><span class="p">[</span>
                <span class="n">gwas_data_melted</span><span class="p">[</span><span class="s1">&#39;MAPPED_TRAIT_URI&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">mapped_trait_uri</span>
            <span class="p">][</span><span class="s1">&#39;GENE_ID&#39;</span><span class="p">]</span>
            <span class="o">.</span><span class="n">unique</span><span class="p">()</span>
            <span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="c1"># clean up gene names</span>
        <span class="n">gene_sets</span> <span class="o">=</span> <span class="p">[</span><span class="n">gene</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">gene</span> <span class="ow">in</span> <span class="n">gene_sets</span><span class="p">]</span>
        <span class="c1"># add the item to the mongodb collection, also</span>
        <span class="c1"># including the trait name</span>
        <span class="n">geneset_annotations_by_trait</span><span class="o">.</span><span class="n">update_one</span><span class="p">(</span>
            <span class="p">{</span><span class="s1">&#39;mapped_trait_uri&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">mapped_trait_uri</span><span class="p">)},</span>
            <span class="p">{</span>
                <span class="s1">&#39;$set&#39;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s1">&#39;mapped_trait_uri&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">mapped_trait_uri</span><span class="p">),</span>
                    <span class="s1">&#39;gene_sets&#39;</span><span class="p">:</span> <span class="n">gene_sets</span><span class="p">,</span>
                    <span class="s1">&#39;trait_name&#39;</span><span class="p">:</span> <span class="n">trait_name_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">mapped_trait_uri</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">),</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="n">upsert</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>


<span class="n">import_genesets_by_trait</span><span class="p">(</span><span class="n">gwas_data</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that this function uses an <em>upsert</em> operation, which is a combination of insertion (if the document with this key doesn’t already exist) or updating (if the document with this key already exists).  This results in a collection with 3,047 records, each of which is indexed by the trait identifier and includes a list of all of the genes associated with the trait across the GWAS studies.  We also include the trait names to make the records human-readable, but we rely upon the unique identifiers (which in this case are defined as URLs, such as “<a class="reference external" href="http://www.ebi.ac.uk/efo/EFO_0004309">http://www.ebi.ac.uk/efo/EFO_0004309</a>” which maps to the trait of “platelet count”.</p>
</section>
<section id="annotating-gene-sets">
<h3><a class="toc-backref" href="#id75">Annotating gene sets</a><a class="headerlink" href="#annotating-gene-sets" title="Permalink to this heading">#</a></h3>
<p>Remember that our goal in this analysis is to identify the biological overlap between traits. We could do this by assessing the degree to which they are associated with the same genes, but this would miss out on the fact that genes work together in networks that are often associated with the function of specific biological pathways.  Given a particular set of genes, we can use bioinformatics tools to identify the biological processes that are associated with that set of genes. In this case I used the  <a class="reference external" href="https://biit.cs.ut.ee/gprofiler/gost">g:Profiler</a> tool from ELIXIR, which comes with a handy <a class="reference external" href="https://pypi.org/project/gprofiler-official/">Python package</a>.   This tool returns a set of pathways that are statistically enriched for each gene set, each of which is defined by a unique identifier that refers to a particular ontology such as the Gene Ontology.   For example, the 877 genes associated with the “platelet count” trait are involved in a range of biological processes and pathways, which range from the very general (e.g. GO:0005515, referring to “protein binding”) to the very specific (e.g. GO:0007599, referring to “hemostasis”, which is the stopping of bleeding).</p>
<p>We can use <code class="docutils literal notranslate"><span class="pre">g:Profiler</span></code> to obtain the annotation for the gene set associated with each trait:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">annotate_genesets_by_trait</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="c1"># loop over all entries in the geneset_annotations_by_trait collection</span>
    <span class="c1"># and do functional annotation of the gene sets</span>

    <span class="n">geneset_annotations_by_trait</span> <span class="o">=</span> <span class="n">setup_mongo_collection</span><span class="p">(</span><span class="n">COLLECTION_GENESET</span><span class="p">)</span>

    <span class="n">gp</span> <span class="o">=</span> <span class="n">GProfiler</span><span class="p">(</span><span class="n">return_dataframe</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># use a list here so that we can use tqdm to show progress</span>
    <span class="c1"># skip any entries that already have functional_annotation</span>
    <span class="n">annotations</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">i</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">geneset_annotations_by_trait</span><span class="o">.</span><span class="n">find</span><span class="p">({})</span>
        <span class="k">if</span> <span class="s1">&#39;functional_annotation&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">i</span>
    <span class="p">]</span>

    <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">annotations</span><span class="p">):</span>
        <span class="n">mapped_trait_uri</span> <span class="o">=</span> <span class="n">entry</span><span class="p">[</span><span class="s1">&#39;mapped_trait_uri&#39;</span><span class="p">]</span>
        <span class="n">gene_sets</span> <span class="o">=</span> <span class="n">entry</span><span class="p">[</span><span class="s1">&#39;gene_sets&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">gene_sets</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="c1"># do functional annotation</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">annotation_results</span> <span class="o">=</span> <span class="n">gp</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span>
                <span class="n">organism</span><span class="o">=</span><span class="s1">&#39;hsapiens&#39;</span><span class="p">,</span>
                <span class="n">query</span><span class="o">=</span><span class="n">gene_sets</span><span class="p">,</span>
                <span class="n">sources</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;GO:BP&#39;</span><span class="p">,</span> <span class="s1">&#39;GO:MF&#39;</span><span class="p">,</span> <span class="s1">&#39;GO:CC&#39;</span><span class="p">,</span> <span class="s1">&#39;KEGG&#39;</span><span class="p">,</span> <span class="s1">&#39;REAC&#39;</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1"># catch any exception to avoid breaking the loop</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Error annotating </span><span class="si">{</span><span class="n">mapped_trait_uri</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="c1"># convert the dataframe to a dictionary</span>
        <span class="n">annotation_results_dict</span> <span class="o">=</span> <span class="n">annotation_results</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="n">orient</span><span class="o">=</span><span class="s1">&#39;records&#39;</span><span class="p">)</span>
        <span class="c1"># update the entry in the mongo collection with the annotation results</span>
        <span class="n">geneset_annotations_by_trait</span><span class="o">.</span><span class="n">update_one</span><span class="p">(</span>
            <span class="p">{</span><span class="s1">&#39;mapped_trait_uri&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">mapped_trait_uri</span><span class="p">)},</span>
            <span class="p">{</span><span class="s1">&#39;$set&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;functional_annotation&#39;</span><span class="p">:</span> <span class="n">annotation_results_dict</span><span class="p">}},</span>
        <span class="p">)</span>
    <span class="c1"># drop members of geneset_annotations_by_trait with empty annotation</span>
    <span class="n">geneset_annotations_by_trait</span><span class="o">.</span><span class="n">delete_many</span><span class="p">(</span>
        <span class="p">{</span><span class="s1">&#39;functional_annotation&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;$in&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">[],</span> <span class="p">{}]}}</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s1">&#39;Remaining entries with functional annotation: </span><span class="si">{</span>
<span class="w">          </span><span class="n">geneset_annotations_by_trait</span><span class="o">.</span><span class="n">count_documents</span><span class="p">({})</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="p">)</span>


<span class="n">annotate_genesets_by_trait</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Number of documents in geneset_annotations_by_trait: 3047
100%|██████████| 3047/3047 [56:31&lt;00:00,  1.11s/it] 
Remaining entries with functional annotation: 1845
</pre></div>
</div>
<p>Having now annotated the gene sets with information about their biological functions, we can now move to assessing the similarity of traits based on their associated functions.</p>
</section>
<section id="mapping-pathway-information-to-traits">
<h3><a class="toc-backref" href="#id76">Mapping pathway information to traits</a><a class="headerlink" href="#mapping-pathway-information-to-traits" title="Permalink to this heading">#</a></h3>
<p>The previous analysis added a <code class="docutils literal notranslate"><span class="pre">functional</span> <span class="pre">annotation</span></code> element to each trait, which includes information about the associated pathways. While we could use this collection to obtain the mappings from traits to pathways, the deeply embedded nature of the annotation data would make the queries somewhat complicated.  Next we will use that information to generate a collection including all unique pathways, which we will then use to compute biological similarity between traits:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">COLLECTION_PATHWAYS</span> <span class="o">=</span> <span class="s1">&#39;pathways&#39;</span>

<span class="k">def</span> <span class="nf">get_pathway_info_by_trait</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">geneset_collection</span> <span class="o">=</span> <span class="n">setup_mongo_collection</span><span class="p">(</span>
        <span class="n">COLLECTION_GENESET</span><span class="p">,</span> <span class="n">clear_existing</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">pathway_collection</span> <span class="o">=</span> <span class="n">setup_mongo_collection</span><span class="p">(</span>
        <span class="n">COLLECTION_PATHWAYS</span><span class="p">,</span> <span class="n">clear_existing</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>

    <span class="c1"># loop through traits and add pathway information to the database</span>
    <span class="n">traits</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">i</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">geneset_collection</span><span class="o">.</span><span class="n">find</span><span class="p">()</span>
        <span class="k">if</span> <span class="s1">&#39;functional_annotation&#39;</span> <span class="ow">in</span> <span class="n">i</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;functional_annotation&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="p">]</span>

    <span class="k">for</span> <span class="n">trait</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">traits</span><span class="p">):</span>
        <span class="n">annotations</span> <span class="o">=</span> <span class="n">trait</span><span class="p">[</span><span class="s1">&#39;functional_annotation&#39;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">pathway</span> <span class="ow">in</span> <span class="n">annotations</span><span class="p">:</span>
            <span class="c1"># change key for clarity</span>
            <span class="n">pathway</span><span class="p">[</span><span class="s1">&#39;pathway_id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pathway</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;native&#39;</span><span class="p">)</span>

            <span class="n">pathway_collection</span><span class="o">.</span><span class="n">update_one</span><span class="p">(</span>
                <span class="p">{</span><span class="s1">&#39;pathway_id&#39;</span><span class="p">:</span> <span class="n">pathway</span><span class="p">[</span><span class="s1">&#39;pathway_id&#39;</span><span class="p">]},</span>
                <span class="p">{</span>
                    <span class="s1">&#39;$set&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">pathway</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">),</span>
                        <span class="s1">&#39;source&#39;</span><span class="p">:</span> <span class="n">pathway</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;source&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">),</span>
                        <span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="n">pathway</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;description&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">),</span>
                    <span class="p">}</span>
                <span class="p">},</span>
                <span class="n">upsert</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>


<span class="n">get_pathway_info_by_trait</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Number of documents in geneset_annotations_by_trait: 1845
Number of documents in pathways: 0
100%|██████████| 1845/1845 [00:18&lt;00:00, 98.22it/s] 
</pre></div>
</div>
</section>
<section id="generate-the-graph-database-linking-publications-pathways-to-traits">
<h3><a class="toc-backref" href="#id77">Generate the graph database linking publications pathways to traits</a><a class="headerlink" href="#generate-the-graph-database-linking-publications-pathways-to-traits" title="Permalink to this heading">#</a></h3>
<p>Graph databases are designed to store and query relational information, making them perfect for our dataset linking pathways to traits.  In the next step I created a graph database using the Neo4j database package, which involves creating a Neo4j session and then issuing a set of Cyper commands:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_neo4j_session</span><span class="p">():</span>
    <span class="k">assert</span> <span class="s1">&#39;NEO4J_PASSWORD&#39;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">,</span> <span class="s1">&#39;NEO4J_PASSWORD should be set in .env&#39;</span>
    <span class="n">neo4j_driver</span> <span class="o">=</span> <span class="n">GraphDatabase</span><span class="o">.</span><span class="n">driver</span><span class="p">(</span>
        <span class="s1">&#39;bolt://localhost:7687&#39;</span><span class="p">,</span> <span class="n">auth</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;neo4j&#39;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;NEO4J_PASSWORD&#39;</span><span class="p">])</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">neo4j_driver</span><span class="o">.</span><span class="n">session</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">build_neo4j_graph</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">geneset_collection</span> <span class="o">=</span> <span class="n">setup_mongo_collection</span><span class="p">(</span><span class="n">COLLECTION_GENESET</span><span class="p">)</span>
    <span class="n">pathway_collection</span> <span class="o">=</span> <span class="n">setup_mongo_collection</span><span class="p">(</span><span class="n">COLLECTION_PATHWAYS</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">get_neo4j_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
        <span class="c1"># Clear DB</span>
        <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;MATCH (n) DETACH DELETE n&#39;</span><span class="p">)</span>
        
        <span class="c1"># Create Indexes</span>
        <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">((</span>
          <span class="s1">&#39;CREATE CONSTRAINT IF NOT EXISTS FOR (p:Phenotype) &#39;</span>
          <span class="s1">&#39;REQUIRE p.id IS UNIQUE&#39;</span><span class="p">))</span>
        <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
          <span class="p">(</span><span class="s1">&#39;CREATE CONSTRAINT IF NOT EXISTS FOR (p:Pathway) &#39;</span>
          <span class="s1">&#39;REQUIRE p.id IS UNIQUE&#39;</span><span class="p">))</span>

        <span class="c1"># 1. Batch Import Pathways</span>
        <span class="c1"># Fetch all pathways into a list of dicts</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading pathways...&quot;</span><span class="p">)</span>
        <span class="n">pathways_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">pathway_collection</span><span class="o">.</span><span class="n">find</span><span class="p">({},</span>
          <span class="p">{</span><span class="s1">&#39;_id&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;pathway_id&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;source&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}))</span>
        
        <span class="c1"># Use UNWIND to insert all pathways in one transaction</span>
        <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            UNWIND $batch AS row</span>
<span class="s2">            MERGE (pw:Pathway {id: row.pathway_id})</span>
<span class="s2">            SET pw.name = row.name,</span>
<span class="s2">                pw.source = row.source,</span>
<span class="s2">                pw.description = row.description</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">pathways_data</span><span class="p">)</span>

        <span class="c1"># 2. Batch Import Phenotypes and Relationships</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading phenotypes and relationships...&quot;</span><span class="p">)</span>
        <span class="c1"># We need to restructure the Mongo data slightly for Neo4j consumption</span>
        <span class="n">pheno_batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">geneset_collection</span><span class="o">.</span><span class="n">find</span><span class="p">():</span>
            <span class="n">pheno_id</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="s1">&#39;mapped_trait_uri&#39;</span><span class="p">])</span>
            <span class="c1"># Extract list of pathway IDs</span>
            <span class="n">pathway_ids</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">i</span><span class="p">[</span><span class="s1">&#39;native&#39;</span><span class="p">]</span> 
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;functional_annotation&#39;</span><span class="p">,</span> <span class="p">[])</span> 
                <span class="k">if</span> <span class="s1">&#39;native&#39;</span> <span class="ow">in</span> <span class="n">i</span><span class="p">]</span>
             
            <span class="k">if</span> <span class="n">pathway_ids</span><span class="p">:</span>
                <span class="n">pheno_batch</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="n">pheno_id</span><span class="p">,</span>
                    <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">doc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;trait_name&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">),</span>
                    <span class="s1">&#39;pathway_ids&#39;</span><span class="p">:</span> <span class="n">pathway_ids</span>
                <span class="p">})</span>

        <span class="c1"># Insert Phenotypes and create edges to Pathways</span>
        <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            UNWIND $batch AS row</span>
<span class="s2">            MERGE (p:Phenotype {id: row.id})</span>
<span class="s2">            SET p.name = row.name</span>
<span class="s2">            </span>
<span class="s2">            WITH p, row</span>
<span class="s2">            UNWIND row.pathway_ids AS pw_id</span>
<span class="s2">            MATCH (pw:Pathway {id: pw_id})</span>
<span class="s2">            MERGE (p)-[:MAPPED_TO]-&gt;(pw)</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">pheno_batch</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Graph build complete.&quot;</span><span class="p">)</span>


<span class="n">build_neo4j_graph</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Number of documents in geneset_annotations_by_trait: 1845
Number of documents in pathways: 6051
Loading pathways...
Loading phenotypes and relationships...
Graph build complete.
</pre></div>
</div>
<p>Having populated the database, we can then use the <a class="reference external" href="https://neo4j.com/docs/graph-data-science/current/algorithms/node-similarity/">gds.nodeSimilarity function</a> from the Neo4j Graph Data Science library to compute the similarity of each trait in terms of their pathway overlap.  This function takes a <em>bipartite graph</em> (which is a graph that contains two sets of nodes - in our case, pathways and traits) and returns the Jaccard similarity coefficient, in which in this case reflects the ratio of common pathways to the total number of pathways for each pair of nodes. We filter out nodes that have fewer than two pathways associated with them to make the estimate more stable. (Note that here we use the term “phenotype” interchangeably with “trait”.)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">compute_phenotype_similarities</span><span class="p">(</span>
    <span class="n">graph_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;phenotype-pathway-graph&#39;</span><span class="p">,</span>
    <span class="n">min_pathways</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>

    <span class="k">with</span> <span class="n">get_neo4j_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
        <span class="c1"># 1. Clean up any existing graph with the same name</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;CALL gds.graph.drop($name)&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">graph_name</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">ClientError</span><span class="p">:</span>
            <span class="c1"># Graph did not exist, safe to ignore</span>
            <span class="k">pass</span>

        <span class="c1"># 2. Project the Graph</span>
        <span class="c1"># We project Phenotypes, Pathways, and the relationship between them.</span>
        <span class="c1"># &#39;UNDIRECTED&#39; orientation allows the algorithm to see the shared connections.</span>
        <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            CALL gds.graph.project(</span>
<span class="s2">                $graph_name,</span>
<span class="s2">                [&#39;Phenotype&#39;, &#39;Pathway&#39;],</span>
<span class="s2">                {</span>
<span class="s2">                    MAPPED_TO: {</span>
<span class="s2">                        orientation: &#39;UNDIRECTED&#39;</span>
<span class="s2">                    }</span>
<span class="s2">                }</span>
<span class="s2">            )</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="p">,</span> <span class="n">graph_name</span><span class="o">=</span><span class="n">graph_name</span><span class="p">)</span>

        <span class="c1"># 3. Run Node Similarity</span>
        <span class="c1"># We use &#39;degreeCutoff&#39; to filter out phenotypes with too few pathways </span>
        <span class="c1"># BEFORE the calculation - much faster than filtering the results.</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            CALL gds.nodeSimilarity.stream($graph_name, {</span>
<span class="s2">                degreeCutoff: $min_pathways</span>
<span class="s2">            })</span>
<span class="s2">            YIELD node1, node2, similarity</span>
<span class="s2">            </span>
<span class="s2">            // Map internal IDs back to our Phenotype IDs</span>
<span class="s2">            WITH node1, node2, similarity</span>
<span class="s2">            MATCH (p1:Phenotype), (p2:Phenotype)</span>
<span class="s2">            WHERE id(p1) = node1 AND id(p2) = node2</span>
<span class="s2">            </span>
<span class="s2">            RETURN p1.id AS phenotype1, p2.id AS phenotype2, similarity</span>
<span class="s2">            ORDER BY similarity DESC</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="p">,</span> <span class="n">graph_name</span><span class="o">=</span><span class="n">graph_name</span><span class="p">,</span> <span class="n">min_pathways</span><span class="o">=</span><span class="n">min_pathways</span><span class="p">)</span>

        <span class="c1"># 4. Convert to DataFrame</span>
        <span class="c1"># result.data() fetches all records into a list of dictionaries</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">data</span><span class="p">())</span>
        
        <span class="c1"># 5. Cleanup: Drop the graph to free up memory</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;CALL gds.graph.drop($name)&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">graph_name</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">ClientError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="k">return</span> <span class="n">df</span>


<span class="n">similarity_result_df</span> <span class="o">=</span> <span class="n">compute_phenotype_similarities</span><span class="p">()</span>
</pre></div>
</div>
<p>Now that we have the similarity between phenotypes based on their biological functions, we can move on to assessing their similarity based on associated publications.</p>
</section>
<section id="obtaining-literature-related-to-traits">
<h3><a class="toc-backref" href="#id78">Obtaining literature related to traits</a><a class="headerlink" href="#obtaining-literature-related-to-traits" title="Permalink to this heading">#</a></h3>
<p>To assess semantic similarity between traits we need to obtain abstracts related to each trait.  To do this, we first wish to obtain any synonyms for the traits, to maximize the effectiveness of the search.  We can obtain these from the <a class="reference external" href="https://www.ebi.ac.uk/ols4/api-docs">EBI Ontology Search API</a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">COLLECTION_TRAIT_INFO</span> <span class="o">=</span> <span class="s1">&#39;trait_info_by_trait&#39;</span>

<span class="k">def</span> <span class="nf">get_trait_info_from_ols</span><span class="p">(</span>
    <span class="n">client_url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;http://www.ebi.ac.uk/ols&#39;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="c1"># use EBI OLS API to get trait information for all traits</span>
    <span class="n">trait_info_by_trait</span> <span class="o">=</span> <span class="n">setup_mongo_collection</span><span class="p">(</span>
        <span class="n">collection_name</span><span class="o">=</span><span class="n">COLLECTION_TRAIT_INFO</span>
    <span class="p">)</span>

    <span class="n">trait_info_by_trait</span><span class="o">.</span><span class="n">create_index</span><span class="p">(</span><span class="s1">&#39;trait_uri&#39;</span><span class="p">,</span> <span class="n">unique</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">geneset_annotations_by_trait</span> <span class="o">=</span> <span class="n">setup_mongo_collection</span><span class="p">(</span>
        <span class="n">collection_name</span><span class="o">=</span><span class="n">COLLECTION_GENESET</span>
    <span class="p">)</span>

    <span class="c1"># get all unique trait URIs that are not already in the collection</span>
    <span class="c1"># use lstrip because many have a leading space</span>
    <span class="n">unique_trait_uris</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">i</span><span class="o">.</span><span class="n">lstrip</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">geneset_annotations_by_trait</span><span class="o">.</span><span class="n">distinct</span><span class="p">(</span><span class="s1">&#39;mapped_trait_uri&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">trait_info_by_trait</span><span class="o">.</span><span class="n">count_documents</span><span class="p">({</span><span class="s1">&#39;trait_uri&#39;</span><span class="p">:</span> <span class="n">i</span><span class="o">.</span><span class="n">lstrip</span><span class="p">()})</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_trait_uris</span><span class="p">)</span><span class="si">}</span><span class="s1"> un-annotated trait URIs.&#39;</span><span class="p">)</span>

    <span class="n">client</span> <span class="o">=</span> <span class="n">ols_client</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span><span class="n">client_url</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">trait_uri</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">unique_trait_uris</span><span class="p">):</span>
        <span class="n">trait_id</span> <span class="o">=</span> <span class="n">trait_uri</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">trait_uri</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">trait_uri</span><span class="p">)</span>
        <span class="c1"># skip if already in the collection</span>
        <span class="k">if</span> <span class="n">trait_info_by_trait</span><span class="o">.</span><span class="n">count_documents</span><span class="p">({</span><span class="s1">&#39;trait_uri&#39;</span><span class="p">:</span> <span class="n">trait_uri</span><span class="p">})</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">term_data</span> <span class="o">=</span> <span class="n">get_info_from_ols</span><span class="p">(</span><span class="n">trait_id</span><span class="p">,</span> <span class="n">client</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">HTTPError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;HTTPError for </span><span class="si">{</span><span class="n">trait_uri</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="k">continue</span>
        <span class="k">if</span> <span class="n">term_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;No data returned for </span><span class="si">{</span><span class="n">trait_uri</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="k">continue</span>
        <span class="n">trait_info_by_trait</span><span class="o">.</span><span class="n">update_one</span><span class="p">(</span>
            <span class="p">{</span><span class="s1">&#39;trait_uri&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">trait_uri</span><span class="p">)},</span>
            <span class="p">{</span><span class="s1">&#39;$set&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;trait_uri&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">trait_uri</span><span class="p">),</span> <span class="s1">&#39;trait_info&#39;</span><span class="p">:</span> <span class="n">term_data</span><span class="p">}},</span>
            <span class="n">upsert</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>


<span class="n">get_trait_info_from_ols</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Number of documents in geneset_annotations_by_trait: 1845
Number of documents in pathways: 0
100%|██████████| 1845/1845 [00:18&lt;00:00, 98.22it/s] 
</pre></div>
</div>
<p>We then use the <code class="docutils literal notranslate"><span class="pre">Biopython.Entrez</span></code> module to search PubMed for each of the traits, along with any synonyms, obtaining a maximum of 100 abstracts for each query:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">COLLECTION_PMID_BY_TRAIT</span> <span class="o">=</span> <span class="s1">&#39;pmids_by_trait&#39;</span>

<span class="k">def</span> <span class="nf">get_pmids_for_traits</span><span class="p">(</span>
    <span class="n">n_abstracts_per_trait</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

    <span class="n">pmid_collection</span> <span class="o">=</span> <span class="n">setup_mongo_collection</span><span class="p">(</span><span class="n">COLLECTION_PMID_BY_TRAIT</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">pmid_collection</span><span class="o">.</span><span class="n">create_index</span><span class="p">(</span>
        <span class="p">[(</span><span class="s1">&#39;trait_uri&#39;</span><span class="p">,</span> <span class="n">pymongo</span><span class="o">.</span><span class="n">ASCENDING</span><span class="p">)],</span> <span class="n">unique</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="c1"># get all entries from the trait_info_by_trait collection and pull out </span>
    <span class="c1"># the label and synonyms to use as pubmed search terms</span>
    <span class="n">trait_info_collection</span> <span class="o">=</span> <span class="n">setup_mongo_collection</span><span class="p">(</span><span class="n">COLLECTION_TRAIT_INFO</span><span class="p">)</span>
    <span class="n">db_result</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">trait_info_collection</span><span class="o">.</span><span class="n">find</span><span class="p">({}))</span>

    <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">db_result</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Searching PubMed&#39;</span><span class="p">):</span>
        <span class="n">trait_uri</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;trait_uri&#39;</span><span class="p">]</span>
        <span class="n">lbl</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;trait_info&#39;</span><span class="p">][</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>
        <span class="n">synonyms</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;trait_info&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;synonyms&#39;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="c1"># create a pubmed query using the label and synonyms</span>
        <span class="n">query_terms</span> <span class="o">=</span> <span class="p">[</span><span class="n">lbl</span><span class="p">]</span> <span class="o">+</span> <span class="n">synonyms</span>
        <span class="n">query</span> <span class="o">=</span> <span class="s1">&#39; OR &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s1">&#39;&quot;</span><span class="si">{</span><span class="n">term</span><span class="si">}</span><span class="s1">&quot;&#39;</span> <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">query_terms</span><span class="p">])</span>

        <span class="n">existing_entry</span> <span class="o">=</span> <span class="n">pmid_collection</span><span class="o">.</span><span class="n">find_one</span><span class="p">({</span><span class="s1">&#39;trait_uri&#39;</span><span class="p">:</span> <span class="n">trait_uri</span><span class="p">})</span>
        <span class="c1"># Skip existing entry if pmid entry is not empty</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">existing_entry</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="n">existing_entry</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;pmids&#39;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">existing_entry</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;pmids&#39;</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;PMIDs already exist for </span><span class="si">{</span><span class="n">lbl</span><span class="si">}</span><span class="s1">, skipping...&#39;</span><span class="p">)</span>
            <span class="k">continue</span>
        <span class="c1"># run pubmed search - retry up to 3 times if it fails</span>
        <span class="n">pmids</span> <span class="o">=</span> <span class="n">run_pubmed_search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">retmax</span><span class="o">=</span><span class="n">n_abstracts_per_trait</span><span class="p">,</span>
          <span class="n">max_retries</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">pmids</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">pmids</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
          <span class="k">continue</span>
        <span class="n">pmid_collection</span><span class="o">.</span><span class="n">update_one</span><span class="p">(</span>
            <span class="p">{</span><span class="s1">&#39;trait_uri&#39;</span><span class="p">:</span> <span class="n">trait_uri</span><span class="p">},</span>
            <span class="p">{</span><span class="s1">&#39;$set&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">lbl</span><span class="p">,</span> <span class="s1">&#39;pmids&#39;</span><span class="p">:</span> <span class="n">pmids</span><span class="p">,</span> <span class="s1">&#39;search_query&#39;</span><span class="p">:</span> <span class="n">query</span><span class="p">}},</span>
            <span class="n">upsert</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>


<span class="n">get_pmids_for_traits</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Number of documents in pmids_by_trait: 0
Number of documents in trait_info_by_trait: 1590
Searching PubMed: 100%|██████████| 1590/1590 [13:58&lt;00:00,  1.90it/s]
</pre></div>
</div>
<p>We then identify all of the unique Pubmed IDs (PMIDs) across these queries and fetch the full Pubmed record (including the title and abstract, which we will use in our semantic analysis) for each of them, placing them in a new collection:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">COLLECTION_PUBMED</span> <span class="o">=</span> <span class="s1">&#39;pubmed_abstracts&#39;</span>


<span class="k">def</span> <span class="nf">fetch_and_store_pubmed_abstracts</span><span class="p">(</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

    <span class="n">pubmed_collection</span> <span class="o">=</span> <span class="n">setup_mongo_collection</span><span class="p">(</span>
        <span class="n">COLLECTION_PUBMED</span><span class="p">,</span> <span class="n">clear_existing</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">pubmed_collection</span><span class="o">.</span><span class="n">create_index</span><span class="p">([(</span><span class="s1">&#39;PMID&#39;</span><span class="p">,</span> <span class="n">pymongo</span><span class="o">.</span><span class="n">ASCENDING</span><span class="p">)],</span> <span class="n">unique</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># remove any PMIDs already in the pubmed_collection</span>
    <span class="n">existing_pmids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">pubmed_collection</span><span class="o">.</span><span class="n">find</span><span class="p">({},</span> <span class="p">{</span><span class="s1">&#39;PMID&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}):</span>
        <span class="n">existing_pmids</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">entry</span><span class="p">[</span><span class="s1">&#39;PMID&#39;</span><span class="p">])</span>

    <span class="n">pmids_to_fetch</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">pmid</span>
        <span class="k">for</span> <span class="n">pmid</span> <span class="ow">in</span> <span class="n">get_unique_pmids_from_trait_collection</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">pmid</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">existing_pmids</span>
    <span class="p">]</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pmids_to_fetch</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;All PMIDs are already fetched. Skipping.&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Fetching </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">pmids_to_fetch</span><span class="p">)</span><span class="si">}</span><span class="s1"> PMIDs...&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span>
        <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pmids_to_fetch</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">),</span>
        <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Fetching PubMed abstracts&#39;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">pmids_to_fetch</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">pubmed_records</span> <span class="o">=</span> <span class="n">fetch_pubmed_records</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">retmax</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">parsed_records</span> <span class="o">=</span> <span class="n">parse_pubmed_query_result</span><span class="p">(</span><span class="n">pubmed_records</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">parsed_records</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;No new records to insert for batch </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">batch_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
            <span class="k">continue</span>
        <span class="n">pubmed_collection</span><span class="o">.</span><span class="n">insert_many</span><span class="p">(</span><span class="n">parsed_records</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="c1"># print(f&quot;Inserted {len(parsed_records)} abstracts&quot;)</span>


<span class="n">fetch_and_store_pubmed_abstracts</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Number of documents in pubmed_abstracts: 0
Number of documents in pmids_by_trait: 1590
Fetching 106387 PMIDs...
</pre></div>
</div>
</section>
<section id="add-documents-to-vector-database">
<h3><a class="toc-backref" href="#id79">Add documents to vector database</a><a class="headerlink" href="#add-documents-to-vector-database" title="Permalink to this heading">#</a></h3>
<p>We want to use the documents downloaded from Pubmed for each trait to compute the semantic similarity between traits.  This is a good application for a <em>vector database</em>, which can ingest documents, embed them into a vector space, which we can then use to perform similarity computations between documents based on their vector embeddings.  We will use ChromaDB which is a popular open-source vector database.  By default ChromaDB uses the <em>all-MiniLM-L6-v2</em> embedding model from the <a class="reference external" href="https://www.sbert.net/">Sentence Transformers</a> package, but we will instead use the more powerful <code class="docutils literal notranslate"><span class="pre">text-embedding-3-large</span></code> via the OpenAI API.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_chromadb_collection</span><span class="p">(</span><span class="n">collection_name</span><span class="o">=</span><span class="s1">&#39;pubmed_docs&#39;</span><span class="p">,</span> 
    <span class="n">path</span><span class="o">=</span><span class="s1">&#39;../../data/chroma_data&#39;</span><span class="p">,</span>
    <span class="n">embedding</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;text-embedding-3-large&quot;</span><span class="p">):</span>

    <span class="k">assert</span> <span class="s1">&#39;OPENAI&#39;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">,</span> <span class="s1">&#39;OPENAI API key should be set in .env&#39;</span>
    <span class="k">if</span> <span class="n">embedding</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">embedding_function</span> <span class="o">=</span> <span class="n">embedding_functions</span><span class="o">.</span><span class="n">OpenAIEmbeddingFunction</span><span class="p">(</span>
                    <span class="n">api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;OPENAI&#39;</span><span class="p">),</span>
                    <span class="n">model_name</span><span class="o">=</span><span class="n">embedding</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">embedding_function</span> <span class="o">=</span> <span class="n">embedding_functions</span><span class="o">.</span><span class="n">SentenceTransformerEmbeddingFunction</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">)</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">PersistentClient</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">)</span>
    <span class="c1"># check if collection exists, if not create it</span>
    <span class="k">if</span> <span class="n">collection_name</span> <span class="ow">in</span> <span class="p">[</span><span class="n">col</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">client</span><span class="o">.</span><span class="n">list_collections</span><span class="p">()]:</span>
        <span class="k">return</span> <span class="n">client</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">collection_name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Created new collection: </span><span class="si">{</span><span class="n">collection_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">client</span><span class="o">.</span><span class="n">create_collection</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">collection_name</span><span class="p">,</span> <span class="n">embedding_function</span><span class="o">=</span><span class="n">embedding_function</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">add_pubmed_abstracts_to_chromadb</span><span class="p">(</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

    <span class="n">pubmed_collection</span> <span class="o">=</span> <span class="n">setup_mongo_collection</span><span class="p">(</span>
        <span class="n">COLLECTION_PUBMED</span><span class="p">,</span> <span class="n">clear_existing</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>

    <span class="n">collection</span> <span class="o">=</span> <span class="n">get_chromadb_collection</span><span class="p">()</span>
    <span class="c1"># get ids (pmid) and documents (title + abstract) from pubmed_collection</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">documents</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">pubmed_collection</span><span class="o">.</span><span class="n">find</span><span class="p">({}):</span>
        <span class="n">full_text</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="n">entry</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;abstract&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="n">documents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_text</span><span class="p">)</span>
        <span class="n">ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">entry</span><span class="p">[</span><span class="s1">&#39;PMID&#39;</span><span class="p">]))</span>

    <span class="c1"># exclude ids that are already in the chromadb collection</span>
    <span class="n">existing_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">collection</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[])[</span><span class="s1">&#39;ids&#39;</span><span class="p">])</span>
    <span class="n">ids_to_add</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">documents_to_add</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">id_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ids</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">id_</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">existing_ids</span><span class="p">:</span>
            <span class="n">ids_to_add</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">id_</span><span class="p">)</span>
            <span class="n">documents_to_add</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">documents</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="c1"># add in batches</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ids_to_add</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">batch_ids</span> <span class="o">=</span> <span class="n">ids_to_add</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">batch_documents</span> <span class="o">=</span> <span class="n">documents_to_add</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">collection</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ids</span><span class="o">=</span><span class="n">batch_ids</span><span class="p">,</span> <span class="n">documents</span><span class="o">=</span><span class="n">batch_documents</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Added </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_ids</span><span class="p">)</span><span class="si">}</span><span class="s1"> documents to chromadb collection&#39;</span><span class="p">)</span>


<span class="n">add_pubmed_abstracts_to_chromadb</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Number of documents in pubmed_abstracts: 106120
Using existing collection: pubmed_docs
</pre></div>
</div>
<p>We then compute the vector similarity between the document embeddings associated with each pair of traits. We compute the Euclidean distance between each pair of documents associated with both traits, and then compute the mean across the documents.  These are added to the data frame that also contains the pathway distances, for each in subsequent analyses:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">text_similarity_df</span> <span class="o">=</span> <span class="n">compute_text_similarities</span><span class="p">(</span><span class="n">similarity_result_df</span><span class="p">)</span>
</pre></div>
</div>
<p>We now have the semantic and biological similarity values for each pair of traits in a single data frame, which we can use for our statistical analysis.</p>
</section>
<section id="analyzing-and-visualizing-the-results">
<h3><a class="toc-backref" href="#id80">Analyzing and visualizing the results</a><a class="headerlink" href="#analyzing-and-visualizing-the-results" title="Permalink to this heading">#</a></h3>
<p>We can first visualize the relationship between semantic and biological similarity:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">text_similarity_df</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s1">&#39;pathway_similarity&#39;</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;text_similarity&#39;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
<span class="n">corr_value</span> <span class="o">=</span> <span class="n">text_similarity_df</span><span class="p">[</span><span class="s2">&quot;pathway_similarity&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span>
    <span class="n">text_similarity_df</span><span class="p">[</span><span class="s2">&quot;text_similarity&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span>
  <span class="sa">f</span><span class="s1">&#39;Pathway Similarity vs Text Similarity (r=</span><span class="si">{</span><span class="n">corr_value</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">)&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
<figure class="align-default" id="pathwaysimilarity-fig">
<a class="reference internal image-reference" href="_images/pathway_vs_text_similarity.png"><img alt="Pathway versus semantic similarity across traits" src="_images/pathway_vs_text_similarity.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 11 </span><span class="caption-text">A scatterplot of biological similarity (estimated as overlap in pathways) versus semantic similarity (estimated as embedding distance of Pubmed abstracts) on the GWAS dataset.</span><a class="headerlink" href="#pathwaysimilarity-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>There is a small but robust correlation between these two similarity measures. In order to more accurately estimate this association we need to take into account the fact that different documents vary in their overall similarity by including a <em>random effect</em> of document within a mixed effects model.  We use the <code class="docutils literal notranslate"><span class="pre">lmer()</span></code> function from the R <code class="docutils literal notranslate"><span class="pre">lme4</span></code> package, via the R magic within Jupyter:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>%%R -i text_similarity_df

if (!requireNamespace(&quot;lme4&quot;, quietly = TRUE)) {
    install.packages(&quot;lme4&quot;)
}
if (!requireNamespace(&quot;lmerTest&quot;, quietly = TRUE)) {
    install.packages(&quot;lmerTest&quot;)
}
library(lme4)
library(lmerTest)

model &lt;- lmer(pathway_similarity ~ text_similarity  + (1 | phenotype1) + (1 | phenotype2), data = text_similarity_df)
summary(model)  
</pre></div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
lmerModLmerTest]
Formula: pathway_similarity ~ text_similarity + (1 | phenotype1) + (1 |  
    phenotype2)
   Data: text_similarity_df

REML criterion at convergence: -9301.4

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-5.4960 -0.4077 -0.0685  0.2873  8.9175 

Random effects:
 Groups     Name        Variance Std.Dev.
 phenotype1 (Intercept) 0.040351 0.20087 
 phenotype2 (Intercept) 0.009485 0.09739 
 Residual               0.007039 0.08390 
Number of obs: 6904, groups:  phenotype1, 981; phenotype2, 905

Fixed effects:
                 Estimate Std. Error        df t value Pr(&gt;|t|)    
(Intercept)     2.484e-01  7.802e-03 1.507e+03   31.83   &lt;2e-16 ***
text_similarity 3.666e-01  2.532e-02 5.858e+03   14.48   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Correlation of Fixed Effects:
            (Intr)
text_smlrty -0.334
</pre></div>
</div>
<p>This result is statistically significant, but we also want to ask how practically significant it is by looking at the amount of variance accounted for by the model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>%%R

if (!requireNamespace(&quot;MuMIn&quot;, quietly = TRUE)) {
    install.packages(&quot;MuMIn&quot;)
}

library(MuMIn)
r.squaredGLMM(model)
</pre></div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="w">            </span><span class="n">R2m</span><span class="w">       </span><span class="n">R2c</span>
<span class="p">[</span><span class="m">1</span><span class="p">,]</span><span class="w"> </span><span class="m">0.01068788</span><span class="w"> </span><span class="m">0.8775626</span>
</pre></div>
</div>
<p>For a mixed effect model there are two R-squared values: The <em>conditional</em> R-squared (R2c), which refers to the total variance accounted for by both fixed and random effects, and the <em>marginal</em> R-squared (R2m) that refers to the variance accounted for by the fixed effects, which is the figure of interest here.  This shows that while the association is strongly statistically significant, semantic similarity only accounts for about 1% of the variability in biological similarity, and thus is not a particularly strong predictor in practice.  The high conditional R-squared demonstrates that the variability in the data is dominated by document-level differences in similarity, such that documents vary in the degree to which they are more generally similar to others on average.</p>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="id8"><span class="brackets"><a class="fn-backref" href="#id2">1</a></span></dt>
<dd><p>Note that the term “license” is often used to describe these data usage agreements, but this terminology is technically inappropriate in jurisdictions such as the U.S. where most data are treated as “facts” and thus are not subject to intellectual property laws (such as copyright laws).</p>
</dd>
</dl>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="project_organization.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Project structure and management</p>
      </div>
    </a>
    <a class="right-next"
       href="bibliography.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Bibliography</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principles-of-data-management">Principles of data management</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fair-principles">The FAIR Principles</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#findable">Findable</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#accessible">Accessible</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#interoperable">Interoperable</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#reusable">Reusable</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-data-lifecycle">The data lifecycle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#planning-a-study">Planning a study</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-management-plans">Data Management Plans</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collecting-data">Collecting data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#storing-data">Storing data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#file-system-storage">File system storage</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#storage-on-a-pc-laptop-hard-drive">Storage on a PC/laptop hard drive</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#storage-on-a-network-drive">Storage on a network drive</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cloud-drives">Cloud drives</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cloud-object-storage">Cloud object storage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#database-storage">Database storage</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#relational-databases">Relational databases</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#acid">ACID</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#analytic-databases">Analytic databases</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#nosql-databases">NoSQL databases</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#document-stores">Document stores</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-databases">Graph databases</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-databases">Vector databases</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#managing-original-data">Managing original data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#immutable-storage">Immutable storage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backup">Backup</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-access">Data access</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-formats-and-file-types">Data formats and file types</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tabular-data">Tabular data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#long-wide-and-tidy-tabular-data">Long, wide, and tidy tabular data</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#column-headers-are-values-not-variable-names">Column headers are values, not variable names</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-variables-are-stored-in-one-column">Multiple variables are stored in one column</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#variables-are-stored-in-both-rows-and-columns">Variables are stored in both rows and columns</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#single-type-of-observational-unit-spread-across-multiple-tables">Single type of observational unit spread across multiple tables</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tabular-file-formats">Tabular file formats</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#russ-s-first-law-of-tabular-data-management">Russ’s First Law of Tabular Data Management</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multidimensional-array-data">Multidimensional array data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#multidimensional-array-file-formats">Multidimensional array file formats</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#symmetrical-matrices">Symmetrical matrices</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#network-graph-data">Network/graph data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-data-file-formats">Graph data file formats</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specialized-data-formats">Specialized data formats</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-organization-schemes">Data organization schemes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#file-granularity">File granularity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-file-folder-naming-conventions">Data file/folder naming conventions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata">Metadata</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-file-formats">Metadata file formats</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-documentation">Data documentation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-dictionaries">Data dictionaries</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#codebooks">Codebooks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#provenance">Provenance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-of-sensitive-data">Handling of sensitive data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-security">Data security</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deidentification">Deidentification</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#anonymization">Anonymization</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#version-control-for-data">Version control for data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-git-for-data-version-control">Using git for data version control</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-datalad-for-version-control-on-larger-datasets">Using Datalad for version control on larger datasets</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-local-datalad-dataset">Creating a local Datalad dataset</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#modifying-files">Modifying files</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pushing-data-to-a-remote-repository">Pushing data to a remote repository</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#archiving-data">Archiving data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix-an-example-of-database-usage">Appendix: An example of database usage</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-gwas-data-to-a-document-store">Adding GWAS data to a document store</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#annotating-gene-sets">Annotating gene sets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mapping-pathway-information-to-traits">Mapping pathway information to traits</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-graph-database-linking-publications-pathways-to-traits">Generate the graph database linking publications pathways to traits</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#obtaining-literature-related-to-traits">Obtaining literature related to traits</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#add-documents-to-vector-database">Add documents to vector database</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analyzing-and-visualizing-the-results">Analyzing and visualizing the results</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Russell Poldrack et al.
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>