

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Software testing &#8212; Better Code, Better Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'testing';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Bibliography" href="bibliography.html" />
    <link rel="prev" title="Principles of software engineering" href="software_engineering.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="frontmatter.html">
  
  
  
  
  
  
    <p class="title logo__title">Better Code, Better Science</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="frontmatter.html">
                    Better Code, Better Science
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="essential_tools_and_techniques.html">Essential tools and techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="software_engineering.html">Principles of software engineering</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Software testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/poldrack/BetterCodeBetterScience" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/poldrack/BetterCodeBetterScience/issues/new?title=Issue%20on%20page%20%2Ftesting.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/testing.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Software testing</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-use-software-tests">Why use software tests?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-tests">Types of tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unit-tests">Unit tests</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integration-tests">Integration tests</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-anatomy-of-a-test">The anatomy of a test</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#when-to-write-tests">When to write tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bug-driven-testing-any-time-you-encounter-a-bug-write-a-test">Bug-driven testing: Any time you encounter a bug, write a test</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-structure-of-a-good-test">The structure of a good test</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-against-the-interface-not-the-implementation">Test against the interface, not the implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tests-should-be-independent">Tests should be independent</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#testing-frameworks">Testing frameworks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#potential-problems-with-ai-generated-tests">Potential problems with AI-generated tests</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-driven-development-and-ai-assisted-coding">Test-driven development and AI-assisted coding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-coverage">Test coverage</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-fixtures">Test fixtures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mocking">Mocking</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="software-testing">
<h1>Software testing<a class="headerlink" href="#software-testing" title="Permalink to this heading">#</a></h1>
<p>Tests define the expected behavior of code, and detect when the code doesn’t match that expected behavior.</p>
<p>One useful analogy for software testing comes from the biosciences.  Think for a moment about the rapid COVID-19 tests that we  all came to know during the pandemic.  These tests had two lines, one of which was a <em>control</em> line; if this line didn’t show up, then that meant that the test was not functioning as expected.  This is known as a <em>positive control</em> because it assesses the test’s ability to identify a positive response<a class="footnote-reference brackets" href="#id3" id="id1">1</a>.  Other tests also include <em>negative controls</em>, which ensure that the test returns a negative result when it should.</p>
<p>By analogy, we can think of software tests as being either positive or negative controls for the expected outcome of a software component.  A positive test assesses whether, given a particular valid input, the component returns the correct output.  A negative test assesses whether, in the absence of valid input, the component correctly returns the appropriate error message or null result.</p>
<section id="why-use-software-tests">
<h2>Why use software tests?<a class="headerlink" href="#why-use-software-tests" title="Permalink to this heading">#</a></h2>
<p>The most obvious reason to write tests for code is to make sure that the answers that the code gives you are correct.  This becomes increasingly important as AI assistants write more of the code, to the degree that testing is becoming <em>more important</em> than code generation as a skill for generating good scientific code.  But creating correct code is far from the only reason for writing tests.</p>
<p>A second reason for testing was highlighted in our earlier discussion of test-driven development.  Tests can provide the coder with a measure of task completion; when the tests pass, the job is done, other than refactoring the code to make it cleaner and more robust.  Writing tests make one think harder about what exactly they want/need the code to do, and to specify those goals in as clear a way as possible.  Focusing on tests can help keep the coder’s “eyes on the MVP prize” and prevent generating too much extraneous code (“gold plating”).</p>
<p>A third reason to write tests is that they can help drive modularity in the code.  It’s much easier to write tests for a simple function that does a single thing than for a complex function with many different roles.  Testing can also help drive modularity by causing you to think more clearly about what a function does when developing the test; the inability to easily write a test for a function can suggest that the function might be overly complex and should be refactored. In this way, writing tests can give us useful insights into the structure of the code.</p>
<p>A final reason to write tests is that they make it much easier to make changes to the code.  Without a robust test suite, one is always left worried that changing some aspect of the code will have unexpected effects on its former behavior (known as a “regression”).  Tests can provide you with the comfort you need to make changes, knowing that you will detect any untoward effects your changes might have.  This includes refactoring, where the changes are not meant to modify the function but simply to make the code more robust and readable.</p>
</section>
<section id="types-of-tests">
<h2>Types of tests<a class="headerlink" href="#types-of-tests" title="Permalink to this heading">#</a></h2>
<section id="unit-tests">
<h3>Unit tests<a class="headerlink" href="#unit-tests" title="Permalink to this heading">#</a></h3>
<p>Unit tests are the bread and butter of software testing.  They are meant to assess whether individual software components (in the case of Python, functions, classes, and methods) perform as expected.  This includes both assessing whether the component performs as it is supposed to perform given a particular input, but also assessing whether it performs correctly under boundary conditions or problematic conditions, where the correct response is often to raise an exception.  A major goal of unit testing in the latter case is preventing “garbage in, garbage out” behavior.  For example, say that we are testing a function that takes in two matrices, and that the size of these matrices along their first dimension is assumed to match.  In this case, we would want to test to make sure that if the function is provided with two matrices that mismatch in their first dimension, the function will respond by raising an exception rather than by giving back an answer that is incorrect or nonsensical (such as <em>NaN</em>, or “not a number”).  That is, we want to aim for “garbage in, exception out” behavior.</p>
</section>
<section id="integration-tests">
<h3>Integration tests<a class="headerlink" href="#integration-tests" title="Permalink to this heading">#</a></h3>
<p>As the name suggests, an integration test assesses whether the entire application works as it should, integrating all of the components that were tested via unit testing.</p>
<p>One simple type of integration test is a “smoke test”.  This name <a class="reference external" href="https://learn.microsoft.com/en-us/previous-versions/ms182613(v=vs.80)">apparently</a> derives from the computer hardware industry, where one often performs an initial sanity test on an electronic component by plugging it in and seeing if it smokes.  In coding, a smoke test is a simple sanity check meant to ensure that the entire application runs without crashing.  This is usually accomplished by running a top-level function that exercises the entire application.  Smoke tests are useful for quickly identifying major problems, but they don’t actually test whether the application performs its function correctly.  They can be especially useful for large applications, where the full test suite may take hours to run. An initial smoke test can determine whether something is broken downstream, saving lots of wasted testing time.</p>
<p>Full integration tests assess the function of the entire application; one can think of them as unit tests where the unit is the entire application. Just as with unit tests, we want integration tests that both confirm proper operation under intended conditions, as well as confirming proper behavior (such as exiting with an error message) under improper conditions.</p>
</section>
</section>
<section id="the-anatomy-of-a-test">
<h2>The anatomy of a test<a class="headerlink" href="#the-anatomy-of-a-test" title="Permalink to this heading">#</a></h2>
<p>A test is generally structured as a function that executes without raising an exception as long as the code behaves in an expected way.  Let’s say that we want to generate a function that returns the escape velocity of a planet:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">escape_velocity</span><span class="p">(</span><span class="n">mass</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">radius</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">G</span><span class="o">=</span><span class="mf">6.67430e-11</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the escape velocity from a celestial body, given its mass and radius.</span>

<span class="sd">    Args:</span>
<span class="sd">    mass (float): Mass of the celestial body in kg.</span>
<span class="sd">    radius (float): Radius of the celestial body in meters.</span>

<span class="sd">    Returns:</span>
<span class="sd">    float: Escape velocity in m/s.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">G</span> <span class="o">*</span> <span class="n">mass</span> <span class="o">/</span> <span class="n">radius</span><span class="p">)</span>
</pre></div>
</div>
<p>We can then generate a test to determine whether the value returned by our function matches the known value for a given planet:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_escape_velocity</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Test the escape_velocity function with known values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mass_earth</span> <span class="o">=</span> <span class="mf">5.972e24</span>  <span class="c1"># Earth mass in kg</span>
    <span class="n">radius_earth</span> <span class="o">=</span> <span class="mf">6.371e6</span>  <span class="c1"># Earth radius in meters</span>
    <span class="n">ev_expected</span> <span class="o">=</span> <span class="mf">11186.0</span>  <span class="c1"># Expected escape velocity for Earth in m/s</span>
    <span class="n">ev_computed</span> <span class="o">=</span> <span class="n">escape_velocity</span><span class="p">(</span><span class="n">mass_earth</span><span class="p">,</span> <span class="n">radius_earth</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">ev_expected</span><span class="p">,</span> <span class="n">ev_computed</span><span class="p">),</span> <span class="s2">&quot;Test failed!&quot;</span>
</pre></div>
</div>
<p>We can run this using <code class="docutils literal notranslate"><span class="pre">pytest</span></code> (more about this later), which tells us that the test passes:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>❯<span class="w"> </span>pytest<span class="w"> </span>src/BetterCodeBetterScience/escape_velocity.py
<span class="o">======================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">======================</span>

src/BetterCodeBetterScience/escape_velocity.py<span class="w"> </span>..<span class="w">          </span><span class="o">[</span><span class="m">100</span>%<span class="o">]</span>

<span class="o">=======================</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>passed<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.10s<span class="w"> </span><span class="o">=======================</span>
</pre></div>
</div>
<p>If the returned value didn’t match the known value (within a given level of tolerance, which is handled by <code class="docutils literal notranslate"><span class="pre">np.allclose()</span></code>), then the assertion will fail and raise an exception, causing the test to fail.  For example, if we had mis-specified the expected value as 1186.0, we would have seen an error like this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>❯<span class="w"> </span>pytest<span class="w"> </span>src/BetterCodeBetterScience/escape_velocity.py
<span class="o">======================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">======================</span>

src/BetterCodeBetterScience/escape_velocity.py<span class="w"> </span>F<span class="w">          </span><span class="o">[</span><span class="m">100</span>%<span class="o">]</span>

<span class="o">===========================</span><span class="w"> </span><span class="nv">FAILURES</span><span class="w"> </span><span class="o">===========================</span>
_____________________<span class="w"> </span>test_escape_velocity<span class="w"> </span>_____________________

<span class="w">    </span>def<span class="w"> </span>test_escape_velocity<span class="o">()</span>:
<span class="w">        </span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        Test the escape_velocity function with known values.</span>
<span class="s2">        &quot;&quot;&quot;</span>
<span class="w">        </span><span class="nv">mass_earth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span>.972e24<span class="w">  </span><span class="c1"># Earth mass in kg</span>
<span class="w">        </span><span class="nv">radius_earth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">6</span>.371e6<span class="w">  </span><span class="c1"># Earth radius in meters</span>
<span class="w">        </span><span class="nv">ev_expected</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1186</span>.0<span class="w"> </span><span class="c1"># 11186.0  # Expected escape velocity for Earth in m/s</span>
<span class="w">        </span><span class="nv">ev_computed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>escape_velocity<span class="o">(</span>mass_earth,<span class="w"> </span>radius_earth<span class="o">)</span>
&gt;<span class="w">       </span>assert<span class="w"> </span>np.allclose<span class="o">(</span>ev_expected,<span class="w"> </span>ev_computed<span class="o">)</span>,<span class="w"> </span><span class="s2">&quot;Test failed!&quot;</span>
E<span class="w">       </span>AssertionError:<span class="w"> </span>Test<span class="w"> </span>failed!
E<span class="w">       </span>assert<span class="w"> </span>False
E<span class="w">        </span>+<span class="w">  </span>where<span class="w"> </span><span class="nv">False</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>&lt;<span class="k">function</span><span class="w"> </span>allclose<span class="w"> </span>at<span class="w"> </span>0x101403370&gt;<span class="o">(</span><span class="m">1186</span>.0,<span class="w"> </span><span class="m">11185</span>.97789184991<span class="o">)</span>
E<span class="w">        </span>+<span class="w">    </span>where<span class="w"> </span>&lt;<span class="k">function</span><span class="w"> </span>allclose<span class="w"> </span>at<span class="w"> </span>0x101403370&gt;<span class="w"> </span><span class="o">=</span><span class="w"> </span>np.allclose

src/BetterCodeBetterScience/escape_velocity.py:26:<span class="w"> </span><span class="nv">AssertionError</span>
<span class="o">=====================</span><span class="w"> </span>short<span class="w"> </span><span class="nb">test</span><span class="w"> </span>summary<span class="w"> </span><span class="nv">info</span><span class="w"> </span><span class="o">=====================</span>
FAILED<span class="w"> </span>src/BetterCodeBetterScience/escape_velocity.py::test_escape_velocity<span class="w"> </span>-<span class="w"> </span>AssertionError:<span class="w"> </span>Test<span class="w"> </span>failed!
<span class="o">========================</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>failed<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.11s<span class="w"> </span><span class="o">========================</span>
</pre></div>
</div>
<p>It’s also important to make sure that an exception is raised whenever it should be.  For example, the version of the <code class="docutils literal notranslate"><span class="pre">escape_velocity()</span></code> function above did not check to make sure that the mass and radius arguments had positive values, which means that it would give nonsensical results when passed a negative mass or radius value.  To address this we should add code to the function that causes it to raise an exception if either of the arguments is negative:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">escape_velocity</span><span class="p">(</span><span class="n">mass</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">radius</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">G</span><span class="o">=</span><span class="mf">6.67430e-11</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the escape velocity from a celestial body, given its mass and radius.</span>

<span class="sd">    Args:</span>
<span class="sd">    mass (float): Mass of the celestial body in kg.</span>
<span class="sd">    radius (float): Radius of the celestial body in meters.</span>

<span class="sd">    Returns:</span>
<span class="sd">    float: Escape velocity in m/s.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mass</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">radius</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Mass and radius must be positive values.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">G</span> <span class="o">*</span> <span class="n">mass</span> <span class="o">/</span> <span class="n">radius</span><span class="p">)</span>

</pre></div>
</div>
<p>We can then specify a test that checks whether the function properly raises an exception when passed a negative value. To do this we can use a feature of the <code class="docutils literal notranslate"><span class="pre">pytest</span></code> package (<code class="docutils literal notranslate"><span class="pre">pytest.raises</span></code>) that passes only if the specified exception is raised:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_escape_velocity_negative</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Make sure the function raises ValueError for negative mass or radius.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">pytest</span><span class="o">.</span><span class="n">raises</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">escape_velocity</span><span class="p">(</span><span class="o">-</span><span class="mf">5.972e24</span><span class="p">,</span> <span class="mf">6.371e6</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="when-to-write-tests">
<h2>When to write tests<a class="headerlink" href="#when-to-write-tests" title="Permalink to this heading">#</a></h2>
<p>Too often researchers decide to write tests after they have written an entire codebase.  Having any tests is certainly better than having no tests, but integrating testing into ones development workflow from the start can help improve the development experience and ultimately lead to better and more maintainable software.  In Chapter 1 we mentioned the idea of <em>test-driven development</em>, which we outline in more detail below, but we first discuss a simple approach to introducing testing into the development process.</p>
<section id="bug-driven-testing-any-time-you-encounter-a-bug-write-a-test">
<h3>Bug-driven testing: Any time you encounter a bug, write a test<a class="headerlink" href="#bug-driven-testing-any-time-you-encounter-a-bug-write-a-test" title="Permalink to this heading">#</a></h3>
<p>An easy way to introduce testing into the development process is to write a new test any time one encounters a bug, which we refer to as <em>bug-driven testing</em>.  This makes it easy to then work on fixing the bug, since the test will determine when the bug has been fixed. In addition, the test will detect if future changes reintroduce the bug.</p>
<p>As an example, take the following function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">find_outliers</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Find outliers in a dataset using z-score method.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : List[float]</span>
<span class="sd">        List of numerical values.</span>
<span class="sd">    threshold : float, default=2.0</span>
<span class="sd">        Number of standard deviations from the mean to consider a value as an outlier.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    List[int]</span>
<span class="sd">        List of indices of outliers in the data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">mean</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">variance</span> <span class="o">**</span> <span class="mf">0.5</span>
    
    <span class="c1"># Bug: division by zero when std is 0 (all values are identical)</span>
    <span class="c1"># This only happens when all data points are the same</span>
    <span class="n">outliers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="n">z_score</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">value</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span> 
        <span class="k">if</span> <span class="n">z_score</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">:</span>
            <span class="n">outliers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">outliers</span>
</pre></div>
</div>
<p>This code works to properly identify outliers:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">:</span> <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>

<span class="n">In</span> <span class="p">:</span> <span class="n">find_outliers</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">Out</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
<p>However, it fails due to a division by zero if all of the values are equal:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">:</span> <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">In</span> <span class="p">:</span> <span class="n">find_outliers</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="o">---------------------------------------------------------------------------</span>
<span class="ne">ZeroDivisionError</span>                         <span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">)</span>
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">21</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="o">----&gt;</span> <span class="mi">1</span> <span class="n">find_outliers</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">9</span><span class="p">],</span> <span class="n">line</span> <span class="mi">26</span><span class="p">,</span> <span class="ow">in</span> <span class="n">find_outliers</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
     <span class="mi">24</span> <span class="n">outliers</span> <span class="o">=</span> <span class="p">[]</span>
     <span class="mi">25</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
<span class="o">---&gt;</span> <span class="mi">26</span>     <span class="n">z_score</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">value</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span> 
     <span class="mi">27</span>     <span class="k">if</span> <span class="n">z_score</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">:</span>
     <span class="mi">28</span>         <span class="n">outliers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

<span class="ne">ZeroDivisionError</span><span class="p">:</span> <span class="nb">float</span> <span class="n">division</span> <span class="n">by</span> <span class="n">zero</span>

</pre></div>
</div>
<p>Our intended behavior if all of the values are equal is to return an empty list, since there are by definition no outliers.  But before we do this, let’s create a couple of tests to check for the intended behavior and provide useful error messages if the test fails:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_find_outliers_normal_case</span><span class="p">():</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>  <span class="c1"># 100 is clearly an outlier</span>
    <span class="n">outliers</span> <span class="o">=</span> <span class="n">find_outliers</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
    
    <span class="c1"># Should find the outlier at index 5</span>
    <span class="k">assert</span> <span class="mi">5</span> <span class="ow">in</span> <span class="n">outliers</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Failed to detect outlier: </span><span class="si">{</span><span class="n">outliers</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">outliers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;Expected exactly one outlier, got: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">outliers</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span>


<span class="k">def</span> <span class="nf">test_find_outliers_identical_values</span><span class="p">():</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>  <span class="c1"># All identical values</span>
    
    <span class="n">outliers</span> <span class="o">=</span> <span class="n">find_outliers</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">outliers</span> <span class="o">==</span> <span class="p">[],</span> <span class="sa">f</span><span class="s2">&quot;Expected no outliers for identical values, got </span><span class="si">{</span><span class="n">outliers</span><span class="si">}</span><span class="s2">&quot;</span>
</pre></div>
</div>
<p>Running this with the original function definition, we see that it fails:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>❯ pytest src/BetterCodeBetterScience/bug_driven_testing.py
=========================== test session starts ===========================
collected 2 items

src/BetterCodeBetterScience/bug_driven_testing.py .F                [100%]

================================ FAILURES =================================
___________________ test_find_outliers_identical_values ___________________

    def test_find_outliers_identical_values():
        data = [5, 5, 5, 5, 5]  # All identical values

&gt;       outliers = find_outliers(data, threshold=2.0)

src/BetterCodeBetterScience/bug_driven_testing.py:50:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

data = [5, 5, 5, 5, 5], threshold = 2.0

    def find_outliers(data: List[float], threshold: float = 2.0) -&gt; List[int]:
        &quot;&quot;&quot;
        Find outliers in a dataset using z-score method.

        Parameters
        ----------
        data : List[float]
            List of numerical values.
        threshold : float, default=2.0
            Number of standard deviations from the mean to consider a value as an outlier.

        Returns
        -------
        List[int]
            List of indices of outliers in the data.
        &quot;&quot;&quot;

        mean = sum(data) / len(data)
        variance = sum((x - mean) ** 2 for x in data) / len(data)
        std = variance ** 0.5

        # Bug: division by zero when std is 0 (all values are identical)
        # This only happens when all data points are the same
        outliers = []
        for i, value in enumerate(data):
&gt;           z_score = abs(value - mean) / std  # Bug: std can be 0!
E           ZeroDivisionError: float division by zero

src/BetterCodeBetterScience/bug_driven_testing.py:31: ZeroDivisionError
========================= short test summary info =========================
FAILED src/BetterCodeBetterScience/bug_driven_testing.py::test_find_outliers_identical_values
 - ZeroDivisionError: float division by zero
======================= 1 failed, 1 passed in 0.10s =======================
</pre></div>
</div>
<p>We can now fix the code by returning an empty list if zero standard deviation is detected:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="o">...</span>
    <span class="k">if</span> <span class="n">std</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># If standard deviation is zero, all values are identical, so no outliers</span>
        <span class="k">return</span> <span class="p">[]</span>
</pre></div>
</div>
<p>Here we add a comment to explain the intention of the statement. Running the tests now will show that the problem is fixed:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>❯ pytest src/BetterCodeBetterScience/bug_driven_testing.py
=========================== test session starts ===========================
collected 2 items

src/BetterCodeBetterScience/bug_driven_testing.py ..                [100%]

============================ 2 passed in 0.08s ============================

</pre></div>
</div>
<p>Now we can continue coding with confidence that if we happen to accidentally reintroduce the bug, it will be caught.</p>
</section>
</section>
<section id="the-structure-of-a-good-test">
<h2>The structure of a good test<a class="headerlink" href="#the-structure-of-a-good-test" title="Permalink to this heading">#</a></h2>
<p>A commonly used scheme for writing a test is “given/when/then”:</p>
<ul class="simple">
<li><p>given some particular situation as background</p></li>
<li><p>when something happens (such as a particular input)</p></li>
<li><p>then something else should happen (such as a particular output or exception)</p></li>
</ul>
<p>Importantly, a test should only test one thing at a time.  This doesn’t mean that the test should necessarily only test for one specific error at a time; rather, it means that the test should assess a specific situation (“given/when”), and then assess all of the possible outcomes that are necessary to ensure that the component functions properly (“then”).  You can see this in the test for zero standard deviation that we generated in the earlier example, which actually tested for two conditions (the intended value being present in the list, and the list having a length of one) that together define the condition that we are interested in testing for.</p>
<p>How do we test that the output of a function is correct given the input?  There are different answers for different situations:</p>
<ul class="simple">
<li><p><em>commonly known answer</em>: Sometimes we possess inputs where the output is known.  For example, if we were creating a function that computes the circumference of a circle, then we know that the output for an input radius of 1 should be 2 * pi.  This is generally only the case for very simple functions.</p></li>
<li><p><em>reference implementation</em>: In other cases we may have a standard implementation of an algorithm that we can compare against.  While in general it’s not a good idea to reimplement code that already exists in a standard library, in come cases we may want to extend existing code but also check that the basic version still works as planned.</p></li>
<li><p><em>parallel implementation</em>: Some times we don’t have a reference implementation, but we can code up another parallel implementation to compare our code to.  It’s important that this isn’t just a copy of the code used in the function; in that case, it’s really not a test at all!</p></li>
<li><p><em>behavioral test</em>: Sometimes the best we can do is to run the code repeatedly and ensure that it behaves as expected on average.  For example, if a function outputs a numerical value and we know the expected distribution of that value given a particular input, we can ensure that the result matches that distribution with a high probability.  Such <em>probabilistic tests</em> are not optimal in the sense that they can occasionally fail even when the code is correct, but they are sometimes the best we can do.</p></li>
</ul>
<section id="test-against-the-interface-not-the-implementation">
<h3>Test against the interface, not the implementation<a class="headerlink" href="#test-against-the-interface-not-the-implementation" title="Permalink to this heading">#</a></h3>
<p>A good test shouldn’t know about the internal implementation details of the function that it is testing, and changes in the internal code that do not modify the input-output relationship should not affect the test.  That is, from the standpoint of the test, a function should be a “black box”.</p>
<p>The most common way in which a test can violate this principle is by accessing the internal variables of a class that it is testing.  For example, we might generate a class that performs a scaling operation on a numpy matrix:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleScaler</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformed_</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformed_</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformed_</span>

    <span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p>We could write a test that checks the values returned by the <code class="docutils literal notranslate"><span class="pre">fit_transform()</span></code> method, treating the the class as a black box:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_simple_scaler_interface</span><span class="p">():</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">SimpleScaler</span><span class="p">()</span>
    
    <span class="c1"># Test the interface without accessing internals</span>
    <span class="n">transformed_X</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">transformed_X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">transformed_X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p>Alternatively one might use knowledge of the internals of the class to test the transformed value:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_simple_scaler_internals</span><span class="p">():</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">SimpleScaler</span><span class="p">()</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
    <span class="c1"># Test that the transformed data is correct using the internal</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">transformed_</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">transformed_</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>

</pre></div>
</div>
<p>Both of these tests pass against the class definition shown above. However, if we were to change the way that the transformation is performed (for example, we decide to use the <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> function from <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> instead of writing our own), then the implementation-aware tests are likely to fail unless the sample internal variable names are used.  In general we should only interact with a function or class via its explicit interfaces.</p>
</section>
<section id="tests-should-be-independent">
<h3>Tests should be independent<a class="headerlink" href="#tests-should-be-independent" title="Permalink to this heading">#</a></h3>
<p>In scientific computing it’s common to compose many different operations into a workflow.  If we want to test the workflow, then the tests of later steps in the workflow must necessarily rely upon earlier steps.  We could in theory write a set of tests that operate on a shared object, but the tests would fail if executed in an incorrect order, even if the code was correct.  Similarly, a failure on an early test would cause cascading failures in later tests, even if their code was correct.  The use of ordered tests also prevents the parallel execution of tests, which may slow down testing for complex projects.  For these reasons, we should always aim to create tests that can be executed independently.</p>
<p>Here is an example where coupling between tests could cause failures.  First we generate two functions that make changes in place to a data frame:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">split_names</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;firstname&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;lastname&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">get_initials</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;initials&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;firstname&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;lastname&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

</pre></div>
</div>
<p>In this case, the <code class="docutils literal notranslate"><span class="pre">get_initials()</span></code> function relies upon the <code class="docutils literal notranslate"><span class="pre">split_names()</span></code> function having been run, since otherwise the necessary columns won’t exist in the data frame. We can then create tests for each of these, and a data frame that they can both use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">people_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Alice Smith&#39;</span><span class="p">,</span> <span class="s1">&#39;Bob Howard&#39;</span><span class="p">,</span> <span class="s1">&#39;Charlie Ashe&#39;</span><span class="p">]})</span> 

<span class="k">def</span> <span class="nf">test_split_names</span><span class="p">():</span>
    <span class="n">split_names</span><span class="p">(</span><span class="n">people_df</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">people_df</span><span class="p">[</span><span class="s1">&#39;firstname&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;Alice&#39;</span><span class="p">,</span> <span class="s1">&#39;Bob&#39;</span><span class="p">,</span> <span class="s1">&#39;Charlie&#39;</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">people_df</span><span class="p">[</span><span class="s1">&#39;lastname&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;Smith&#39;</span><span class="p">,</span> <span class="s1">&#39;Howard&#39;</span><span class="p">,</span> <span class="s1">&#39;Ashe&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">test_get_initials</span><span class="p">():</span>
    <span class="n">get_initials</span><span class="p">(</span><span class="n">people_df</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">people_df</span><span class="p">[</span><span class="s1">&#39;initials&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;AS&#39;</span><span class="p">,</span> <span class="s1">&#39;BH&#39;</span><span class="p">,</span> <span class="s1">&#39;CA&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>These tests run correctly, but the same tests fail if we change their order such that <code class="docutils literal notranslate"><span class="pre">test_get_intials()</span></code> runs first, because the necessary columns (<code class="docutils literal notranslate"><span class="pre">firstname</span></code> and <code class="docutils literal notranslate"><span class="pre">lastname</span></code>) have not yet been created.</p>
<p>One simple way to deal with this is to set up all of the necessary structure locally within each test:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">get_people_df</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Alice Smith&#39;</span><span class="p">,</span> <span class="s1">&#39;Bob Howard&#39;</span><span class="p">,</span> <span class="s1">&#39;Charlie Ashe&#39;</span><span class="p">]})</span> 

<span class="k">def</span> <span class="nf">test_split_names_fullsetup</span><span class="p">():</span>
    <span class="n">local_people_df</span> <span class="o">=</span> <span class="n">get_people_df</span><span class="p">()</span>
    <span class="n">split_names</span><span class="p">(</span><span class="n">local_people_df</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">local_people_df</span><span class="p">[</span><span class="s1">&#39;firstname&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;Alice&#39;</span><span class="p">,</span> <span class="s1">&#39;Bob&#39;</span><span class="p">,</span> <span class="s1">&#39;Charlie&#39;</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">local_people_df</span><span class="p">[</span><span class="s1">&#39;lastname&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;Smith&#39;</span><span class="p">,</span> <span class="s1">&#39;Howard&#39;</span><span class="p">,</span> <span class="s1">&#39;Ashe&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">test_get_initials_fullsetup</span><span class="p">():</span>
    <span class="n">local_people_df</span> <span class="o">=</span> <span class="n">get_people_df</span><span class="p">()</span>
    <span class="n">split_names</span><span class="p">(</span><span class="n">local_people_df</span><span class="p">)</span>
    <span class="n">get_initials</span><span class="p">(</span><span class="n">local_people_df</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">local_people_df</span><span class="p">[</span><span class="s1">&#39;initials&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;AS&#39;</span><span class="p">,</span> <span class="s1">&#39;BH&#39;</span><span class="p">,</span> <span class="s1">&#39;CA&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>For simple functions like these this would not cause too much computational overhead, but for computationally intensive functions we would like to be able to reuse the results from the first time each function is run.  In a later section we will discuss the use of <em>fixtures</em> which allow this kind of reuse across tests while avoiding the ordering problems that we saw above when using a global variable across tests.</p>
</section>
</section>
<section id="testing-frameworks">
<h2>Testing frameworks<a class="headerlink" href="#testing-frameworks" title="Permalink to this heading">#</a></h2>
<p>One could write tests without the help of any specialized packages, but we generally use a testing framework to help automate the activities of testing.  There are several testing frameworks for Python; we will focus on the popular and flexible <code class="docutils literal notranslate"><span class="pre">pytest</span></code> framework.</p>
<p>We will start with a very simple example: a function that generates the Euclidean distance between two points.  Copilot generates the following for us based on the prompt in the comment:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate a function that calculates the distance between two points</span>
<span class="c1"># where each point is defined as a tuple of two numbers</span>

<span class="kn">import</span> <span class="nn">math</span>

<span class="k">def</span> <span class="nf">distance</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate the distance between two points&quot;&quot;&quot;</span>
    <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="n">p1</span>
    <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="n">p2</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">x2</span> <span class="o">-</span> <span class="n">x1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">y2</span> <span class="o">-</span> <span class="n">y1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we would like to generate some tests for this code to make sure that it works properly. If we ask Copilot to generate some tests, it does a seeming decent job:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_distance_zero</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">distance</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">test_distance_positive_coordinates</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">distance</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span> <span class="o">==</span> <span class="mi">5</span>

<span class="k">def</span> <span class="nf">test_distance_negative_coordinates</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">distance</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">))</span> <span class="o">==</span> <span class="mi">5</span>

<span class="k">def</span> <span class="nf">test_distance_mixed_coordinates</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">distance</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span> <span class="o">==</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">125</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test_distance_same_x</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">distance</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span> <span class="o">==</span> <span class="mi">4</span>

<span class="k">def</span> <span class="nf">test_distance_same_y</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">distance</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span> <span class="o">==</span> <span class="mi">4</span>
</pre></div>
</div>
<p>Now that we have our tests, we can run them using the <code class="docutils literal notranslate"><span class="pre">pytest</span></code> command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pytest<span class="w"> </span>src/BetterCodeBetterScience/distance_testing
</pre></div>
</div>
<p>This command will cause pytest to search (by default) for any files named <code class="docutils literal notranslate"><span class="pre">test_*.py</span></code> or <code class="docutils literal notranslate"><span class="pre">*_test.py</span></code> in the relevant path, and the select any functions whose name starts with the prefix “test”.  Running those tests, we get an error:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&gt;<span class="w">       </span>assert<span class="w"> </span>distance<span class="o">((</span><span class="m">1</span>,<span class="w"> </span>-2<span class="o">)</span>,<span class="w"> </span><span class="o">(</span>-4,<span class="w"> </span><span class="m">6</span><span class="o">))</span><span class="w"> </span><span class="o">==</span><span class="w"> </span>math.sqrt<span class="o">(</span><span class="m">125</span><span class="o">)</span>
E<span class="w">       </span>assert<span class="w"> </span><span class="m">9</span>.433981132056603<span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">11</span>.180339887498949
E<span class="w">        </span>+<span class="w">  </span>where<span class="w"> </span><span class="m">9</span>.433981132056603<span class="w"> </span><span class="o">=</span><span class="w"> </span>distance<span class="o">((</span><span class="m">1</span>,<span class="w"> </span>-2<span class="o">)</span>,<span class="w"> </span><span class="o">(</span>-4,<span class="w"> </span><span class="m">6</span><span class="o">))</span>
E<span class="w">        </span>+<span class="w">  </span>and<span class="w">   </span><span class="m">11</span>.180339887498949<span class="w"> </span><span class="o">=</span><span class="w"> </span>&lt;built-in<span class="w"> </span><span class="k">function</span><span class="w"> </span>sqrt&gt;<span class="o">(</span><span class="m">125</span><span class="o">)</span>
E<span class="w">        </span>+<span class="w">    </span>where<span class="w"> </span>&lt;built-in<span class="w"> </span><span class="k">function</span><span class="w"> </span>sqrt&gt;<span class="w"> </span><span class="o">=</span><span class="w"> </span>math.sqrt
</pre></div>
</div>
<p>Here we see that the value returned by our function is different from the one expected by the test; in this case, the test value generated by Copilot is incorrect.  In our research, it was not uncommon for ChatGPT to generate incorrect test values, so these must always be checked by a domain expert.  Once we fix the expected value for that test (the square root of 89), then we can rerun the tests and see that they have passed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>pytest<span class="w"> </span>pytest<span class="w"> </span>src/BetterCodeBetterScience/distance_testing
<span class="o">====================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">=====================</span><span class="w">                                     </span>

src/codingforscience/simple_testing/test_distance.py<span class="w"> </span>.<span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="m">16</span>%<span class="o">]</span>
.....<span class="w">                                                  </span><span class="o">[</span><span class="m">100</span>%<span class="o">]</span>

<span class="o">=====================</span><span class="w"> </span><span class="m">6</span><span class="w"> </span>passed<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.06s<span class="w"> </span><span class="o">======================</span>
</pre></div>
</div>
<section id="potential-problems-with-ai-generated-tests">
<h3>Potential problems with AI-generated tests<a class="headerlink" href="#potential-problems-with-ai-generated-tests" title="Permalink to this heading">#</a></h3>
<p>If we are going to rely upon AI tools to generate our tests, we need to be sure that the tests are correct.  One of my early forays into AI-driven test generation uncovered an interesting example of how this can go wrong.</p>
<p>In our early project that examined the performance of GPT-4 for coding <span id="id2">[<a class="reference internal" href="bibliography.html#id17" title="Russell A Poldrack, Thomas Lu, and Gašper Beguš. Ai-assisted coding: experiments with gpt-4. 2023. URL: https://arxiv.org/abs/2304.13187, arXiv:2304.13187.">Poldrack <em>et al.</em>, 2023</a>]</span>, one of the analyses that we performed first asked GPT-4 to do was to generate a set of functions related to common problems in several scientific domains, and then to generate tests to make sure that the function performed correctly.  One of the functions that was generated was the escape velocity function shown above, for which GPT-4 generated the <a class="reference external" href="https://github.com/poldrack/ai-coding-experiments/blob/main/data/conceptual_prompting/testdirs/conceptual_prompting06/test_answer.py">following test</a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_escape_velocity</span><span class="p">():</span>

    <span class="n">mass_earth</span> <span class="o">=</span> <span class="mf">5.972e24</span>
    <span class="n">radius_earth</span> <span class="o">=</span> <span class="mf">6.371e6</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">escape_velocity</span><span class="p">(</span><span class="n">mass_earth</span><span class="p">,</span> <span class="n">radius_earth</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">pytest</span><span class="o">.</span><span class="n">approx</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">rel</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span> <span class="o">==</span> <span class="mf">11186.25</span>

    <span class="n">mass_mars</span> <span class="o">=</span> <span class="mf">6.4171e23</span>
    <span class="n">radius_mars</span> <span class="o">=</span> <span class="mf">3.3895e6</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">escape_velocity</span><span class="p">(</span><span class="n">mass_mars</span><span class="p">,</span> <span class="n">radius_mars</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">pytest</span><span class="o">.</span><span class="n">approx</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">rel</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span> <span class="o">==</span> <span class="mf">5027.34</span>

    <span class="n">mass_jupiter</span> <span class="o">=</span> <span class="mf">1.8982e27</span>
    <span class="n">radius_jupiter</span> <span class="o">=</span> <span class="mf">6.9911e7</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">escape_velocity</span><span class="p">(</span><span class="n">mass_jupiter</span><span class="p">,</span> <span class="n">radius_jupiter</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">pytest</span><span class="o">.</span><span class="n">approx</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">rel</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span> <span class="o">==</span> <span class="mf">59564.97</span>
</pre></div>
</div>
<p>When we run this test (renaming it <code class="docutils literal notranslate"><span class="pre">test_escape_velocity_gpt4</span></code>), we see that one of the tests fails:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>❯<span class="w"> </span>pytest<span class="w"> </span>src/BetterCodeBetterScience/escape_velocity.py::test_escape_velocity_gpt4
<span class="o">====================================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">====================================</span>
platform<span class="w"> </span>darwin<span class="w"> </span>--<span class="w"> </span>Python<span class="w"> </span><span class="m">3</span>.12.0,<span class="w"> </span>pytest-8.4.1,<span class="w"> </span>pluggy-1.5.0
rootdir:<span class="w"> </span>/Users/poldrack/Dropbox/code/BetterCodeBetterScience
configfile:<span class="w"> </span>pyproject.toml
plugins:<span class="w"> </span>cov-5.0.0,<span class="w"> </span>anyio-4.6.0,<span class="w"> </span>hypothesis-6.115.3,<span class="w"> </span>mock-3.14.0
collected<span class="w"> </span><span class="m">1</span><span class="w"> </span>item

src/BetterCodeBetterScience/escape_velocity.py<span class="w"> </span>F<span class="w">                                      </span><span class="o">[</span><span class="m">100</span>%<span class="o">]</span>

<span class="o">=========================================</span><span class="w"> </span><span class="nv">FAILURES</span><span class="w"> </span><span class="o">==========================================</span>
_________________________________<span class="w"> </span>test_escape_velocity_gpt4<span class="w"> </span>_________________________________

<span class="w">    </span>def<span class="w"> </span>test_escape_velocity_gpt4<span class="o">()</span>:

<span class="w">        </span><span class="nv">mass_earth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span>.972e24
<span class="w">        </span><span class="nv">radius_earth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">6</span>.371e6
<span class="w">        </span><span class="nv">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>escape_velocity<span class="o">(</span>mass_earth,<span class="w"> </span>radius_earth<span class="o">)</span>
<span class="w">        </span>assert<span class="w"> </span>pytest.approx<span class="o">(</span>result,<span class="w"> </span><span class="nv">rel</span><span class="o">=</span>1e-3<span class="o">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">11186</span>.25

<span class="w">        </span><span class="nv">mass_mars</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">6</span>.4171e23
<span class="w">        </span><span class="nv">radius_mars</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span>.3895e6
<span class="w">        </span><span class="nv">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>escape_velocity<span class="o">(</span>mass_mars,<span class="w"> </span>radius_mars<span class="o">)</span>
<span class="w">        </span>assert<span class="w"> </span>pytest.approx<span class="o">(</span>result,<span class="w"> </span><span class="nv">rel</span><span class="o">=</span>1e-3<span class="o">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">5027</span>.34

<span class="w">        </span><span class="nv">mass_jupiter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span>.8982e27
<span class="w">        </span><span class="nv">radius_jupiter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">6</span>.9911e7
<span class="w">        </span><span class="nv">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>escape_velocity<span class="o">(</span>mass_jupiter,<span class="w"> </span>radius_jupiter<span class="o">)</span>
&gt;<span class="w">       </span>assert<span class="w"> </span>pytest.approx<span class="o">(</span>result,<span class="w"> </span><span class="nv">rel</span><span class="o">=</span>1e-3<span class="o">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">59564</span>.97
E<span class="w">       </span>assert<span class="w"> </span><span class="m">60202</span>.716344497014<span class="w"> </span>±<span class="w"> </span><span class="m">60</span>.2027<span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">59564</span>.97
E
E<span class="w">         </span>comparison<span class="w"> </span>failed
E<span class="w">         </span>Obtained:<span class="w"> </span><span class="m">59564</span>.97
E<span class="w">         </span>Expected:<span class="w"> </span><span class="m">60202</span>.716344497014<span class="w"> </span>±<span class="w"> </span><span class="m">60</span>.2027

src/BetterCodeBetterScience/escape_velocity.py:52:<span class="w"> </span><span class="nv">AssertionError</span>
<span class="o">==================================</span><span class="w"> </span>short<span class="w"> </span><span class="nb">test</span><span class="w"> </span>summary<span class="w"> </span><span class="nv">info</span><span class="w"> </span><span class="o">==================================</span>
FAILED<span class="w"> </span>src/BetterCodeBetterScience/escape_velocity.py::test_escape_velocity_gpt4<span class="w"> </span>-<span class="w"> </span>assert<span class="w"> </span><span class="m">60202</span>.716344497014<span class="w"> </span>±<span class="w"> </span><span class="m">60</span>.2027<span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">59564</span>.97
<span class="o">=====================================</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>failed<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.12s<span class="w"> </span><span class="o">=====================================</span>
</pre></div>
</div>
<p>It seems that the first two assertions pass but the third one, for Jupiter, fails.  This failure took a bit of digging to fully understand.  In this case, the code and test value are both correct, depending on where you stand on Jupiter! The problem is that planets are <em>oblate</em>, meaning that they are slightly flattened such that the radius around the equator is higher than at other points.  NASA’s <a class="reference external" href="https://nssdc.gsfc.nasa.gov/planetary/factsheet/jupiterfact.html">Jupiter fact sheet</a> claims an escape velocity of 59.5 km/s, which seems to be the source of the test value.  This is correct when computed using the equatorial radius of 71492 km.  However, the radius given for Jupiter in GPT-4’s test (69911 km) is the volumetric mean radius rather than the equatorial radius, and the value generated by the code (60.2 km/s) is correct when computed using the volumetric mean radius.  Thus, the test failed not due to any problems with the code itself, but due to a mismatch in assumptions regarding the combination of test values.  This example highlights the importance of understanding and checking the tests that are generated by AI coding tools.</p>
</section>
</section>
<section id="test-driven-development-and-ai-assisted-coding">
<h2>Test-driven development and AI-assisted coding<a class="headerlink" href="#test-driven-development-and-ai-assisted-coding" title="Permalink to this heading">#</a></h2>
<p>Here we will dive into a more realistic example of an application that one might develop using AI assistance, specifically looking at how we could develop the application using a test-driven development (TDD) approach.  We will develop a Python application that takes in a query for the PubMed database and returns a data frame containing the number of database records matching that query for each year. We start by decomposing the problem and sketching out the main set of functions that we will need to develop, with understandable names for each:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">get_PubmedIDs_for_query</span></code>: A function that will search pubmed for a given query and return a list of pubmed IDs</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_record_from_PubmedID</span></code>: A function that will retrieve the record for a given pubmed ID</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">parse_year_from_Pubmed_record</span></code>: A function that will parse a record to extract the year of publication</p></li>
<li><p>A function that will summarize the number of records per year</p></li>
<li><p>The main function that will take in a query and return a data frame with the number of records per year for the query</p></li>
</ul>
<p>We start by creating <code class="docutils literal notranslate"><span class="pre">get_PubmedIDs_for_query</span></code>.  We could use the <code class="docutils literal notranslate"><span class="pre">Biopython.Entrez</span></code> module to perform this search, but Biopython is a relatively large module that could introduce technical debt.  Instead, we will directly retrieve the result using the Entrez API and the built-in <code class="docutils literal notranslate"><span class="pre">requests</span></code> module. Note that for all of the code shown here we will not include docstrings, but they are available in the code within the repository.</p>
<p>If we are using the TDD approach, we would first want to develop a set of tests to make sure that our function is working correctly.  The following three tests specify several different outcomes that we might expect. First, we give a query that is known to give a valid result, and test whether it in fact gives such a result:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_get_PubmedIDs_for_query_check_valid</span><span class="p">():</span>
    <span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;friston-k AND &#39;free energy&#39;&quot;</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="n">get_PubmedIDs_for_query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>

    <span class="c1"># make sure that a list is returned</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>       
    <span class="c1"># make sure the list is not empty</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>                 
</pre></div>
</div>
<p>Second, we give a query with a known empty result, and make sure it returns an empty list:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_get_PubmedIDs_for_query_check_empty</span><span class="p">():</span>
    <span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;friston-k AND &#39;fizzbuzz&#39;&quot;</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="n">get_PubmedIDs_for_query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>

    <span class="c1"># make sure that a list is returned</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>   
    <span class="c1"># make sure the resulting list is empty</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
</pre></div>
</div>
<p>With the minimal tests in place, we then move to writing the code for the module.  We first create an empty function to ensure that the tests fail:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_PubmedIDs_for_query</span><span class="p">(</span><span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
                            <span class="n">retmax</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                            <span class="n">esearch_url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="k">return</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The test result shows that all of the tests fail:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>❯<span class="w"> </span>python<span class="w"> </span>-m<span class="w"> </span>pytest<span class="w"> </span>-v<span class="w"> </span>tests/textmining
<span class="o">==================================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">===================================</span>
...
tests/textmining/test_textmining.py::test_get_PubmedIDs_for_query_check_valid<span class="w"> </span>FAILED<span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="m">50</span>%<span class="o">]</span>
tests/textmining/test_textmining.py::test_get_PubmedIDs_for_query_check_empty<span class="w"> </span>FAILED<span class="w"> </span><span class="o">[</span><span class="m">100</span>%<span class="o">]</span>

<span class="o">========================================</span><span class="w"> </span><span class="nv">FAILURES</span><span class="w"> </span><span class="o">========================================</span>
________________________<span class="w"> </span>test_get_PubmedIDs_for_query_check_valid<span class="w"> </span>________________________

<span class="nv">ids</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>None

<span class="w">    </span>def<span class="w"> </span>test_get_PubmedIDs_for_query_check_valid<span class="o">(</span>ids<span class="o">)</span>:
&gt;<span class="w">       </span>assert<span class="w"> </span>isinstance<span class="o">(</span>ids,<span class="w"> </span>list<span class="o">)</span>
E<span class="w">       </span>assert<span class="w"> </span>False
E<span class="w">        </span>+<span class="w">  </span>where<span class="w"> </span><span class="nv">False</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>isinstance<span class="o">(</span>None,<span class="w"> </span>list<span class="o">)</span>

tests/textmining/test_textmining.py:32:<span class="w"> </span>AssertionError
________________________<span class="w"> </span>test_get_PubmedIDs_for_query_check_empty<span class="w"> </span>________________________

<span class="w">    </span>def<span class="w"> </span>test_get_PubmedIDs_for_query_check_empty<span class="o">()</span>:
<span class="w">        </span><span class="nv">query</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;friston-k AND &#39;fizzbuzz&#39;&quot;</span>
<span class="w">        </span><span class="nv">ids</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>get_PubmedIDs_for_query<span class="o">(</span>query<span class="o">)</span>
&gt;<span class="w">       </span>assert<span class="w"> </span>len<span class="o">(</span>ids<span class="o">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">0</span>
<span class="w">               </span>^^^^^^^^
E<span class="w">       </span>TypeError:<span class="w"> </span>object<span class="w"> </span>of<span class="w"> </span><span class="nb">type</span><span class="w"> </span><span class="s1">&#39;NoneType&#39;</span><span class="w"> </span>has<span class="w"> </span>no<span class="w"> </span>len<span class="o">()</span>

tests/textmining/test_textmining.py:39:<span class="w"> </span><span class="nv">TypeError</span>
<span class="o">================================</span><span class="w"> </span>short<span class="w"> </span><span class="nb">test</span><span class="w"> </span>summary<span class="w"> </span><span class="nv">info</span><span class="w"> </span><span class="o">=================================</span>
FAILED<span class="w"> </span>tests/textmining/test_textmining.py::test_get_PubmedIDs_for_query_check_valid<span class="w"> </span>-<span class="w"> </span>assert<span class="w"> </span>False
FAILED<span class="w"> </span>tests/textmining/test_textmining.py::test_get_PubmedIDs_for_query_check_empty<span class="w"> </span>-<span class="w"> </span>TypeError:<span class="w"> </span>object<span class="w"> </span>of<span class="w"> </span><span class="nb">type</span><span class="w"> </span><span class="s1">&#39;NoneType&#39;</span><span class="w"> </span>has<span class="w"> </span>no<span class="w"> </span>len<span class="o">()</span>
<span class="o">===================================</span><span class="w"> </span><span class="m">2</span><span class="w"> </span>failed<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.12s<span class="w"> </span><span class="o">====================================</span>
</pre></div>
</div>
<p>Now we work with Copilot write the code to make the tests pass:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the eutils base URL globally for the module</span>
<span class="c1"># - not best practice but probably ok here</span>
<span class="n">BASE_URL</span> <span class="o">=</span> <span class="s2">&quot;https://eutils.ncbi.nlm.nih.gov/entrez/eutils&quot;</span>


<span class="k">def</span> <span class="nf">get_PubmedIDs_for_query</span><span class="p">(</span>
    <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">retmax</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">esearch_url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Search database for a given query and return a list of IDs.</span>
<span class="sd">    :param query: str, the query to search for</span>
<span class="sd">    :param retmax: int, the maximum number of results to return</span>
<span class="sd">    :base_url: str, the base url for the pubmed search</span>
<span class="sd">    :return: list, a list of pubmed IDs</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># define the base url for the pubmed search</span>
    <span class="k">if</span> <span class="n">esearch_url</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">esearch_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">BASE_URL</span><span class="si">}</span><span class="s2">/esearch.fcgi&quot;</span>

    <span class="n">params</span> <span class="o">=</span> <span class="n">format_pubmed_query_params</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">retmax</span><span class="o">=</span><span class="n">retmax</span><span class="p">)</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">esearch_url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">get_idlist_from_response</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">format_pubmed_query_params</span><span class="p">(</span><span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">retmax</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Format a query for use with the pubmed api.</span>
<span class="sd">    :param query: str, the query to format</span>
<span class="sd">    :return: dict, the formatted query dict</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># define the parameters for the search</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;db&quot;</span><span class="p">:</span> <span class="s2">&quot;pubmed&quot;</span><span class="p">,</span> <span class="s2">&quot;term&quot;</span><span class="p">:</span> <span class="n">query</span><span class="p">,</span> <span class="s2">&quot;retmode&quot;</span><span class="p">:</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span> <span class="s2">&quot;retmax&quot;</span><span class="p">:</span> <span class="n">retmax</span><span class="p">}</span>


<span class="k">def</span> <span class="nf">get_idlist_from_response</span><span class="p">(</span><span class="n">response</span><span class="p">:</span> <span class="n">requests</span><span class="o">.</span><span class="n">Response</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
        <span class="c1"># extract the pubmed IDs from the response</span>
        <span class="n">ids</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s2">&quot;esearchresult&quot;</span><span class="p">][</span><span class="s2">&quot;idlist&quot;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">ids</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Bad request&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that we have split parts of the functionality into separate functions in order to make the code more understandable.  Running the tests, we see that both of them pass.  Assuming that our tests cover all possible outcomes of interest, we can consider our function complete.  We can also add additional tests to cover additional functions that we generated; we won’t go into the details here, but you can see them on the Github repo.</p>
</section>
<section id="test-coverage">
<h2>Test coverage<a class="headerlink" href="#test-coverage" title="Permalink to this heading">#</a></h2>
<p>It can be useful to know if there are any portions of our code that are not being exercised by our tests, which is known as <em>code coverage</em>.  The <code class="docutils literal notranslate"><span class="pre">pytest-cov</span></code> extension for the <code class="docutils literal notranslate"><span class="pre">pytest</span></code> testing package can provide us with a report of test coverage for these tests:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>----------<span class="w"> </span>coverage:<span class="w"> </span>platform<span class="w"> </span>darwin,<span class="w"> </span>python<span class="w"> </span><span class="m">3</span>.12.0-final-0<span class="w"> </span>----------
Name<span class="w">                                                   </span>Stmts<span class="w">   </span>Miss<span class="w">  </span>Cover<span class="w">   </span>Missing
------------------------------------------------------------------------------------
src/BetterCodeBetterScience/textmining/textmining.py<span class="w">      </span><span class="m">30</span><span class="w">      </span><span class="m">1</span><span class="w">    </span><span class="m">97</span>%<span class="w">   </span><span class="m">70</span>
------------------------------------------------------------------------------------
TOTAL<span class="w">                                                     </span><span class="m">30</span><span class="w">      </span><span class="m">1</span><span class="w">    </span><span class="m">97</span>%
</pre></div>
</div>
<p>This report shows that of the 30 statements in our code, one of them is not covered by the tests.  When we look at the missing code (denoted as being on line 70), we see that the missing line is this one from <code class="docutils literal notranslate"><span class="pre">get_idlist_from_response</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># raise an exception if the search didn&#39;t return a usable response</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Bad request&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Since none of our test cases caused a bad request to occur, this line never gets executed in the tests. We can address this by adding a test that makes sure that an exception is raised if an invalid base url is provided. To check for an exception, we need to use the <code class="docutils literal notranslate"><span class="pre">pytest.raises</span></code> context manager:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_get_PubmedIDs_for_query_check_badurl</span><span class="p">():</span>
    <span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;friston-k AND &#39;free energy&#39;&quot;</span>
    <span class="c1"># bad url</span>
    <span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.f&#39;</span>
    
    <span class="c1"># make sure that the function raises an exception</span>
    <span class="k">with</span> <span class="n">pytest</span><span class="o">.</span><span class="n">raises</span><span class="p">(</span><span class="ne">Exception</span><span class="p">):</span>
        <span class="n">ids</span> <span class="o">=</span> <span class="n">get_PubmedIDs_for_query</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">base_url</span><span class="o">=</span><span class="n">base_url</span><span class="p">)</span>
    
</pre></div>
</div>
<p>After adding this test, we see that we now have 100% coverage. It’s important not to get too hung up on test coverage; rather than always aspiring to 100% coverage, it’s important to make sure that the most likely possible situations are tested.  Just because you have 100% coverage doesn’t mean that your code is perfectly tested, since there could always be situations that you haven’t checked for. And spending too much time testing for unlikely problems can divert your efforts from other most useful activities.</p>
</section>
<section id="test-fixtures">
<h2>Test fixtures<a class="headerlink" href="#test-fixtures" title="Permalink to this heading">#</a></h2>
<p>Sometimes we need to use a the same data for multiple tests. Rather than duplicating potentially time-consuming processes across each of the tests, it is often preferable to create a single instance of the object that can be used across multiple tests, which is known as a <em>test fixture</em>.  This also helps maintain isolation between tests, since the order of tests shouldn’t matter if an appropriate fixture is generated as soon as it’s needed.</p>
<p>For our example above, it’s likely that we will need to reuse the list of pubmed IDs from the search to perform various tests on the subsequent functions.  We can create a single version of this list of IDs by creating a fixture. In the <code class="docutils literal notranslate"><span class="pre">pytest</span></code> framework we do this using a special Python operator called a <em>decorator</em>, which is denoted by the symbol <code class="docutils literal notranslate"><span class="pre">&#64;</span></code> as a prefix. A decorator is function that takes another function as input, modifies its functionality, and returns another function; you don’t need to understand in detail how decorators work for this particular usage.  To refactor our tests above, we would first create the fixture by decorating the function that generates the fixture with the <code class="docutils literal notranslate"><span class="pre">&#64;pytest.fixture</span></code> decorator, setting the <code class="docutils literal notranslate"><span class="pre">scope</span></code> variable to “session” so that the fixture is only generated once within the session:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;session&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ids</span><span class="p">():</span>
    <span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;friston-k AND &#39;free energy&#39;&quot;</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="n">get_PubmedIDs_for_query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ids</span>
</pre></div>
</div>
<p>We can then refactor our tests for a valid query to use the fixture by passing it as an argument to the test function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_get_PubmedIDs_for_query_check_valid</span><span class="p">(</span><span class="n">ids</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
</pre></div>
</div>
<p>The result is the same, but we now have a set of ids that we can reuse in subsequent tests, so that we don’t have to make repeated queries.  It’s important to note while using a session-scoped fixture: If any of the subsequent tests modify the fixture, those modifications will persist, which will break the isolation between tests.  We could prevent this by removing the <code class="docutils literal notranslate"><span class="pre">scope=&quot;session&quot;</span></code> argument, which would then default to the standard scope which is within a specific function.  If you wish to use session-scoped fixtures and need to modify them within the test function, then it is best to first create a copy of the fixture object (e.g. <code class="docutils literal notranslate"><span class="pre">my_ids</span> <span class="pre">=</span> <span class="pre">ids.copy()</span></code>) so that the global fixture object won’t be modified.</p>
</section>
<section id="mocking">
<h2>Mocking<a class="headerlink" href="#mocking" title="Permalink to this heading">#</a></h2>
<p>Sometimes tests require infrastructure that is outside of the control of the tester. In the example above, we are assuming that the Pubmed API is working correctly for our tests to run; if we were to try to run these tests without an internet connection, they would fail.  In other cases, code may rely upon a database system that may or may not exist on a particular system.  In these cases, we can create a mock object that can stand in for and simulate the behavior of the system that the code needs to interact with.</p>
<p>In our example, we want to create a mock response that looks sufficiently like a response from the real API to pass our tests.  Using pytest’s <em>monkeypatch</em> fixture, we can temporarily replace the real requests.get function with our own fake function that returns a predictable, controlled response.  We first need to create a class that can replace the <code class="docutils literal notranslate"><span class="pre">requests.get</span></code> call in <code class="docutils literal notranslate"><span class="pre">get_PubmedIDs_for_query</span></code>, replacing it with a mock version that outputs a fixed simulacrum of an API response via its <code class="docutils literal notranslate"><span class="pre">.json()</span></code> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MockPubmedResponse</span><span class="p">:</span>
    <span class="n">status_code</span> <span class="o">=</span> <span class="mi">200</span>

    <span class="k">def</span> <span class="nf">json</span><span class="p">():</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;header&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;esearch&#39;</span><span class="p">,</span> <span class="s1">&#39;version&#39;</span><span class="p">:</span> <span class="s1">&#39;0.3&#39;</span><span class="p">},</span>
            <span class="s1">&#39;esearchresult&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;count&#39;</span><span class="p">:</span> <span class="s1">&#39;2&#39;</span><span class="p">,</span>
                <span class="s1">&#39;retmax&#39;</span><span class="p">:</span> <span class="s1">&#39;20&#39;</span><span class="p">,</span>
                <span class="s1">&#39;retstart&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
                <span class="s1">&#39;idlist&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;39312494&#39;</span><span class="p">,</span> <span class="s1">&#39;39089179&#39;</span><span class="p">]</span>
            <span class="p">}</span>
        <span class="p">}</span>
</pre></div>
</div>
<p>We now insert this mock response for the standard <code class="docutils literal notranslate"><span class="pre">requests.get</span></code> call within the test. In my initial attempt, I created created a fixture based on the mocked response and then tested that fixture:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span> <span class="nf">ids_mocked</span><span class="p">(</span><span class="n">monkeypatch</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">mock_get</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">MockPubmedResponse</span><span class="p">()</span>

    <span class="c1"># apply the monkeypatch for requests.get to mock_get</span>
    <span class="n">monkeypatch</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="n">requests</span><span class="p">,</span> <span class="s2">&quot;get&quot;</span><span class="p">,</span> <span class="n">mock_get</span><span class="p">)</span>

    <span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;friston-k AND &#39;free energy&#39;&quot;</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="n">get_PubmedIDs_for_query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ids</span>

<span class="k">def</span> <span class="nf">test_get_PubmedIDs_for_query_check_valid_mocked</span><span class="p">(</span><span class="n">ids_mocked</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ids_mocked</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">ids_mocked</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>

</pre></div>
</div>
<p>Turning off my network connection shows that the mocked test passes, while the tests that require connecting to the actual API fail.  However, my usual code review (using Google’s Gemini 2.5 Pro) identified a problem with this fixture: it conflates the setup (creating the mock API) with the execution of the function that uses the mock API.  A better approach (recommended by Gemini) is move the function execution out of the fixture and into the test:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fixture ONLY does the setup (the mocking)</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span> <span class="nf">mock_pubmed_api</span><span class="p">(</span><span class="n">monkeypatch</span><span class="p">):</span>

    <span class="k">class</span> <span class="nc">MockPubmedResponse</span><span class="p">:</span>
        <span class="n">status_code</span> <span class="o">=</span> <span class="mi">200</span>
        <span class="k">def</span> <span class="nf">json</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s1">&#39;header&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;esearch&#39;</span><span class="p">,</span> <span class="s1">&#39;version&#39;</span><span class="p">:</span> <span class="s1">&#39;0.3&#39;</span><span class="p">},</span>
                <span class="s1">&#39;esearchresult&#39;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s1">&#39;count&#39;</span><span class="p">:</span> <span class="s1">&#39;2&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;retmax&#39;</span><span class="p">:</span> <span class="s1">&#39;20&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;retstart&#39;</span><span class="p">:</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;idlist&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;39312494&#39;</span><span class="p">,</span> <span class="s1">&#39;39089179&#39;</span><span class="p">]</span>
                <span class="p">}</span>
            <span class="p">}</span>

    <span class="k">def</span> <span class="nf">mock_get</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">MockPubmedResponse</span><span class="p">()</span>

    <span class="c1"># Apply the monkeypatch for requests.get to mock_get</span>
    <span class="n">monkeypatch</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="n">requests</span><span class="p">,</span> <span class="s2">&quot;get&quot;</span><span class="p">,</span> <span class="n">mock_get</span><span class="p">)</span>

<span class="c1"># The test requests the setup, then performs the action and assertion.</span>
<span class="k">def</span> <span class="nf">test_get_PubmedIDs_for_query_check_valid_mocked</span><span class="p">(</span><span class="n">mock_pubmed_api</span><span class="p">):</span>
    <span class="c1"># Action: Call the function under test</span>
    <span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;friston-k AND &#39;free energy&#39;&quot;</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="n">get_PubmedIDs_for_query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>

    <span class="c1"># Assertion: Check the result</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
</pre></div>
</div>
<p>Note that while mocking can be useful for testing specific components by saving time and increasing robustness, integration tests and smoke tests should usually be run without mocking, in order to catch any errors that arise through interaction with the relevant components that are being mocked.  In fact, it’s always a good idea to have tests that specifically assess the usage of the external service and the system’s response to failures in that service (e.g. by using features of the testing framework that allow one to shut down access to the network).</p>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="id3"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>This is slightly inaccurate, because a true positive control would contain the actual virus. It would be more precise to call it a “procedural control” but these seem to be also referred to as “positive controls” so I am sticking with the more understandable terminology here.</p>
</dd>
</dl>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="software_engineering.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Principles of software engineering</p>
      </div>
    </a>
    <a class="right-next"
       href="bibliography.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Bibliography</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-use-software-tests">Why use software tests?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-tests">Types of tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unit-tests">Unit tests</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integration-tests">Integration tests</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-anatomy-of-a-test">The anatomy of a test</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#when-to-write-tests">When to write tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bug-driven-testing-any-time-you-encounter-a-bug-write-a-test">Bug-driven testing: Any time you encounter a bug, write a test</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-structure-of-a-good-test">The structure of a good test</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-against-the-interface-not-the-implementation">Test against the interface, not the implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tests-should-be-independent">Tests should be independent</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#testing-frameworks">Testing frameworks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#potential-problems-with-ai-generated-tests">Potential problems with AI-generated tests</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-driven-development-and-ai-assisted-coding">Test-driven development and AI-assisted coding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-coverage">Test coverage</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-fixtures">Test fixtures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mocking">Mocking</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Russell Poldrack et al.
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>